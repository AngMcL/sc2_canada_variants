---
title: "VisualizeStates"
author: "Angela"
date: "10/11/2020"
output: github_document
---

## Change log
2023-07-10
Cloned the Beta script to use for VOIs, first epsilon
Change the key dates, descrips, highlighted intervention/annotation, before vs after


Updates 2023-02-08
* gen2 based on this script
* fixed plotting issues with colors, axes, empty
* added averted sublineages, singletons, and cases 
* estimate of total focal var cases
* imports over time as line plots with confidence intervals, added alpha channel to non focal sources
* singletons: found tmrca of parental node, used 3/4 point b/w sample date and tmrca dt as intro date
* moved domestic transmission scripts into a different script

TO DO
* add singletons and sublins over time together
* calculate singeltons averted
* add confidence interval of sublins over time into the averted estimation

Update 2022-12-09
* make a generic version (based on the eta script) that will work on all vars
* include b/w prov transition events
* imports over time, make raw counts, consider showing singletons+sublineages
* Add text output of data queries
* add an input for whether or not there were variant specific measures, if so what date

Update 2022-11-21
update gamma script for eta
note: should really make a version of this that takes the variant name as input 
currently have to search/repl gamma with eta
check custom chunks about largest sublineages
modify key dates if needed
eta, epsilon, kappa, zeta, mu - no custom dates: remove highlight annotation and any before vs after
once complete on theses variants, write a new script to combine all the summarized results (sublins over time and descendants)

UPDATE 2022-10-24
Change file locations, start date, end date
Lineage colors should be similar to the var.WHO - specify within the script

UPDATE 2022-06-17
Many changes made for VOC-specific analysis
* voc instead of a specific subsaple strat
* need to subset out non-VOC intros / sublins
* should also subset to not allow predating voc.df$earliestsample
* 

UPDATE 2022-05-11
Incorporated changes that account for nested sublineages. If a sequence has multiple sublineage identities (due to nested sublineages), then only identify it as a unique descendant of the most recent one. Issue was that we were overinflating the size of early sublineages which were ancestral to large sections of the tree. This led to overestimate of early subs' sizes, the age since importation, etc. Multiple places where updates are necessary. Also, when only counting unique descendants, some sublineages disappeared altogether. Need to check these out - are they a result of polytomies? Were they artefacts of binarized polytomies? Once these changes made in this script, need to merge these changes into the other subsampling strategy scripts, including the comparison one.

UPDATE 2022-04-04
Decided that the 75% subsample was the best one to focus on in the figures
Restrict inputs to only have those ones
Change time range up to 2021-03-01
Change color scheme
Re-export all the figures and numbers for the results

Previous changes:
* Read in the output of the ancestral reconstruction from all boots
* Look at origins, intros, decscendants over time (using earliest sample collection date)
* Make significant code changes to read into list, extract necesssary uncertatinty related to 
  * Sublineages' #/% origin location, #/% province of introduction
  * Sublineage size distribution (what % sublins )
  * % singletons
* Signif change to merge the TMRCA_boots script INTO this one   
  
## to do
* incorporate tree bootstrap support into likelihood sensitivity analysis
* make this into a .Rscript to run via .sh script on cluster

## setup
```{r include=FALSE}
library(ape)
library(stringr)
library(dplyr)
library(tidyr)
library(plyr)
library(RColorBrewer)
library(ggplot2)
library(ggtree)
library(ggimage)
library(phytools)
library(phangorn)
library(forcats)
library(lubridate)
library(gridExtra)
library(cowplot)
library(ggstance)
library(ggalluvial)
library(ggmosaic)
library(MASS)
library(gtools)
library(treeio)
library(magick)
library(treemapify)
library(EpiEstim)
library(incidence)
library(reshape2)
library(zoo)
library(fitdistrplus)
library(ggridges)

```

## Set inputs 
```{r}
#Modifiable inputs
focal.var<-"iota"
Focal.var<-str_to_title(focal.var) 
ft_trees<-paste0("../02_trees/202208_analysis/",focal.var, "_lsd_out")
ft_in<-paste0("202208_ace_out/",focal.var,"_ace_out")
ft_trees_pre<-"../02_trees/202208_analysis/ft_betagammaiota_root_res"
focal.source<-c("USA")
focal.source.brf<-c("USA")


#were there variant specific interventions, if so, what dates?
int.yn<-FALSE
if(int.yn==T){
  # int.start<-as.Date("2020-12-24")
  # int.end<-as.Date("2021-02-22")
  # int.duration<-int.end-int.start
  # int.descrip<-"South Africa enhanced screening"
}

#for figures
fig.start.date<-as.Date("2020-11-01")
fig.end.date<-as.Date("2021-08-01")


#geo colors and lookup (merged to conts for small contribs)
global.colors.in<-"../01_subSample/colors_out/global.colors.tsv"
lookup.geo.in<-"../01_subSample/colors_out/lookup.geo.csv"
#variant colors
variant.colors.in<-"../01_subSample/CleanMeta_PreSubsamp/variant_colors.tsv"
#updated these
variant.df.in.glob<-paste0("../01_subSample/archive/Results_PreSubsamp_omi/variant.firstglobdate.csv")
variant.df.in<-paste0("../01_subSample/Results_PreSubsamp_omi_2023/variant.df.can.csv")
meta.glob.cases.in<-"../01_subSample/Results_PreSubsamp_omi_2023/meta.glob.var.country.daily.full3.csv"
meta.can.cases.in<-"../01_subSample/Results_PreSubsamp_omi_2023/meta.can.var.daily.full3.csv"

# study period
data.date<-"2022-03-22" 
start.date<-"2020-11-01"

# folder for exports
today<-Sys.Date()
f.out<-paste0(today,"_",focal.var,"_analysis/") 
if(!dir.exists(f.out)){dir.create(f.out)}

# EXPORT a textfile of inputs, summaries, and data queries
text.out<-paste0(f.out,today,"_DataSummary.txt")
cat(paste0("variant = ",focal.var),
    paste0("focal source geography = ",focal.source),
    paste0("lsd folder = ",ft_trees),
    paste0("var-specific intervention = ",int.yn),
    file=text.out,sep="\n",append=F)

if(int.yn==T){
  cat(paste0("var-spec intervention: ",int.descrip, ", from ",int.start," - ", int.end),
      paste0("Intervention duration=",int.end-int.start),
      file=text.out,sep="\n",append=T)
}
```

## read in color for Global and lineage groups
```{r}
#import a tsv of name and hex color for LOCATIONS
globalPalette<-read.table(global.colors.in)
  # "../../20210301_phylogeo/03_ancestral/colors_out/global.colors.tsv",sep="\t")
## make color scheme
glob.colz<-row.names(globalPalette) #NOTE THIS DIDN"T WORK
globalPalette.ch<-as.character(globalPalette$globalPalette)
names(globalPalette.ch)<-glob.colz

GlobColScale<-scale_colour_manual(name = "Location",values = globalPalette.ch,na.value="grey60")
GlobFillScale<-scale_fill_manual(name = "Location",values = globalPalette.ch,na.value="grey60")

CountryColScale<-scale_colour_manual(name = "Global region",
                                     values = globalPalette.ch[15:length( globalPalette.ch)],
                                     na.value="grey60")
CountryFillScale<-scale_fill_manual(name = "Global region",
                                    values = globalPalette.ch[15:length( globalPalette.ch)]
                                    ,na.value="grey60")

#read in lookup table to reduce cateogires to apply this color scheme (if haven't run MakeGlobalColors_boots.Rmd in this project already)
lookup.geo<-read.csv(lookup.geo.in)

## read in the variant df to use for inputs
var.df<-read.csv(variant.df.in)

#take the first canada data from this instead (complete for delta)
var.df.glob<-read.csv(variant.df.in.glob)
var.df.glob<-var.df.glob[,c("var.WHO","first.can.date")]
colnames(var.df.glob)<-c("var.WHO","first.can.date.new")
var.df<-left_join(var.df,var.df.glob,by="var.WHO")
var.df$first.can.date<-var.df$first.can.date.new #replaced!

var.df<-var.df[with(var.df, order(var.df$first.can.date, decreasing = F)),]

# use the first canadian sample date for variant to pull the delay in intervention from first canadian sample to int start
if(int.yn==T){
  firstsamp<-var.df$first.can.date[which(var.df$var.WHO %in% Focal.var)]
  cat(paste0("First Can sample: ", as.Date(firstsamp) ),
      paste0("Intervention delay = ", (int.start - as.Date(firstsamp)) ),
      file=text.out,sep="\n",append=T)
}

var.ord<-var.df$var.WHO
var.ord<-var.ord[-which(var.ord %in% c("Theta","Lambda","GH/490R"))]

varPalette<-read.table(variant.colors.in,sep="\t")

#varaint specific colors
focal.col<-rownames(varPalette)[which(tolower(varPalette$vars.ch)==focal.var)]
focal.pango<-var.df$var.lin[var.df$var.WHO==Focal.var]
focal.pango<-str_replace_all(focal.pango,"\\+","\\|")
focal.pango<-str_replace_all(focal.pango,"\\*","")



## make color scheme
var.colz<-as.character(varPalette$vars.ch)
varPalette.ch<-row.names(varPalette)
names(varPalette.ch)<-var.colz

VOCColScale<-scale_colour_manual(name = "Variant",values = varPalette.ch,na.value=NULL)
VOCFillScale<-scale_fill_manual(name = "Variant",values = varPalette.ch,na.value=NULL)

VOCFillScale2<-scale_fill_manual(name = "Variant",values = varPalette.ch[match(var.ord,names(varPalette.ch))],na.value="grey60")
VOCColScale2<-scale_colour_manual(name = "Variant",values = varPalette.ch[match(var.ord,names(varPalette.ch))],na.value="grey60")
```

## Figure publication themes
```{r}

pubTheme<-theme(panel.grid.major = element_blank(), 
                panel.grid.minor = element_blank(),
                panel.background=element_rect("grey95"), 
                axis.line = element_line(colour = "black"),
                legend.key.size = unit(0.5,"line"),
                text=element_text(size=10,face="bold"),
                legend.text=element_text(size=7))

pubThemeDate<-theme(panel.grid.major = element_blank(), 
                    panel.grid.minor = element_blank(),
                    panel.background=element_rect("grey95"), 
                    axis.line = element_line(colour = "black"),
                    text=element_text(size=10,face="bold"),
                    legend.key.size = unit(0.4,"line"),
                    legend.text=element_text(size=7),
                    axis.text.x=element_text(angle = 45,hjust=1,size=rel(1)))


scaleDate<-scale_x_date(date_breaks = "1 month", date_minor_breaks = "2 weeks", date_labels = "%b %Y",limits=as.Date(c(start.date,data.date)),expand=c(0,0))

xdates<-ymd(c("2020-12-01","2021-03-01","2021-06-01","2021-09-01","2021-12-01","2022-03-01"))
scaleDateBusy<-scale_x_date(breaks=xdates, date_labels = "%b %Y",
                            limits=as.Date(c(start.date,data.date)),
                            expand=c(0,0))

scaleDateFlex<-scale_x_date(date_breaks = "1 month", date_labels = "%b %Y",expand=c(0,0))
scaleDateFlexLess<-scale_x_date(date_breaks = "1 month", date_labels = "%b %Y",expand=c(0,0),
                                limits=c(fig.start.date, fig.end.date))

scaleMonthChar<-scale_x_discrete(breaks=c("2020-12","2021-03","2021-06","2021-09","2021-12","2022-03"),labels=c("Dec 2020","Mar 2021","Jun 2021","Sep 2021","Dec 2021","Mar 2022"))
```

## setup bootstraps and inputs, outputs
```{r}
#Input folders of trees
dir.exists(ft_trees)
#input trees 
trees.in.nex <- list.files(ft_trees, pattern="timetree.nex$",full.names = T) %>% mixedsort()
# trees.in.nex
if(length(trees.in.nex)<1) print("where are the trees??")

#boots aka trees to operate over
n.B<-length(trees.in.nex)
BOOTS<-1:n.B
print(paste("There are ",n.B," trees",sep=""))

#Input folders of ace output
dir.exists(ft_in)

#Input folders of input to lsd
dir.exists(ft_trees_pre)

# input DFs from ace
all.anc.in<-list.files(ft_in,pattern="all.anc.csv",full.names = T) %>% mixedsort() #for the internal transitions
# can.anc.in<-list.files(ft_in,pattern="can.anc.csv",full.names = T) %>% mixedsort()
sum.in<-list.files(ft_in,pattern="sublin.csv",full.names = T)  %>% mixedsort()
meta.in<-list.files(ft_in,pattern="meta.csv",full.names = T) %>% mixedsort()
can.states.in<-list.files(ft_in,pattern="tip.anc.csv",full.names = T) %>% mixedsort()
dates.in<-str_replace_all(trees.in.nex,ft_trees,ft_trees_pre) %>%
  str_replace_all(".fasta.timetree.nex","_dates.txt")
all(file.exists(dates.in))
all(file.exists(meta.in))

#check lengths
# length(can.states.in)==length(trees.in.nex)
length(meta.in)

##OUTPUTS
#main output directory 
sum.out<-str_replace_all(sum.in, ".sublin.csv",".sublin.firstCanDate.csv")
sing.out<-str_replace_all(can.states.in, "_mask.tip.anc.csv","_singletons.csv")

#sublineage epi plots
f.sublin.out<-paste(f.out,"/Sublin.Out",sep="")
if(!dir.exists(f.sublin.out)){dir.create(f.sublin.out)}

#add to summary file
cat(paste0("n.boots = ",n.B),
    paste0("folder.out = ",f.out),file=text.out,sep="\n",append=TRUE)
```

## setup summary functions
```{r}
# function to spit out mean and 95% CI (for small n, t-dsitribution) for a vector containing n observations/boots with X digits
mean.95ci.X<-function(vector, digits){
  n<-length(vector)
  m<-mean(vector)
  sd<-sd(vector)
  t<-qt(0.025,(n-1),lower.tail=F)
  up<-m+(sd/sqrt(n)*t)
  low<-m-(sd/sqrt(n)*t)
  return(paste(round(m,digits=digits), " (",round(low,digits=digits)," - ",round(up,digits=digits),")",sep=""))
}

#scientific notation, digits=x
mean.95ci.SC<-function(vector,digits){ 
  n<-length(vector)
  m<-mean(vector)
  sd<-sd(vector)
  t<-qt(0.025,(n-1),lower.tail=F)
  up<-m+(sd/sqrt(n)*t)
  low<-m-(sd/sqrt(n)*t)
  return(paste(formatC(m,format = "e", digits = digits), " (",
              formatC(low,format = "e", digits = digits)," - ",
              formatC(up,format = "e", digits = digits),")",sep=""))
}

mean.95ci.givenmsd<-function(m,sd,n, digits){
  t<-qt(0.025,(n-1),lower.tail=F)
  up<-m+(sd/sqrt(n)*t)
  low<-m-(sd/sqrt(n)*t)
  return(paste(round(m,digits=digits), " (",round(low,digits=digits)," - ",round(up,digits=digits),")",sep=""))
}

#upperCI only with X and N input
upper.ci.X<-function(vector, digits){ 
  n<-length(vector)
  m<-mean(vector,na.rm = T)
  sd<-sd(vector,na.rm = T)
  t<-qt(0.025,(n-1),lower.tail=F)
  up<-m+(sd/sqrt(n)*t)
  return(round(up,digits=digits))
}

#lowerCI only with X and N input
lower.ci.X<-function(vector, digits){
  n<-length(vector)
  m<-mean(vector,na.rm = T)
  sd<-sd(vector,na.rm = T)
  t<-qt(0.025,(n-1),lower.tail=F)
  low<-m-(sd/sqrt(n)*t)
  return(round(low,digits=digits))
}

#width of the CI
width.ci.X<-function(vector, digits){
  n<-length(vector)
  m<-mean(vector,na.rm = T)
  sd<-sd(vector,na.rm = T)
  t<-qt(0.025,(n-1),lower.tail=F)
  width<-2*(sd/sqrt(n)*t)
  return(round(width,digits=digits))
}

#as above, but for larger n using the normal distribution instead of t distribution
#upperCI only with X and N input
upper.ci.big<-function(vector, digits){ 
  n<-length(vector)
  m<-mean(vector,na.rm = T)
  sd<-sd(vector,na.rm = T)
  t<-qnorm(0.025,(n-1),lower.tail=F)
  up<-m+(sd/sqrt(n)*t)
  return(round(up,digits=digits))
}

#lowerCI only with X and N input
lower.ci.big<-function(vector, digits){
  n<-length(vector)
  m<-mean(vector,na.rm = T)
  sd<-sd(vector,na.rm = T)
  t<-qnorm(0.025,(n-1),lower.tail=F)
  low<-m-(sd/sqrt(n)*t)
  return(round(low,digits=digits))
}

#width of the CI
width.ci.big<-function(vector, digits){
  n<-length(vector)
  m<-mean(vector,na.rm = T)
  sd<-sd(vector,na.rm = T)
  t<-qnorm(0.025,(n-1),lower.tail=F)
  width<-2*(sd/sqrt(n)*t)
  return(round(width,digits=digits))
}

```

# Read in, clean, and merge dfs for each tree/subsample (individual boots)
```{r main chunk}
# read into lists of length trees.in
meta.boots<-replicate(n=n.B,vector()) 
cana.boots<-replicate(n=n.B,vector()) 
sum.boots<-replicate(n=n.B,vector())
sublin.long.unq<-replicate(n=n.B,vector())
dates.samp<-replicate(n=n.B,vector())

can.sing.boots<-replicate(n.B,vector())
can.tip.states.boots<-replicate(n.B,vector())

# make an object of provs
provs<-c("Quebec","Ontario","Alberta","British Columbia","Manitoba","Nova Scotia","New Brunswick","Newfoundland and Labrador","Saskatchewan")
provs.long<-paste("Canada",provs,sep="_")

k=1
# Loop across all trees of any
for (k in 1:n.B) {
  print(paste("Reading boot",k,sep=" "))  
  #### Read in objects from ancestralreconstruction.rmd ####
  sum.boots[[k]]<-read.csv(sum.in[k])
  meta.boots[[k]]<-read.csv(meta.in[k])
  dates.samp[[k]]<-read.table(dates.in[[k]],sep = "\t") #CHAGNE THIS FOR FUTURE
  colnames(dates.samp[[k]])<-c("tip.label","date.lsd.full")
  meta.boots[[k]]<-left_join(meta.boots[[k]],dates.samp[[k]],by="tip.label")
  
  #subset meta to cana only
  cana.boots[[k]]<-meta.boots[[k]] [str_which(meta.boots[[k]]$country, "Canada"),]
  
  #Rename provinces so Canada not in label
  sum.boots[[k]]$Node.Location<-sapply(sum.boots[[k]]$Node.Location, function (x) str_replace_all(x, "Canada_", ""))
  
  #make sure no "." instead of space 
  sum.boots[[k]]$Node.Location<-str_replace_all(sum.boots[[k]]$Node.Location, "\\.", " ")
  sum.boots[[k]]$Parent.Location<-str_replace_all(sum.boots[[k]]$Parent.Location, "\\.", " ")
  sum.boots[[k]]$Descendant.Location<-str_replace_all(sum.boots[[k]]$Descendant.Location, "\\.", " ")
  
  ## APPLY the lookup table to change names
  #Add fiji
  lookup.geo<-bind_rows(lookup.geo,data.frame(og.loc="Fiji",new.loc="Oceania"))
  ## GROUP together if applicable
  for (i in 1:nrow(lookup.geo)){
    if(lookup.geo$new.loc[i] != lookup.geo$og.loc[i]){ #if they don't match, replace 
      #find matches in node loc, and replace with new loc
      pr.ma<-which(sum.boots[[k]]$Node.Location==lookup.geo$og.loc[i])
      if (length(pr.ma)>0) {sum.boots[[k]]$Node.Location[pr.ma]<-lookup.geo$new.loc[i]; next}
      par.ma<-which(sum.boots[[k]]$Parent.Location==lookup.geo$og.loc[i])
      if (length(par.ma)>0) {sum.boots[[k]]$Parent.Location[par.ma]<-lookup.geo$new.loc[i]; next}
    }
  }
 
  #Remove any sublineages with >30000 descenndants, this is likely spurious
  biggie<-which(sum.boots[[k]]$Number.Descendants>30000)
  if(length(biggie)>0){
      sum.boots[[k]]<-sum.boots[[k]][-biggie,]
  }
  
  ## Make list of sublineages, where each one is a df in order to map descendants
  n.sl<-nrow(sum.boots[[k]])
  desc.df.list<-replicate(n=n.sl,vector())
  for (i in 1:n.sl){
    #name it by defining internal node
    names(desc.df.list)[[i]]<-sum.boots[[k]]$Node[i] 
    #extract accession ID (to lookup date in next chunk)
    accessions<-unlist(strsplit(sum.boots[[k]]$Descendant.AccessionID[i], ", "))
    #add each desc as a row in the df
    desc.df.list[[i]]<-data.frame(Lineage=sum.boots[[k]]$Lineage[i],
                                  Node=sum.boots[[k]]$Node[i], #use node to match back later
                                  Descendant.AccessionIDs=accessions,
                                  State=NA,
                                  Date=NA) 
  } 
  
  ## Look up each accession number for its sampling location and LSD-inferred date
  ## Also this fixes the mismatch issue between location and date
  for (i in 1:n.sl){
    # i=10
    metaRows<-match (desc.df.list[[i]]$Descendant.AccessionIDs, meta.boots[[k]]$GISAID_ID) # in order
    #extract location and dates
    desc.df.list[[i]]$State<-meta.boots[[k]]$state [metaRows]
    desc.df.list[[i]]$Date<-as.Date(meta.boots[[k]]$date.lsd.full[metaRows])
  }

  ## Add the LSD dates onto the sumboots object
  ## for each introduction, find the earliest sample collection date and where sampled
  sum.boots[[k]]$FirstCanDateLSD<-as.Date(NA)
  sum.boots[[k]]$FirstCanLocLSD<-NA
  sum.boots[[k]]$FirstCanGISAID<-NA 
  #repeat for lasts
  sum.boots[[k]]$LastCanDateLSD<-as.Date(NA)
  sum.boots[[k]]$LastCanLocLSD<-NA
  sum.boots[[k]]$LastCanGISAID<-NA 
    
  for (i in 1:nrow(sum.boots[[k]])){
    #list of desc is ordered same as sum.boot, subset to the descendants in Canada
    mtchCan<-desc.df.list[[i]] [str_detect(desc.df.list[[i]]$State, "Canada") ,]
    
    #order the subsetted dataframe by date
    mtchCan<-mtchCan[order(mtchCan$Date),]
    
    sum.boots[[k]]$FirstCanDateLSD[i]<-as.Date(first(mtchCan$Date))
    sum.boots[[k]]$FirstCanLocLSD[i]<-first(mtchCan$State)
    sum.boots[[k]]$FirstCanGISAID[i]<-first(mtchCan$Descendant.AccessionIDs)
    
    sum.boots[[k]]$LastCanDateLSD[i]<-as.Date(last(mtchCan$Date))
    sum.boots[[k]]$LastCanLocLSD[i]<-last(mtchCan$State)
    sum.boots[[k]]$LastCanGISAID[i]<-last(mtchCan$Descendant.AccessionIDs)
  }

  ## Name the sublineages ##
  #as Lineage.canX, where X is the order of first sample detection for a given lineage
  sum.boots[[k]]<-with(sum.boots[[k]],sum.boots[[k]][(order(sum.boots[[k]]$FirstCanDateLSD)),])
  
  #make a new column 
  sum.boots[[k]]$Sublineage<-NA 
  sublins<-c()
  for (i in 1:nrow(sum.boots[[k]])){
    subl<-paste(sum.boots[[k]]$Lineage[i],".can",sep="")
    ss<-0
    subl2<-str_replace_all(subl,"\\.","\\\\.") #weird R shit
    ss<-length(str_which(sublins,subl2)) #how many sublins already designated?
    sum.boots[[k]]$Sublineage[i]<-paste(subl,(ss+1),sep="")
    sublins<-c(sublins,subl)
  }

  ## ANOTHER sublinaege name that incorps the first gisaid id
  sum.boots[[k]]$Sublineage2<-NA 
  for (i in 1:nrow(sum.boots[[k]])){
    subl<-paste(sum.boots[[k]]$Lineage[i],".can.",sum.boots[[k]]$FirstCanGISAID[i],sep="")
    sum.boots[[k]]$Sublineage2[i]<-subl
  }
  #check unique
  length(sum.boots[[k]]$Sublineage2)==unique(length(sum.boots[[k]]$Sublineage2))

  ## Add sublineage back into the desc.df.list object, use the node column to matchy
  for (i in 1:length(desc.df.list)){
    match<-which(sum.boots[[k]]$Node== desc.df.list[[i]]$Node[1])
    desc.df.list[[i]]$Sublineage<-sum.boots[[k]]$Sublineage[match]
    desc.df.list[[i]]$Sublineage2<-sum.boots[[k]]$Sublineage2[match]
  }
   
  #rbind them all into one df to refer to later
  sublin.long<-bind_rows(desc.df.list) #sublin.long no longer a list, just a single df for
  
  #### Pull tmrca ####
  ## Find MRCA node in time tree linking the descendent accession IDs in each sublineage 
  tmrca.df<-data.frame(Node=sum.boots[[k]]$Node, #node in the binarized tree
                       mrca_nexus=NA, #mrca node in the non-binarized nexus tree with accurate dates
                       tmrca=NA, tmrca.dt=NA, tmrca.upper.dt=NA, tmrca.lower.dt=NA) #date format
  
  #pull information from the nexus tree (accurate dates, non-binarized)
  tree.boots.nex<-read.beast(trees.in.nex[k])
  td<-get.data(tree.boots.nex)
  tp<-get.tree(tree.boots.nex)
  rm(tree.boots.nex)
  
  #pull the root date as a decimal
  myroot<-decimal_date(as.Date(first(sort(td$date))))
    
  for (i in 1:nrow(tmrca.df)){
    #find tip labels matching any descendant ID in the sublineage
    tip.match.j<-str_which(tp$tip.label,
                           str_replace_all(sum.boots[[k]]$Descendant.AccessionID[i],
                                           ", ", "\\|"))
    mrca.j<-getMRCA(tp,tip.match.j)
    tmrca.df$mrca_nexus[i]<-mrca.j
    tmrca.j<-nodeheight(tp,mrca.j)
    tmrca.df$tmrca[i]<-tmrca.j #node height rel. to root
    
    #pull the TMRCA as a calendar date (mean)
    # TMRCA.dt<-td$date[td$node==mrca.j]
    # if(TMRCA.dt=="2020"|TMRCA.dt=="2021"|TMRCA.dt=="2022"){TMRCA.dt<-format(date_decimal(myroot+tmrca.j),"%Y-%m-%d")}
    # if(is.na(TMRCA.dt)){
    TMRCA.dt<-format(date_decimal(myroot+tmrca.j),"%Y-%m-%d")
      # }
    tmrca.df$tmrca.dt[i]<-TMRCA.dt
    
    # pull the confidence interval for TRMCA
    if(any(td$node==mrca.j)){
      if(!is.na(td$CI_date[td$node==mrca.j])){
        LOWER.dt<-unlist(td$CI_date[td$node==mrca.j])[1]
        tmrca.df$tmrca.lower.dt[i]<-LOWER.dt
        UPPER.dt<-unlist(td$CI_date[td$node==mrca.j])[2]
        if(UPPER.dt=="2021"){UPPER.dt<-as.Date(TMRCA.dt)}
        tmrca.df$tmrca.upper.dt[i]<-UPPER.dt
      }
    }
  }  #end of loop over i rows
  
  ## connect TMRCA back to sum.boots[[k]] object 
  # all(sum.boots[[k]]$Node %in% tmrca.df$Node)
  sum.boots[[k]]<-left_join(sum.boots[[k]],tmrca.df,by="Node")
  
  ## Any unrealistic TMRCAs? 
  too.early<-which(sum.boots[[k]]$tmrca.dt<"2020-09-15")
  # print(sum.boots[[k]]$Sublineage[too.early])
  if(length(too.early)>0){ #replace with the upper limit
    sum.boots[[k]]$tmrca.dt[too.early]<-sum.boots[[k]]$tmrca.upper.dt[too.early]
  }
  #remove sublinages taht are still too early
  still.too.early<-which(sum.boots[[k]]$tmrca.dt<"2020-09-15")
  if(length(still.too.early)>0){
    sum.boots[[k]]<-sum.boots[[k]][-still.too.early, ]
  }

  
  #make year-month a new column
  meta.boots[[k]]$yearmonth<-as.character(NA)
  for (i in 1:nrow(meta.boots[[k]])){
    meta.boots[[k]]$yearmonth[i]<-format(as.Date(meta.boots[[k]]$date.lsd.full[i]), "%Y-%m")
  }
  
  #yearmonth
  sum.boots[[k]]$yearmonth<-as.character(NA)
  for (i in 1:nrow(sum.boots[[k]])){
    sum.boots[[k]]$yearmonth[i]<-format(as.Date(sum.boots[[k]]$tmrca.dt[i]), "%Y-%m")
  }
  
  ## add back some information onto sublin.long from sum.boots
  add.on<-sum.boots[[k]][,c("Sublineage","Node.Location","tmrca.dt","tmrca.upper.dt","tmrca.lower.dt")]
  sublin.long<-left_join(sublin.long,add.on,by="Sublineage")

  # Consider some seqs have multiple sublineages - only take most recent sublin for unique desc 
  dupl.desc<-unique(sublin.long$Descendant.AccessionIDs[which(duplicated(sublin.long$Descendant.AccessionIDs ))]) #unique GISAID IDS that have duplicates (ie no duplicates of the duplicate IDs)
  l.d<-length(dupl.desc)
  dupz<-c()
  if(l.d<1){sublin.long.unq[[k]]<-sublin.long} #if no duplicates, they are unique
  if(l.d>0){ #if there are duplicates, 
    for (j in 1:l.d){ #iterate through dups, find matches, accumulate dups to remove
    matchy<-which(sublin.long$Descendant.AccessionIDs == dupl.desc[j]) #find all instances of the ID
    sublin.long$Sublineage[matchy] #redundant sublineage calls
    rec<-max(as.Date(sublin.long$tmrca.dt[matchy])) #find the most recent tmrca dt
    keep<-which(sublin.long$tmrca.dt[matchy]==rec) #keep the instance matching most recent tmrca, 
    if(length(keep)>1){ #if multiple equally recent tmrcas....
      #keep it in the smallest sublin, b/c more specific
      szs<-sum.boots[[k]]$N.Desc.glob[sum.boots[[k]]$Sublineage %in%
                                          sublin.long$Sublineage[matchy[keep]]]
      keep<-keep[which(szs==min(szs))]
    }
    dup<-matchy[-keep] #dup are all instances that we don't keep
    dupz<-c(dupz,dup) #add to running vector to remove
  }
  sublin.long.unq[[k]]<-sublin.long[-dupz, ]
  } #end of 'if dups'

  
 #note these have pre-lookup names ie Nova Scotia...
  provs.long2<-unique(meta.boots[[k]]$state[str_detect(meta.boots[[k]]$state,"Canada")])   
 
  ## Count the unique descendants global and canadian overall
  for (j in 1:nrow(sum.boots[[k]])){
    n.d.gl<-length(which(sublin.long.unq[[k]]$Sublineage==sum.boots[[k]]$Sublineage[j]))
    n.d.ca<-length(which(sublin.long.unq[[k]]$Sublineage==sum.boots[[k]]$Sublineage[j] &
                           sublin.long.unq[[k]]$State %in% provs.long2))
    sum.boots[[k]]$N.Desc.glob[j]<-n.d.gl
    sum.boots[[k]]$N.Desc.can[j]<-n.d.ca
  }
  # head(sum.boots[[k]][,c("Number.Descendants","N.Desc.glob","N.Desc.can")])
  
  #Need to UDPATE the first/last can date columns to reflect unique descendants
  for (i in 1:nrow(sum.boots[[k]])){
    #which sequences are unique descendants of the sublineage and sampled in Canada
    mtchCan<-sublin.long.unq[[k]] [which(sublin.long.unq[[k]]$Sublineage==sum.boots[[k]]$Sublineage[i] &
            sublin.long.unq[[k]]$State %in% provs.long2),]

    #order the subsetted dataframe by date
    mtchCan<-mtchCan[order(mtchCan$Date),]
    
    sum.boots[[k]]$FirstCanDateLSD[i]<-as.Date(first(mtchCan$Date))
    sum.boots[[k]]$FirstCanLocLSD[i]<-first(mtchCan$State)
    sum.boots[[k]]$FirstCanGISAID[i]<-first(mtchCan$Descendant.AccessionIDs)
    
    sum.boots[[k]]$LastCanDateLSD[i]<-as.Date(last(mtchCan$Date))
    sum.boots[[k]]$LastCanLocLSD[i]<-last(mtchCan$State)
    sum.boots[[k]]$LastCanGISAID[i]<-last(mtchCan$Descendant.AccessionIDs)
  }
  
  ## calculate the detection lag (FirstCanDate - tMRCA) using updated unique desc.
  sum.boots[[k]]<-sum.boots[[k]] %>% mutate(detection.lag = as.Date(FirstCanDateLSD) -as.Date(tmrca.dt))
  sum.boots[[k]]$detection.lag<-as.numeric(sum.boots[[k]]$detection.lag)
  sum.boots[[k]]$tmrca.dt<-as.Date(sum.boots[[k]]$tmrca.dt)
  if(any(sum.boots[[k]]$detection.lag<0)){  
    sum.boots[[k]]$tmrca.dt[sum.boots[[k]]$detection.lag<0]<-
      sum.boots[[k]]$tmrca.dt[sum.boots[[k]]$detection.lag<0] %m-% months(1)}
  
  #lower and upper detection lag (lower tmrca is a bigger lag)
     sum.boots[[k]]<-sum.boots[[k]] %>% mutate(detection.lag.upper = as.Date(FirstCanDateLSD) -as.Date(tmrca.upper.dt))
  sum.boots[[k]]$detection.lag.upper<-as.numeric(sum.boots[[k]]$detection.lag.upper)
  sum.boots[[k]]<-sum.boots[[k]] %>% mutate(detection.lag.lower = as.Date(FirstCanDateLSD) -as.Date(tmrca.lower.dt))
  sum.boots[[k]]$detection.lag.lower<-as.numeric(sum.boots[[k]]$detection.lag.lower)
  
  ## change the tmrcadt to something more likely if detection lag is negative or really big
  sum.boots[[k]]$tmrca.dt.likely<-sum.boots[[k]]$tmrca.dt
  sum.boots[[k]]$tmrca.lower.dt<-as.Date(sum.boots[[k]]$tmrca.lower.dt)
  sum.boots[[k]]$tmrca.upper.dt<-as.Date(sum.boots[[k]]$tmrca.upper.dt)

  
  for (i in 1:nrow(sum.boots[[k]])){
    if(sum.boots[[k]]$detection.lag[i]<0){sum.boots[[k]]$tmrca.dt.likely[i]<-sum.boots[[k]]$tmrca.lower.dt[i]}
    if(sum.boots[[k]]$detection.lag[i]>100){sum.boots[[k]]$tmrca.dt.likely[i]<-as.Date(sum.boots[[k]]$tmrca.upper.dt[i])+7}
  }
  sum.boots[[k]]<-sum.boots[[k]] %>% mutate(detection.lag.likely=as.Date(FirstCanDateLSD) -as.Date(tmrca.dt.likely))
  #replace these columns
  sum.boots[[k]]$tmrca.dt<-sum.boots[[k]]$tmrca.dt.likely
  sum.boots[[k]]$detection.lag<-sum.boots[[k]]$detection.lag.likely

  #apply lookup table on sublinlong.unq
  sublin.long.unq[[k]]$State<-str_replace_all(sublin.long.unq[[k]]$State, "Canada_","")
  
  #convert using lookup table
   for (i in 1:nrow(lookup.geo)){
      if(lookup.geo$new.loc[i] != lookup.geo$og.loc[i]){ 
        #if they don't match, go replace instances
        #find matches in node loc, and replace with new loc
        pr.ma<-which(sublin.long.unq[[k]]$State==lookup.geo$og.loc[i])
        if (length(pr.ma)>0) {sublin.long.unq[[k]]$State[pr.ma]<-lookup.geo$new.loc[i];
        next}
      }
   }
  ## Re-name the sublineages using only unique descendants in the Lin support
  # call lineage support with only unique descendants
  sum.boots[[k]]$LineageUnq<-NA
  sum.boots[[k]]$Lin.SupportUnq<-NA
  for (j in 1:nrow(sum.boots[[k]])){
    # epis<-unlist(strsplit(sum.boots[[k]]$Descendant.AccessionID[j],split=", "))
    episUnq<-sublin.long.unq[[k]]$Descendant.AccessionIDs [which(sublin.long.unq[[k]]$Sublineage==sum.boots[[k]][j,"Sublineage"])]
    t<-table(meta.boots[[k]]$Lineage [which(meta.boots[[k]]$GISAID_ID %in% episUnq)])
    all<-sum(t)
    t<-rev(sort(t)) #sort by most frequent
    des<-c()
    for (p in 1:length(t)){
      n<-paste(names(t)[p], ": ",round(t[p]/all*100,digits=2),"%",sep="")
      des<-c(des,n)
    }
    sum.boots[[k]]$Lin.SupportUnq[j]<-paste0(des,collapse="; ")
    sum.boots[[k]]$LineageUnq[j]<-names(rev(sort(t)))[1] 
  } # end of loop identifying new lin support
  
  #Name the sublineages based on the lineageunq, ordered by first sample date
  sum.boots[[k]]<-with(sum.boots[[k]],sum.boots[[k]][(order(sum.boots[[k]]$FirstCanDateLSD)),])
  sum.boots[[k]]$SublineageUnq<-NA 
  sublins<-c()
  for (j in 1:nrow(sum.boots[[k]])){
    subl<-paste(sum.boots[[k]]$LineageUnq[j],".can",sep="")
    ss<-0
    subl2<-str_replace_all(subl,"\\.","\\\\.") #weird R shit
    ss<-length(str_which(sublins,subl2)) #how many sublins already designated?
    sum.boots[[k]]$SublineageUnq[j]<-paste(subl,(ss+1),sep="")
    sublins<-c(sublins,subl)
  }
  #check
  sum.boots[[k]][which(sum.boots[[k]]$Sublineage != sum.boots[[k]]$SublineageUnq),c("Sublineage","SublineageUnq")]

  #after checking these, they make more sense. Converting old sublin name
  sublin.long.unq[[k]] <- sublin.long.unq[[k]] %>% 
    left_join(sum.boots[[k]][,c("Sublineage","SublineageUnq","LineageUnq")],
              by="Sublineage")
  sublin.long.unq[[k]]$Sublineage<-sublin.long.unq[[k]]$SublineageUnq
  sublin.long.unq[[k]]$Lineage<-sublin.long.unq[[k]]$LineageUnq

  sum.boots[[k]]$Sublineage<-sum.boots[[k]]$SublineageUnq
  sum.boots[[k]]$Lineage<-sum.boots[[k]]$LineageUnq
  sum.boots[[k]]$Lin.Support<-sum.boots[[k]]$Lin.SupportUnq
  
  #calculate sublienage longevity (first to last canadian sample date)
  #change: had previously been going to last sample overall, now focusing on Ca
  sum.boots[[k]]<- sum.boots[[k]] %>% mutate(longevitySample=LastCanDateLSD-FirstCanDateLSD,
                             longevityTMRCA=LastCanDateLSD-tmrca.dt)
  
  #add some colnames to this df
  if(!any(colnames(sublin.long.unq[[k]])=="FirstCanDateLSD")){
    sublin.long.unq[[k]]<-left_join(sublin.long.unq[[k]], sum.boots[[k]][,c("Sublineage", "FirstCanDateLSD", "LastCanDateLSD")],  by="Sublineage")
  }
  
  ## ANY unrealistic sizes?
  too.big<-which(sum.boots[[k]]$N.Desc.glob>15000)
  # if(length(too.big)>1){
  #   sum.boots[[k]]<-sum.boots[[k]][-too.big, ]
  # }
  print(c(length(too.big),length(still.too.early)))
  
 #write this for future use 
  write.csv(sum.boots[[k]], sum.out[k])

  ### SINGLETONS ###
# for (k in 1:n.B){
#   tree.boots.nex<-read.beast(trees.in.nex[k])
#   td<-get.data(tree.boots.nex)
#   tp<-get.tree(tree.boots.nex)
#   myroot<-decimal_date(as.Date(first(sort(td$date))))
  
  #all can tip's states
  can.tip.states.boots[[k]]<-read.csv(can.states.in[k])

  #join canadian metadata by tiplabel to can.tip.states.boots[[k]] 
  if (!"par.lik" %in% colnames(cana.boots[[k]])){ #this is a check to make sure don't do it twice
    cana.boots[[k]]<-left_join(cana.boots[[k]],can.tip.states.boots[[k]],by="tip.label")
  }

  #change names
  cana.boots[[k]]$par.state<-str_replace_all(cana.boots[[k]]$par.state,"Canada_","")
  cana.boots[[k]]$tip.state<-str_replace_all(cana.boots[[k]]$tip.state,"Canada_","")
  
  ##def'n of singleton: tips with non-Canadian origin; can be inside a sublineage
  can.sing.boots[[k]]<-cana.boots[[k]][which(!cana.boots[[k]]$par.state %in% provs),]
  
  ## add TMRCA dt to singletons
  can.sing.boots[[k]]$tmrca.dt<-as.Date(NA)
  for (i in 1:nrow(can.sing.boots[[k]])){
    tip.match.j<-str_which(tp$tip.label, can.sing.boots[[k]]$tip.label[i])
    mrca.j<-getParent(tp,tip.match.j)
    tmrca.j<-nodeheight(tp,mrca.j)
    TMRCA.dt<-format(date_decimal(myroot+tmrca.j),"%Y-%m-%d")
    can.sing.boots[[k]]$tmrca.dt[i]<-TMRCA.dt
  }
  #make a halfway b/w tmrcadt and sample date
  ### THIS IS ACTUALLY 3/5 NOW, b/c was biasing too early
  can.sing.boots[[k]]$date.lsd.full<-as.Date(can.sing.boots[[k]]$date.lsd.full)
  can.sing.boots[[k]]<-mutate(can.sing.boots[[k]],tmrca.dt.half=
                                tmrca.dt+(((date.lsd.full-tmrca.dt)/10)*9), 
                              .keep=T)
  can.sing.boots[[k]]$yearmonth.half<-format(can.sing.boots[[k]]$tmrca.dt.half, "%Y-%m")
  
  #write for future use
  write.csv(can.sing.boots[[k]], sing.out[k])
  
} #end of k loop across bootstraps

```

## Make lineage colors based on what is in the meta
```{r}
#function to check colors in a vector
colortest<-function(vector){
  n<-length(vector)
  return(plot(1:n,1:n,col=vector,pch=15))
}

## copy meta and sum boots
meta.b1<-meta.boots[[1]]
sum.b1<-sum.boots[[1]]

#### make lineage colors #####
print('making lineage color scheme')

#identify lineages that were found in Canada
linz<-unique(meta.b1$Lineage[meta.b1$country=="Canada"])
linz2<-unique(sum.boots[[1]]$Lineage) #check if any extras
if(any(!linz2 %in% linz)){ #if any extras found in sum.boots(possible if predominant called-lineage)in the clade is not the one sampled in canada
  linz<-unique(c(linz,linz2))
}
n.linz<-length(linz)

## sort out aliases in new table
aliases<-data.frame(lineage=linz, alias=NA)
if(any(is.na(aliases$lineage))){
  aliases<-aliases[-which(is.na(aliases$lineage)),]
}
# nrow(aliases)

#if A.* or B.*, then no alias
for (i in 1:nrow(aliases)){
  if (aliases$lineage[i]=="A"|aliases$lineage[i]=="B") {
    aliases$alias[i]<-aliases$lineage[i];next}
  if(str_detect(aliases$lineage[i],"B\\.")){aliases$alias[i]<-aliases$lineage[i];next}
  if(str_detect(aliases$lineage[i],"A\\.")){aliases$alias[i]<-aliases$lineage[i];next}
}

#find patterns
sh<-which(is.na(aliases$alias))
prefixes<-c()
for (i in sh){
  pre<-first(unlist(strsplit(aliases$lineage[i],"\\.")))
  prefixes<-c(prefixes,pre)
}
prefixes<-unique(prefixes)

#could add more here - make exhaustive
pref.exch<-c("AE\\." = "B.1.1.306.",
             "AL\\." = "B.1.1.231.",
             "AY\\." = "B.1.617.2.",
             "AZ\\." = "B.1.1.318.",
             "C\\." = "B.1.1.1.",
             "P\\." = "B.1.1.28.",
             "Q\\." = "B.1.1.7.", #changed a mistake here - need to apply to all scripts
             "R\\." = "B.1.1.316.")

#lookup aliases by prefix
if(length(sh)>0){
  al.sh<-aliases[sh,]
  al.sh$alias<-as.vector(al.sh$lineage) %>% str_replace_all(pref.exch)                                                  
  #join back onto aliases
  aliases[sh,]<-al.sh  
}

# aliases
## test to see if all lineages have an alias
if(any(!is.na(aliases$alias))){print("All lineages have an alias, go you.")} else
{print("add more aliases, foo")}#should be true

#order numerically
aliases<-aliases[with(aliases, order(aliases$alias)),]
#add lineage group and color
aliases$group<-NA
aliases$col<-NA

#assign parent type/lineage group
for (i in 1:nrow(aliases)){
  if(str_detect(aliases$alias[i],"B.1.1\\.")){ty<-"B.1.1"} else
  {if(str_detect(aliases$alias[i],"B\\.")){ty<-"B.1"} else
    if(str_detect(aliases$alias[i],"A\\.")){ty<-"A"} }
  aliases$group[i]<-ty
}

#all lineages within the variant
id.varsub<-str_which(aliases$alias,focal.pango) 
#some general rules
if (length(id.varsub)>1){
  varsubcol<-rev(colorRampPalette(brewer.pal(n=9, "BuGn")[4:9])(length(id.varsub))) 
}
if(length(id.varsub)==1){
  varsubcol<-focal.col
}

#delta colors
if(focal.var=="delta"){
  # custom ordering for AY.
  #deltas first (includ b.1.617.1 even though technically not delta)
  ay.id<-str_which(aliases$lineage,"AY")
  ay.ord<-names(sort(sapply(aliases$lineage[ay.id], function(x)
    as.numeric(unlist(str_split(x,"\\."))[2]))))
  ay.id<-ay.id[match(ay.ord, aliases$lineage[ay.id])]
  id.varsub<-c(id.varsub[1],ay.id) #keep b.1.617.2
  aliases<-aliases[id.varsub,] #re-order aliases this way
  
  #viridis schme
  # library(colourvalues)
  # varsubcol<-colour_values(1:nrow(aliases[id.varsub,]),palette = "viridis")
  
  #green scheme
  varsubcol<-rev(colorRampPalette(brewer.pal(n=9, "BuGn")[4:9])(length(id.varsub)))
  
  # aliases$col.vir[-id.varsub]<-colour_values(1:nrow(aliases[-id.varsub,]), palette = "plasma")
}

aliases$col<-varsubcol
colortest(aliases$col)

#export a tsv of name, alias, and hex color
write.table(aliases,paste(f.out,"lineagecolors.tsv",sep=""),sep="\t",row.names=T)

## make color scheme
lin.colz<-aliases$lineage
linPalette.ch<-as.character(aliases$col)
# linPalette.ch<-as.character(aliases$col)
names(linPalette.ch)<-lin.colz
LinColScale<-scale_colour_manual(name = "Location",values =linPalette.ch,na.value="grey60")
LinFillScale<-scale_fill_manual(name = "Location",values = linPalette.ch,na.value="grey60")

## Test colz
k=1
ggplot(sum.boots[[k]])+
  geom_point(aes(x=1:nrow(sum.boots[[k]]), y=1:nrow(sum.boots[[k]]), color=Lineage))+
  LinColScale+
  theme(legend.position = "none")
```

# overall number of sublins, descendants
```{r}
## export these into the text files

#number of sublins
sublin.tot<-c()
for (k in 1:n.B){
  sublin.tot<-c(sublin.tot,nrow(sum.boots[[k]]))
}
cat(paste0('Mean (95%CI) # of sublins = ',
       mean.95ci.X(sublin.tot,0)), 
    file=text.out,sep="\n",append=T)

# number unique pango lineages
un.lins<-c()
for (k in 1:n.B){
    un.lins<-c(un.lins, length(unique(sum.boots[[k]]$Lineage)))
  }

cat(paste0('Mean (95%CI) # of unique pango lins = ',
       mean.95ci.X(un.lins) ), 
    file=text.out,sep="\n",append=T)
#ALL DESC
desc.tot<-c()
for (k in 1:n.B){
  desc<-length(unique(sublin.long.unq[[k]]$Descendant.AccessionIDs))
  desc.tot<-c(desc.tot,desc)
}
cat(paste0('Mean (95%CI) # of descendants = ',
       mean.95ci.X(desc.tot,0)), 
    file=text.out,sep="\n",append=T)

#INTERNATIONAL DESC
desc.global.tot<-c()
for (k in 1:n.B){
  desc<-length(unique(sublin.long.unq[[k]]$Descendant.AccessionIDs [!sublin.long.unq[[k]]$State %in% provs]))
  desc.global.tot<-c(desc.global.tot,desc)
}
cat(paste0('Mean (95%CI) # of intl descendants = ',
       mean.95ci.X(desc.global.tot,0) ), 
    file=text.out,sep="\n",append=T)

#CANADIAN DESC
desc.can.tot<-c()
for (k in 1:n.B){
  desc<-length(unique(sublin.long.unq[[k]]$Descendant.AccessionIDs [sublin.long.unq[[k]]$State %in% provs]))
  desc.can.tot<-c(desc.can.tot,desc)
}
cat(paste0('Mean (95%CI) # of Can descendants = ',
       mean.95ci.X(desc.can.tot,0)  ), 
    file=text.out,sep="\n",append=T)

#look at tables of parental location
sort(table(sum.boots[[k]]$Parent.Location),decreasing = T)
range(sum.boots[[k]]$tmrca.dt,na.rm=T) #2020-12-04 to 2021-10-05

#sublins by location
sublin.focal.source<-c()
for (k in 1:n.B){
  x<-sum.boots[[k]] %>%
    filter(Parent.Location%in%focal.source) %>%
    nrow()
  sublin.focal.source<-c(sublin.focal.source,x)}

cat(paste0('Mean (95% CI) # of ', focal.source.brf, '-origin variant sublineages = ',
       mean.95ci.X(sublin.focal.source,0) ), 
    file=text.out,sep="\n",append=T)

cat(paste0('Percent of ', focal.source.brf, '-origin variant sublineages = ',
       round((mean(sublin.focal.source)/mean(sublin.tot)*100),digits=1)  ), 
    file=text.out,sep="\n",append=T)

## HOW Many seqs were there from the focal source in the global context seqs
focal.seq<-c()
for (i in 1:length(sum.boots)){
  focal<-length(which(meta.boots[[i]]$country%in%focal.source))
  intl<-length(which(meta.boots[[i]]$country!="Canada"))
  focal.seq<-c(focal.seq,focal/intl*100)
}

cat(paste0("% of intl sequences from ",focal.source,": ",mean.95ci.X(focal.seq,1)),
    file=text.out,sep="\n",append=T)

#sublineage from USA
sublin.usa<-c()
for (k in 1:n.B){
  x<-sum.boots[[k]] %>%
    filter(Parent.Location=="USA") %>%
    nrow()
  sublin.usa<-c(sublin.usa,x)}
cat(paste0('Mean (95% CI) # of USA-origin variant sublineages = ',
      mean.95ci.X(sublin.usa,0) ), 
    file=text.out,sep="\n",append=T)
cat(paste0('Percent of USA-origin variant sublineages = ',
      round((mean(sublin.usa)/mean(sublin.tot)*100 ),digits=2) ), 
    file=text.out,sep="\n",append=T)

## HOW Many seqs were there from the usa in the global context seqs
usa.seq<-c()
for (i in 1:length(sum.boots)){
  usa<-length(which(meta.boots[[i]]$country=="USA"))
  intl<-length(which(meta.boots[[i]]$country!="Canada"))
  usa.seq<-c(usa.seq,usa/intl*100)
}

cat(paste0("% of intl sequences from ","USA",": ",mean.95ci.X(usa.seq,1)),
    file=text.out,sep="\n",append=T)

## IF there was a variant-specific intervention (specified above)...
if(int.yn==T){
  #how many sublineages introduced before intervention
  sublin.preban<-c()
  for (k in 1:n.B){
    x<-length(which(sum.boots[[k]]$tmrca.dt<as.Date(int.start)))
    sublin.preban<-c(sublin.preban,x)}
  cat(paste0('Mean (95%CI) # of sublins pre-intervention = ',
       mean.95ci.X(sublin.preban,0) ), 
    file=text.out,sep="\n",append=T)
  
  #how many sublineages introduced before intervention from focal
  sublin.preban1<-c()
  for (k in 1:n.B){
    x<-length(which(sum.boots[[k]]$tmrca.dt<as.Date(int.start) &
                      sum.boots[[k]]$Parent.Location %in%focal.source))
    sublin.preban1<-c(sublin.preban1,x) }
   cat(paste0('Mean (95%CI) # of sublins pre-intervention from focal = ',
         mean.95ci.X(sublin.preban1,0)  ), 
    file=text.out,sep="\n",append=T) 
   
  ## What proportion of sublins from focal before the ban
  sublin.preban.prop<-c()
  for (k in 1:n.B){
    x<-length(which(sum.boots[[k]]$tmrca.dt<as.Date(int.start) &
                      sum.boots[[k]]$Parent.Location %in%focal.source))
    y<-length(which(sum.boots[[k]]$tmrca.dt<as.Date(int.start)))
    prop<-x/y
    sublin.preban.prop<-c(sublin.preban.prop, prop) }
  cat(paste0('Proportion of sublins pre-intervention from focal = ',
         mean.95ci.X(sublin.preban.prop,2)  ), 
  file=text.out,sep="\n",append=T) 
   
  #DURING BAN
  sublin.duringban<-c()
  for (k in 1:n.B){
    x<-length(which(sum.boots[[k]]$tmrca.dt>=as.Date(int.start) &
                    sum.boots[[k]]$tmrca.dt<as.Date(int.end)  ))
    sublin.duringban<-c(sublin.duringban,x)}
   cat(paste0('Mean (95%CI) # of sublins during intervention = ',
        mean.95ci.X(sublin.duringban,0) ), 
    file=text.out,sep="\n",append=T) 
  
  #DURING BAN from focal.source
  sublin.duringban1<-c()
  for (k in 1:n.B){
    x<-length(which(sum.boots[[k]]$tmrca.dt>=as.Date(int.start) &
                    sum.boots[[k]]$tmrca.dt<as.Date(int.end) &
                      sum.boots[[k]]$Parent.Location %in%focal.source))
    sublin.duringban1<-c(sublin.duringban1,x) }
   cat(paste0('Mean (95%CI) # of sublins during intervention from focal = ',
         mean.95ci.X(sublin.duringban1,0)  ), 
    file=text.out,sep="\n",append=T) 
   
   #proportion of sublin during ban from focal
    sublin.durban.prop<-c()
    for (k in 1:n.B){
    x<-length(which(sum.boots[[k]]$tmrca.dt>=as.Date(int.start) &
                    sum.boots[[k]]$tmrca.dt<as.Date(int.end) &
                      sum.boots[[k]]$Parent.Location %in%focal.source))
    y<-length(which(sum.boots[[k]]$tmrca.dt>=as.Date(int.start) &
                    sum.boots[[k]]$tmrca.dt<as.Date(int.end) ))
    prop<-x/y
    sublin.durban.prop<-c(sublin.durban.prop, prop) }
   cat(paste0('Proportion of sublins during-intervention from focal = ',
         mean.95ci.X(sublin.durban.prop,2)  ), 
    file=text.out,sep="\n",append=T) 
   
   
  #AFTER BAN
  sublin.afterban<-c()
  for (k in 1:n.B){
    x<-length(which(sum.boots[[k]]$tmrca.dt>=as.Date(int.end)  ))
    sublin.afterban<-c(sublin.afterban,x)}
    cat(paste0('Mean (95%CI) # of sublins after intervention = ',
           mean.95ci.X(sublin.afterban,0)  ), 
    file=text.out,sep="\n",append=T) 
    
  #AFTER BAN from focal.source
  sublin.afterban1<-c()
  for (k in 1:n.B){
    x<-length(which(sum.boots[[k]]$tmrca.dt>=as.Date(int.end)  &
                      sum.boots[[k]]$Parent.Location %in%focal.source))
    sublin.afterban1<-c(sublin.afterban1,x)}
  cat(paste0('Mean (95%CI) # of sublins after intervention = ',
          mean.95ci.X(sublin.afterban1,0) ), 
    file=text.out,sep="\n",append=T) 
  
  #proportion of sublin after ban form focal
  sublin.afterban.prop<-c()
    for (k in 1:n.B){
    x<-length(which(sum.boots[[k]]$tmrca.dt>=as.Date(int.end) &
                      sum.boots[[k]]$Parent.Location %in%focal.source))
    y<-length(which(sum.boots[[k]]$tmrca.dt>=as.Date(int.end) ))
    prop<-x/y
    sublin.afterban.prop<-c(sublin.afterban.prop, prop) }
   cat(paste0('Proportion of sublins post-intervention from focal = ',
         mean.95ci.X(sublin.afterban.prop,2)  ), 
    file=text.out,sep="\n",append=T) 
   
  ###Fold change in proportion focal pre vs during
  sublin.fc.prop<-c()
  for (k in 1:n.B){
    x<-sublin.preban.prop[k]
    y<-sublin.durban.prop[k]
    fc<-x/y #if pre=0.5 and during=0.1, 0.5/0.1 = 5-fold reduction 
    sublin.fc.prop<-c(sublin.fc.prop, fc) }
  cat(paste0('Fold reduction in proportion of sublins pre vs during-intervention from focal = ',
       mean.95ci.X(sublin.fc.prop,2)  ), 
  file=text.out,sep="\n",append=T) 

  
} #end of if loop for int.yn=T


```

## closer look at the biggest sublineage 
```{r}
biggest.sub<-c() #all have diff first case
for(k in 1:n.B){
  biggest.sub<-c(biggest.sub,
                 sum.boots[[k]]$Sublineage2[which(sum.boots[[k]]$Number.Descendants==
                                                   max(sum.boots[[k]]$Number.Descendants))])
}
biggest<-first(names(sort(table(biggest.sub),decreasing = T)))

#simpler sublin name
biggest.sub.sh<-c()
for(k in 1:n.B){
  biggest.sub.sh<-c(biggest.sub.sh, sum.boots[[k]]$Sublineage[which(sum.boots[[k]]$Sublineage==biggest.sh)])
}
biggest.sh<-first(names(sort(table(biggest.sub.sh),decreasing = T)))
#this name is more variable across boots

#origin location
og.loc<-c()
for (k in 1:n.B){
  x<-sum.boots[[k]]$Parent.Location[sum.boots[[k]]$Sublineage==biggest.sh]
  og.loc<-c(og.loc,x)}
og.loc.tab<-as.data.frame(table(og.loc) )
og.loc.tab<-og.loc.tab[with(og.loc.tab,order(og.loc.tab$Freq,decreasing = T)),]
og.loc.tab<-og.loc.tab%>% mutate(Perc=Freq/n.B*100)

#likelihood of origin
og.lik<-c()
for (k in 1:n.B){
  x<-sum.boots[[k]]$Parent.Likelihood[sum.boots[[k]]$Sublineage==biggest.sh]
  og.lik<-c(og.lik,x)}

#calculate the mean lik for each origin location
og.loc.tab$MeanLik<-NA
for(i in 1:nrow(og.loc.tab)){
  og.loc.tab$MeanLik[i]<-mean(og.lik[which(og.loc==og.loc.tab$og.loc[i]) ])
}
og.loc.tab<-og.loc.tab %>% mutate(SupportLik=MeanLik*Perc/100)

#TMRCA
og.tmrca<-c()
for (k in 1:n.B){
  x<-sum.boots[[k]]$tmrca.dt[sum.boots[[k]]$Sublineage==biggest.sh]
  og.tmrca<-c(og.tmrca,as.character(x))}
mean.95ci.X(as.Date(og.tmrca)) #""2021-02-03 (2021-02-01 - 2021-02-06)"

#first can sample date
og.first<-c()
for (k in 1:n.B){
  x<-sum.boots[[k]]$FirstCanDateLSD[sum.boots[[k]]$Sublineage==biggest.sh]
  og.first<-c(og.first,as.character(x))}
mean.95ci.X(as.Date(og.first)) #"2021-06-29 (2021-06-20 - 2021-07-09)"

#introduced to:
dest.loc<-c()
for (k in 1:n.B){
  x<-sum.boots[[k]]$Node.Location[sum.boots[[k]]$Sublineage==biggest.sh]
  dest.loc<-c(dest.loc,x)}
dest.loc.tab<-as.data.frame(table(dest.loc) )#focal.source 7, europe 3
dest.loc.tab<-dest.loc.tab[with(dest.loc.tab,order(dest.loc.tab$Freq,decreasing = T)),]
dest.loc.tab<-dest.loc.tab%>% mutate(Perc=Freq/n.B*100)

#likelihood of dest
dest.lik<-c()
for (k in 1:n.B){
  x<-sum.boots[[k]]$Node.Likelihood[sum.boots[[k]]$Sublineage==biggest.sh]
  dest.lik<-c(dest.lik,x)}
# mean.95ci.X(dest.lik,2)
dest.loc.tab$MeanLik<-NA
for(i in 1:nrow(dest.loc.tab)){
  dest.loc.tab$MeanLik[i]<-mean(dest.lik[which(dest.loc==dest.loc.tab$dest.loc[i]) ])
}
dest.loc.tab<-dest.loc.tab %>% mutate(SupportLik=MeanLik*Perc/100)

#lienage support (% lineage composition) - hard to average across boots
sum.boots[[k]]$Lin.Support[sum.boots[[k]]$Sublineage==biggest.sh]
sum.boots[[k]]$Descendant.Location[sum.boots[[k]]$Sublineage==biggest.sh]

#detection lag
det.lag<-c()
for (k in 1:n.B){
  x<-sum.boots[[k]]$detection.lag[sum.boots[[k]]$Sublineage==biggest.sh]
  det.lag<-c(det.lag,x)}
mean.95ci.X(det.lag,2)

#number desec
num.des<-c()
for (k in 1:n.B){
  x<-sum.boots[[k]]$N.Desc.glob[sum.boots[[k]]$Sublineage==biggest.sh]
  num.des<-c(num.des,x)}
mean.95ci.X(num.des,0) 

#number desc can
num.des.c<-c()
for (k in 1:n.B){
  x<-sum.boots[[k]]$N.Desc.can[sum.boots[[k]]$Sublineage==biggest.sh]
  num.des.c<-c(num.des.c,x)}
mean.95ci.X(num.des.c,0) 

#what were the lineages of the first members in Canada
first.lin.can<-c()
for(k in 1:n.B){
  first<-first(sort(sublin.long.unq[[k]]$Date[sublin.long.unq[[k]]$Sublineage2==biggest]))
  lin<-sublin.long.unq[[k]]$Lineage[which(sublin.long.unq[[k]]$Sublineage2==biggest &
                                       sublin.long.unq[[k]]$Date == first)]
  first.lin.can<-c(first.lin.can,lin)
}
table(first.lin.can) #suggests it was p.1.14 before it came to can

#how many USA desc
us.desc<-c()
for(k in 1:n.B){
  x<-length(which(sublin.long.unq[[k]]$Sublineage2==biggest &
                 sublin.long.unq[[k]]$State=="USA"))
  us.desc<-c(us.desc,x)
}
mean.95ci.X(us.desc,0) 

focal.source.desc<-c()
for(k in 1:n.B){
  x<-length(which(sublin.long.unq[[k]]$Sublineage2==biggest &
                 sublin.long.unq[[k]]$State%in%focal.source))
  focal.source.desc<-c(focal.source.desc,x)
}
mean.95ci.X(focal.source.desc,0)

#what about if we pull unique gisaid IDs found in any of the sublin long for thsi sublin? How many desc
all.desc_biggest<-sublin.long.unq[[1]][sublin.long.unq[[1]]$Sublineage2==biggest,] #start with these
for(k in 2:n.B){
  #if unique, add to the data.frame
  df<-sublin.long.unq[[k]][sublin.long.unq[[k]]$Sublineage2==biggest,]
  new<-which(!df$Descendant.AccessionIDs %in% all.desc_biggest$Descendant.AccessionIDs)
  if(length(new>0)){
    all.desc_biggest<-bind_rows(all.desc_biggest,df[new,])
  }
}
nrow(all.desc_biggest) #1231

# length(unique(all.desc_biggest$Descendant.AccessionIDs))
sort(table(all.desc_biggest$State))
(sort(all.desc_biggest$Date))[1]
last(sort(all.desc_biggest$Date))
all.desc_biggest$State[all.desc_biggest$Date==(sort(all.desc_biggest$Date))[1]]
all.desc_biggest$Lineage[all.desc_biggest$Date==(sort(all.desc_biggest$Date))[1]]

## EXPORT this info
cat(paste0("Biggest sublineage = ",biggest), 
    paste0("Biggest sublineage, short = ",biggest.sh), 
    paste0("Most likely origin: ",og.loc.tab$og.loc[1],
           ", % support: ",round(og.loc.tab$Perc[1],2),
            ", Mean lik: ",round(og.loc.tab$MeanLik[1],2),
            ", Support*lik: ",round(og.loc.tab$SupportLik[1],2)),
    paste0("Origin TMRCA mean (95%CI): ", mean.95ci.X(as.Date(og.tmrca)) ),
    paste0("First sample in Can, mean (95%CI): ", mean.95ci.X(as.Date(og.first))),
    paste0("Most likely destination: ",dest.loc.tab$dest.loc[1],
           ", % support: ",round(dest.loc.tab$Perc[1],2),
            ", Mean lik: ",round(dest.loc.tab$MeanLik[1],2),
            ", Support*lik: ",round(dest.loc.tab$SupportLik[1],2)),
    paste0("Detection lag [days]: ", mean.95ci.X(det.lag,2)),
    paste0("Number desc in boot: ", mean.95ci.X(num.des,0) ),
    paste0("Number desc in boot in Can: ", mean.95ci.X(num.des.c,0) ),
    paste0("Number desc in boot in US: ", mean.95ci.X(us.desc,0) ),
    paste0("Number desc in boot in focal source: ", mean.95ci.X(focal.source.desc,0)),
    paste0("n unique desc across boots: ", nrow(all.desc_biggest)),
    file=text.out, append=T,sep="\n")
```

# Sublineage summaries: Alluvial, mosaic, sizes
## summarize the total number and percent of sublins by 1) par. loc, 2) prov of intro, 3) lineage, 4) period
```{r}
#prep list item
sum.Par.Prov.l<-replicate(n.B,vector())

#go through each list item/subsample
## tabulate instances of location pairs
for (k in 1:n.B){
  sum.Par.Prov.l[[k]]<-sum.boots[[k]] %>% dplyr::group_by (Parent.Location, Node.Location) %>% dplyr::summarize (.groups="rowwise", n.Par= n()) %>% as.data.frame() %>% mutate(perc.Par=(n.Par/sum(n.Par))*100)

  ## add a column for subsample
  sum.Par.Prov.l[[k]]$SampleSet<-paste("Sample",BOOTS[k])

}

## rbind the summaries
sum.Par.Prov<-bind_rows(sum.Par.Prov.l) 

#summarize the mean and range for each of 1), 2) and 3)
sum.Par.Prov.summary<-sum.Par.Prov %>% dplyr::group_by(Parent.Location, Node.Location) %>%
  dplyr::summarize(.groups="rowwise",
                   mean.n=round(mean(n.Par)),
                   sd.n=round(sd(n.Par,na.rm=T),digits=2),
                   mean.perc=round(mean(perc.Par),digits=2),
                   sd.perc=round(sd(perc.Par,na.rm=T),digits=2)) %>%
  as.data.frame()

tot.Par<-sum.Par.Prov.summary %>% dplyr::group_by(Parent.Location) %>%
  dplyr::summarise(.groups = "rowwise", totalImports=sum(mean.perc)) %>%
  as.data.frame()

## Alluvial plot for Figure 2
#make a "subject column"
sum.Par.Prov.summary$subject<-1:nrow(sum.Par.Prov.summary)
# sum.Par.Prov.summary<-sum.Par.Prov.summary[-which(sum.Par.Prov.summary$mean.n<1),]

#order the geos
ord.count<-sum.Par.Prov.summary%>% dplyr::group_by(Parent.Location) %>%
  dplyr::summarise(.groups="rowwise",n=sum(mean.perc)) %>% as.data.frame()
ord.count<-ord.count[rev(order(ord.count$n)),'Parent.Location']
sum.Par.Prov.summary$Parent.Location<-factor(sum.Par.Prov.summary$Parent.Location,levels=ord.count)

ord.prov<-sum.Par.Prov.summary%>% dplyr::group_by(Node.Location) %>%
  dplyr::summarise(.groups="rowwise",n=sum(mean.perc)) %>% as.data.frame()
ord.prov<-ord.prov[rev(order(ord.prov$n)),'Node.Location']
sum.Par.Prov.summary$Node.Location<-factor(sum.Par.Prov.summary$Node.Location,levels=ord.prov)


#make it long
sum.Par.Prov.summary.long<-sum.Par.Prov.summary %>% pivot_longer(1:2, names_to = "geo.type", values_to = "geo")
#order the geo types
sum.Par.Prov.summary.long$geo.type<-factor(sum.Par.Prov.summary.long$geo.type,levels=c("Parent.Location","Node.Location"),labels=c("Origin","Destination"))

# sum.Par.Prov.summary.long$geo[which(!sum.Par.Prov.summary.long$geo %in% names(globalPalette.ch))]

#BECAUSE now showing a percent, rescale to equal 100 (means might not sum to 100)
sum.Par.Prov.summary.long$metric<-sum.Par.Prov.summary.long$mean.perc
matchy.origin<-which(sum.Par.Prov.summary.long$geo.type=="Origin")
sum.origin<-sum(sum.Par.Prov.summary.long$mean.perc[matchy.origin])
sum.Par.Prov.summary.long$metric[matchy.origin]<-sum.Par.Prov.summary.long$mean.perc[matchy.origin]/sum.origin*100
# sum(sum.Par.Prov.summary.long$metric[matchy.origin]) #should be 100
matchy.prov<-which(sum.Par.Prov.summary.long$geo.type=="Destination")
sum.prov<-sum(sum.Par.Prov.summary.long$mean.perc[matchy.prov])
sum.Par.Prov.summary.long$metric[matchy.prov]<-sum.Par.Prov.summary.long$mean.perc[matchy.prov]/sum.prov*100
# sum(sum.Par.Prov.summary.long$metric[matchy.prov]) 

```

## Alluvial plot: sublineages
```{r}
P1<- ggplot(sum.Par.Prov.summary.long,
       aes(x = geo.type, stratum = geo, alluvium = subject,
           y = metric,
           fill = geo, label = geo)) +
  scale_x_discrete(expand = c(0.01,0.01)) +
  scale_y_continuous(expand = c(0,0)) +
  geom_flow(alpha = 0.6,width=0.45) +
  geom_stratum(alpha = 0.9,width=0.45) +
  geom_text(stat = "stratum", size = 3.4,min.y=1,fontface="bold") +
  pubTheme+
  theme(legend.position = "none", axis.line = element_blank(), text =element_text(size=14),
        axis.ticks.x = element_blank(),axis.text.x = element_text(hjust=c(0.5,0.5)))+
  labs(x=NULL,y=paste0("% sublineages"))+
  GlobFillScale
P1
ggsave(paste(f.out,"Alluvial.percent.Parent.Node.png",sep=""),height=5,width=5,units="in")

P1.count<- ggplot(sum.Par.Prov.summary.long,
       aes(x = geo.type, stratum = geo, alluvium = subject,
           y = mean.n,
           fill = geo, label = geo)) +
  scale_x_discrete(expand = c(0.01,0.01)) +
  scale_y_continuous(expand = c(0,0)) +
  geom_flow(alpha = 0.6,width=0.45) +
  geom_stratum(alpha = 0.9,width=0.45) +
  geom_text(stat = "stratum", size = 3.4,min.y=1,fontface="bold") +
  pubTheme+
  theme(legend.position = "none", axis.line = element_blank(), text =element_text(size=14),
        axis.ticks.x = element_blank(),axis.text.x = element_text(hjust=c(0.5,0.5)))+
  labs(x=NULL,y=paste0("# sublineages"))+
  GlobFillScale
P1.count
ggsave(paste(f.out,"Alluvial.Count.Parent.Node.png",sep=""),height=5,width=5,units="in")

```

## If there was an intervention: Repeat with pre-; during-; post-intervention
print the csv for these proportions 
```{r}
if(int.yn==T){
  
  #prep list item
  sum.Par.Prov.l<-replicate(n.B,vector())
  
  #go through each list item/subsample
  ## tabulate instances of location pairs
  for (k in 1:n.B){
    sum.Par.Prov.l[[k]]<-sum.boots[[k]] %>%
      filter(tmrca.dt<as.Date(int.start)) %>%
      dplyr::group_by (Parent.Location, Node.Location) %>% dplyr::summarize (.groups="rowwise", n.Par= n()) %>% as.data.frame() %>% mutate(perc.Par=(n.Par/sum(n.Par))*100)
  
    ## add a column for subsample
    sum.Par.Prov.l[[k]]$SampleSet<-paste("Sample",BOOTS[k])
  
  }
  
  ## rbind the summaries
  sum.Par.Prov<-bind_rows(sum.Par.Prov.l)
  
  #summarize the mean and range for each of 1), 2) and 3)
  sum.Par.Prov.summary<-sum.Par.Prov %>% dplyr::group_by(Parent.Location, Node.Location) %>%
    dplyr::summarize(.groups="rowwise",
                     mean.n=round(mean(n.Par)),
                     sd.n=round(sd(n.Par,na.rm=T),digits=2),
                     mean.perc=round(mean(perc.Par),digits=2),
                     sd.perc=round(sd(perc.Par,na.rm=T),digits=2)) %>%
    as.data.frame()
  
  tot.Par<-sum.Par.Prov.summary %>% dplyr::group_by(Parent.Location) %>%
    dplyr::summarise(.groups = "rowwise", totalImports=sum(mean.perc)) %>%
    as.data.frame()
  
  ## Alluvial plot for Figure 2
  #make a "subject column"
  sum.Par.Prov.summary$subject<-1:nrow(sum.Par.Prov.summary)
  # sum.Par.Prov.summary<-sum.Par.Prov.summary[-which(sum.Par.Prov.summary$mean.n<1),]
  
  sum.Par.Prov.summary$Node.Location<-str_replace_all(sum.Par.Prov.summary$Node.Location,"British Columbia","British\nColumbia")
  sum.Par.Prov.summary$Parent.Location<-str_replace_all(sum.Par.Prov.summary$Parent.Location,focal.source,focal.source)
  
  #order the geos
  ord.count<-sum.Par.Prov.summary%>% dplyr::group_by(Parent.Location) %>%
    dplyr::summarise(.groups="rowwise",n=sum(mean.perc)) %>% as.data.frame()
  ord.count<-ord.count[rev(order(ord.count$n)),'Parent.Location']
  sum.Par.Prov.summary$Parent.Location<-factor(sum.Par.Prov.summary$Parent.Location,levels=ord.count)
  
  ord.prov<-sum.Par.Prov.summary%>% dplyr::group_by(Node.Location) %>%
    dplyr::summarise(.groups="rowwise",n=sum(mean.perc)) %>% as.data.frame()
  ord.prov<-ord.prov[rev(order(ord.prov$n)),'Node.Location']
  sum.Par.Prov.summary$Node.Location<-factor(sum.Par.Prov.summary$Node.Location,levels=ord.prov)
  
  #make it long
  sum.Par.Prov.summary.long<-sum.Par.Prov.summary %>% pivot_longer(1:2, names_to = "geo.type", values_to = "geo")
  #order the geo types
  sum.Par.Prov.summary.long$geo.type<-factor(sum.Par.Prov.summary.long$geo.type,levels=c("Parent.Location","Node.Location"),labels=c("Origin","Destination"))
  
  
  # sum.Par.Prov.summary.long$geo[which(!sum.Par.Prov.summary.long$geo %in% names(globalPalette.ch))]
  
  #BECAUSE now showing a percent, rescale to equal 100 (means might not sum to 100)
  sum.Par.Prov.summary.long$metric<-sum.Par.Prov.summary.long$mean.perc
  matchy.origin<-which(sum.Par.Prov.summary.long$geo.type=="Origin")
  sum.origin<-sum(sum.Par.Prov.summary.long$mean.perc[matchy.origin])
  sum.Par.Prov.summary.long$metric[matchy.origin]<-sum.Par.Prov.summary.long$mean.perc[matchy.origin]/sum.origin*100
  # sum(sum.Par.Prov.summary.long$metric[matchy.origin]) #should be 100
  matchy.prov<-which(sum.Par.Prov.summary.long$geo.type=="Destination")
  sum.prov<-sum(sum.Par.Prov.summary.long$mean.perc[matchy.prov])
  sum.Par.Prov.summary.long$metric[matchy.prov]<-sum.Par.Prov.summary.long$mean.perc[matchy.prov]/sum.prov*100
  # sum(sum.Par.Prov.summary.long$metric[matchy.prov])
  #Modified palette with weird names TODO
  globalPalette.ch.mod<-globalPalette.ch
  names(globalPalette.ch.mod)<-str_replace_all(names(globalPalette.ch.mod),c("British Columbia"="British\nColumbia",focal.source=focal.source))
  GlobFillScale.mod<-scale_fill_manual(name = "Location",values = globalPalette.ch.mod,na.value="grey60")
  GlobColScale.mod<-scale_color_manual(name = "Location",values = globalPalette.ch.mod,na.value="grey60")
  
  
  ## Alluvial plot
  P1.wave1<- ggplot(sum.Par.Prov.summary.long,
         aes(x = geo.type, stratum = geo, alluvium = subject,
             y = mean.n,
             fill = geo, label = geo)) +
    scale_x_discrete(expand = c(0.01,0.01)) +
    scale_y_continuous(expand = c(0,0)) +
    geom_flow(alpha = 0.6,width=0.55) +
    geom_stratum(alpha = 0.8,width=0.55) +
    geom_text(stat = "stratum", size = 3.4,min.y=1,fontface="bold") +
    pubTheme+
    theme(legend.position = "none", axis.line = element_blank(), text =element_text(size=14),
          axis.ticks.x = element_blank(),axis.text.x = element_text(hjust=c(0.5,0.5)),
          plot.margin=margin(4,4,4,4,unit="pt"))+
    labs(x=NULL,y=paste0("# sublineages pre-intervention"))+
    GlobFillScale.mod
  P1.wave1
  # ggsave(paste(f.out,"WAVE1.Alluvial.percent.Parent.Node.png",sep=""),height=5,width=5,units="in")
  
  ### WAVE 2 DURING BAN####
  #prep list item
  sum.Par.Prov.2.l<-replicate(n.B,vector())
  
  #go through each list item/subsample
  ## tabulate instances of location pairs
  for (k in 1:n.B){
    sum.Par.Prov.2.l[[k]]<-sum.boots[[k]] %>%
      filter(tmrca.dt>=as.Date(int.start)) %>%
      filter(tmrca.dt<=as.Date(int.end)) %>%
      dplyr::group_by (Parent.Location, Node.Location) %>% dplyr::summarize (.groups="rowwise", n.Par= n()) %>% as.data.frame() %>% mutate(perc.Par=(n.Par/sum(n.Par))*100)
  
    ## add a column for subsample
    sum.Par.Prov.2.l[[k]]$SampleSet<-paste("Sample",BOOTS[k])
  
  }
  
  ## rbind the summaries
  sum.Par.Prov<-bind_rows(sum.Par.Prov.2.l)
  
  #summarize the mean and range for each of 1), 2) and 3)
  sum.Par.Prov.2.summary<-sum.Par.Prov %>% dplyr::group_by(Parent.Location, Node.Location) %>%
    dplyr::summarize(.groups="rowwise",
                     mean.n=round(mean(n.Par)),
                     sd.n=round(sd(n.Par,na.rm=T),digits=2),
                     mean.perc=round(mean(perc.Par),digits=2),
                     sd.perc=round(sd(perc.Par,na.rm=T),digits=2)) %>%
    as.data.frame()
  
  tot.Par<-sum.Par.Prov.2.summary %>% dplyr::group_by(Parent.Location) %>%
    dplyr::summarise(.groups = "rowwise", totalImports=sum(mean.perc)) %>%
    as.data.frame()
  
  ## Alluvial plot for Figure 2
  #make a "subject column"
  sum.Par.Prov.2.summary$subject<-1:nrow(sum.Par.Prov.2.summary)
  # sum.Par.Prov.2.summary<-sum.Par.Prov.2.summary[-which(sum.Par.Prov.2.summary$mean.n<1),]
  
  
  sum.Par.Prov.2.summary$Node.Location<-str_replace_all(sum.Par.Prov.2.summary$Node.Location,"British Columbia","British\nColumbia")
  sum.Par.Prov.2.summary$Parent.Location<-str_replace_all(sum.Par.Prov.2.summary$Parent.Location,focal.source,focal.source)
  
  #order the geos
  ord.count<-sum.Par.Prov.2.summary%>% dplyr::group_by(Parent.Location) %>%
    dplyr::summarise(.groups="rowwise",n=sum(mean.perc)) %>% as.data.frame()
  ord.count<-ord.count[rev(order(ord.count$n)),'Parent.Location']
  sum.Par.Prov.2.summary$Parent.Location<-factor(sum.Par.Prov.2.summary$Parent.Location,levels=ord.count)
  
  ord.prov<-sum.Par.Prov.2.summary%>% dplyr::group_by(Node.Location) %>%
    dplyr::summarise(.groups="rowwise",n=sum(mean.perc)) %>% as.data.frame()
  ord.prov<-ord.prov[rev(order(ord.prov$n)),'Node.Location']
  sum.Par.Prov.2.summary$Node.Location<-factor(sum.Par.Prov.2.summary$Node.Location,levels=ord.prov)
  
  
  #make it long
  sum.Par.Prov.2.summary.long<-sum.Par.Prov.2.summary %>% pivot_longer(1:2, names_to = "geo.type", values_to = "geo")
  #order the geo types
  sum.Par.Prov.2.summary.long$geo.type<-factor(sum.Par.Prov.2.summary.long$geo.type,levels=c("Parent.Location","Node.Location"),labels=c("Origin","Destination"))
  
  # sum.Par.Prov.2.summary.long$geo[which(!sum.Par.Prov.2.summary.long$geo %in% names(globalPalette.ch))]
  
  #BECAUSE now showing a percent, rescale to equal 100 (means might not sum to 100)
  sum.Par.Prov.2.summary.long$metric<-sum.Par.Prov.2.summary.long$mean.perc
  matchy.origin<-which(sum.Par.Prov.2.summary.long$geo.type=="Origin")
  sum.origin<-sum(sum.Par.Prov.2.summary.long$mean.perc[matchy.origin])
  sum.Par.Prov.2.summary.long$metric[matchy.origin]<-sum.Par.Prov.2.summary.long$mean.perc[matchy.origin]/sum.origin*100
  # sum(sum.Par.Prov.2.summary.long$metric[matchy.origin]) #should be 100
  matchy.prov<-which(sum.Par.Prov.2.summary.long$geo.type=="Destination")
  sum.prov<-sum(sum.Par.Prov.2.summary.long$mean.perc[matchy.prov])
  sum.Par.Prov.2.summary.long$metric[matchy.prov]<-sum.Par.Prov.2.summary.long$mean.perc[matchy.prov]/sum.prov*100
  # sum(sum.Par.Prov.2.summary.long$metric[matchy.prov])
  ## Alluvial plot
  
  P1.wave2<- ggplot(sum.Par.Prov.2.summary.long,
         aes(x = geo.type, stratum = geo, alluvium = subject,
             y = mean.n,
             fill = geo, label = geo)) +
    scale_x_discrete(expand = c(0.01,0.01)) +
    scale_y_continuous(expand = c(0,0)) +
    geom_flow(alpha = 0.6,width=0.55) +
    geom_stratum(alpha = 0.8,width=0.55) +
    geom_text(stat = "stratum", size = 3.4,min.y=1,fontface="bold") +
    pubTheme+
    theme(legend.position = "none", axis.line = element_blank(), text =element_text(size=14),
          axis.ticks.x = element_blank(),axis.text.x = element_text(hjust=c(0.5,0.5)),
                  plot.margin=margin(4,4,4,4,unit="pt"))+
    labs(x=NULL,y=paste0("# sublineages during intervention"))+
    GlobFillScale.mod
  P1.wave2
  # ggsave(paste(f.out,"WAVE2.Alluvial.percent.Parent.Node.png",sep=""),height=8,width=5,units="in")
  
  
  ### WAVE 3 AFTER BAN####
  #prep list item
  sum.Par.Prov.3.l<-replicate(n.B,vector())
  
  #go through each list item/subsample
  ## tabulate instances of location pairs
  for (k in 1:n.B){
    sum.Par.Prov.3.l[[k]]<-sum.boots[[k]] %>%
      filter(tmrca.dt>as.Date(int.end)) %>%
      dplyr::group_by (Parent.Location, Node.Location) %>% dplyr::summarize (.groups="rowwise", n.Par= n()) %>% as.data.frame() %>% mutate(perc.Par=(n.Par/sum(n.Par))*100)
  
    ## add a column for subsample
    sum.Par.Prov.3.l[[k]]$SampleSet<-paste("Sample",BOOTS[k])
  
  }
  
  ## rbind the summaries
  sum.Par.Prov<-bind_rows(sum.Par.Prov.3.l)
  
  #summarize the mean and range for each of 1), 2) and 3)
  sum.Par.Prov.3.summary<-sum.Par.Prov %>% dplyr::group_by(Parent.Location, Node.Location) %>%
    dplyr::summarize(.groups="rowwise",
                     mean.n=round(mean(n.Par)),
                     sd.n=round(sd(n.Par,na.rm=T),digits=2),
                     mean.perc=round(mean(perc.Par),digits=2),
                     sd.perc=round(sd(perc.Par,na.rm=T),digits=2)) %>%
    as.data.frame()
  
  tot.Par<-sum.Par.Prov.3.summary %>% dplyr::group_by(Parent.Location) %>%
    dplyr::summarise(.groups = "rowwise", totalImports=sum(mean.perc)) %>%
    as.data.frame()
  
  ## Alluvial plot for Figure 2
  #make a "subject column"
  sum.Par.Prov.3.summary$subject<-1:nrow(sum.Par.Prov.3.summary)
  # sum.Par.Prov.3.summary<-sum.Par.Prov.3.summary[-which(sum.Par.Prov.3.summary$mean.n<1),]
  
  
  sum.Par.Prov.3.summary$Node.Location<-str_replace_all(sum.Par.Prov.3.summary$Node.Location,"British Columbia","British\nColumbia")
  sum.Par.Prov.3.summary$Parent.Location<-str_replace_all(sum.Par.Prov.3.summary$Parent.Location,focal.source,focal.source)
  
  #order the geos
  ord.count<-sum.Par.Prov.3.summary%>% dplyr::group_by(Parent.Location) %>%
    dplyr::summarise(.groups="rowwise",n=sum(mean.perc)) %>% as.data.frame()
  ord.count<-ord.count[rev(order(ord.count$n)),'Parent.Location']
  sum.Par.Prov.3.summary$Parent.Location<-factor(sum.Par.Prov.3.summary$Parent.Location,levels=ord.count)
  
  ord.prov<-sum.Par.Prov.3.summary%>% dplyr::group_by(Node.Location) %>%
    dplyr::summarise(.groups="rowwise",n=sum(mean.perc)) %>% as.data.frame()
  ord.prov<-ord.prov[rev(order(ord.prov$n)),'Node.Location']
  sum.Par.Prov.3.summary$Node.Location<-factor(sum.Par.Prov.3.summary$Node.Location,levels=ord.prov)
  
  
  #make it long
  sum.Par.Prov.3.summary.long<-sum.Par.Prov.3.summary %>% pivot_longer(1:2, names_to = "geo.type", values_to = "geo")
  #order the geo types
  sum.Par.Prov.3.summary.long$geo.type<-factor(sum.Par.Prov.3.summary.long$geo.type,levels=c("Parent.Location","Node.Location"),labels=c("Origin","Destination"))
  
  # sum.Par.Prov.3.summary.long$geo[which(!sum.Par.Prov.3.summary.long$geo %in% names(globalPalette.ch))]
  
  #BECAUSE now showing a percent, rescale to equal 100 (means might not sum to 100)
  sum.Par.Prov.3.summary.long$metric<-sum.Par.Prov.3.summary.long$mean.perc
  matchy.origin<-which(sum.Par.Prov.3.summary.long$geo.type=="Origin")
  sum.origin<-sum(sum.Par.Prov.3.summary.long$mean.perc[matchy.origin])
  sum.Par.Prov.3.summary.long$metric[matchy.origin]<-sum.Par.Prov.3.summary.long$mean.perc[matchy.origin]/sum.origin*100
  # sum(sum.Par.Prov.3.summary.long$metric[matchy.origin]) #should be 100
  matchy.prov<-which(sum.Par.Prov.3.summary.long$geo.type=="Destination")
  sum.prov<-sum(sum.Par.Prov.3.summary.long$mean.perc[matchy.prov])
  sum.Par.Prov.3.summary.long$metric[matchy.prov]<-sum.Par.Prov.3.summary.long$mean.perc[matchy.prov]/sum.prov*100
  # sum(sum.Par.Prov.3.summary.long$metric[matchy.prov])
  ## Alluvial plot
  
  P1.wave3<- ggplot(sum.Par.Prov.3.summary.long,
         aes(x = geo.type, stratum = geo, alluvium = subject,
             y = mean.n,
             fill = geo, label = geo)) +
    scale_x_discrete(expand = c(0.01,0.01)) +
    scale_y_continuous(expand = c(0,0)) +
    geom_flow(alpha = 0.6,width=0.55) +
    geom_stratum(alpha = 0.8,width=0.55) +
    geom_text(stat = "stratum", size = 3.4,min.y=1,fontface="bold") +
    pubTheme+
    theme(legend.position = "none", axis.line = element_blank(), text =element_text(size=14),
          axis.ticks.x = element_blank(),axis.text.x = element_text(hjust=c(0.5,0.5)),
                  plot.margin=margin(4,4,4,4,unit="pt"))+
    labs(x=NULL,y=paste0("# sublineages post-intervention"))+
    GlobFillScale.mod
  P1.wave3

  #grob plot of both waves
  plot_grid(P1.wave1,P1.wave2,P1.wave3,nrow=1,labels=c("A","B","C"))
  ggsave(paste(f.out,"SepWaves.Alluvial.percent.Parent.Node.png",sep=""),height=5,width=11,units="in")
}
```

## Alluvial stratified by lineage, then by intervention period
```{r}
#if there are more than one unique pango lineage among sublin designations...  
if(mean(un.lins)>1){
  #prep list item
  sum.Par.Prov.L.l<-replicate(n.B,vector())
  
  #go through each list item/subsample
  ## tabulate instances of location pairs
  for (k in 1:n.B){
    sum.Par.Prov.L.l[[k]]<-sum.boots[[k]] %>% 
      dplyr::group_by (Parent.Location, Node.Location, Lineage) %>% 
      dplyr::summarize (.groups="rowwise", n.Par= n()) %>% 
      as.data.frame() %>% 
      mutate(perc.Par=(n.Par/sum(n.Par))*100)
  
    ## add a column for subsample
    sum.Par.Prov.L.l[[k]]$SampleSet<-paste("Sample",BOOTS[k])
  
  }
  
  sum.Par.Prov.L<-bind_rows(sum.Par.Prov.L.l)
  
  #summarize the mean and range for each of 1), 2) and 3)
  sum.Par.Prov.L.summary<-sum.Par.Prov.L %>% dplyr::group_by(Parent.Location, Node.Location, Lineage) %>%
    dplyr::summarize(.groups="rowwise",
                     mean.n=round(mean(n.Par)),
                     sd.n=round(sd(n.Par,na.rm=T),digits=2),
                     mean.perc=round(mean(perc.Par),digits=2),
                     sd.perc=round(sd(perc.Par,na.rm=T),digits=2)) %>%
    as.data.frame()
  # head(sum.Par.Prov.L.summary)
  ### Alluvial plot for Figure 2
  #make a "subject column"
  sum.Par.Prov.L.summary$subject<-1:nrow(sum.Par.Prov.L.summary)
  sum.Par.Prov.L.summary$Node.Location<-str_replace_all(sum.Par.Prov.L.summary$Node.Location,"British Columbia","British\nColumbia")
  
  #order the geos by frequency
  ord.count<-sum.Par.Prov.L.summary%>% dplyr::group_by(Parent.Location) %>%
    dplyr::summarise(.groups="rowwise",n=sum(mean.perc)) %>% as.data.frame()
  ord.count<-ord.count[rev(order(ord.count$n)),'Parent.Location']
  sum.Par.Prov.L.summary$Parent.Location<-factor(sum.Par.Prov.L.summary$Parent.Location,levels=ord.count)
  
  ord.prov<-sum.Par.Prov.L.summary%>% dplyr::group_by(Node.Location) %>%
    dplyr::summarise(.groups="rowwise",n=sum(mean.perc)) %>% as.data.frame()
  ord.prov<-ord.prov[rev(order(ord.prov$n)),'Node.Location']
  sum.Par.Prov.L.summary$Node.Location<-factor(sum.Par.Prov.L.summary$Node.Location,levels=ord.prov)
  
  #make it long
  sum.Par.Prov.L.summary.long<-sum.Par.Prov.L.summary %>% pivot_longer(1:2, names_to = "geo.type", values_to = "geo") %>% as.data.frame()
  
  #order the geo types and lineages
  sum.Par.Prov.L.summary.long$geo.type<-factor(sum.Par.Prov.L.summary.long$geo.type,levels=c("Parent.Location","Node.Location"),labels=c("Origin","Destination"))
  sum.Par.Prov.L.summary.long$Lineage<-factor(sum.Par.Prov.L.summary.long$Lineage,levels=aliases$lineage)
  
  #re-scale to perfect 100
  sum.Par.Prov.L.summary.long$metric<-sum.Par.Prov.L.summary.long$mean.perc
  matchy.origin<-which(sum.Par.Prov.L.summary.long$geo.type=="Origin")
  sum.origin<-sum(sum.Par.Prov.L.summary.long$mean.perc[matchy.origin])
  sum.Par.Prov.L.summary.long$metric[matchy.origin]<-sum.Par.Prov.L.summary.long$mean.perc[matchy.origin]/sum.origin*100
  sum(sum.Par.Prov.summary.long$metric[matchy.origin],na.rm=T) #should be 100
  matchy.prov<-which(sum.Par.Prov.L.summary.long$geo.type=="Destination")
  sum.prov<-sum(sum.Par.Prov.L.summary.long$mean.perc[matchy.prov])
  sum.Par.Prov.L.summary.long$metric[matchy.prov]<-sum.Par.Prov.L.summary.long$mean.perc[matchy.prov]/sum.prov*100
  
  #plot it
  alluv.lin<-ggplot(sum.Par.Prov.L.summary.long,
         aes(x = geo.type, stratum = geo, alluvium = subject,
             y = metric, label = geo)) +
    scale_x_discrete(expand = c(0.01,0.01)) +
    scale_y_continuous(expand = c(0,0)) +
    geom_flow(aes(fill = Lineage),alpha = 1,width=0.4) +
    LinFillScale+
    geom_stratum(alpha = 0.4,width=0.4 )+
    scale_color_manual(name = "geo",values = globalPalette.ch,na.value="grey60")+
    geom_text(stat = "stratum", size = 3.3,min.y=1,label.padding=unit(0.1, "lines")) +
    geom_text(stat="flow",aes(label=Lineage,color=Lineage),size=1.5,min.y=0.75,color="white",
              nudge_x=-0.206,hjust=1)+
    pubTheme+
    theme(legend.position = "none",
          axis.ticks.x = element_blank(),axis.text.x = element_text(hjust=c(0.5,0.5)),
          axis.title.y=element_text(vjust=-2),
          plot.margin=margin(4,4,4,1,unit="pt"))+
    labs(x=NULL,y=paste0("% sublineages"))
  alluv.lin
  
  ggsave(paste(f.out,"/Alluvial.Perc.Parent.Node.Lineage.png",sep=""),height=5,width=5,units="in")
  
  #plot the count instead of perc
  alluv.lin.n<-ggplot(sum.Par.Prov.L.summary.long,
         aes(x = geo.type, stratum = geo, alluvium = subject,
             y = mean.n, label = geo)) +
    scale_x_discrete(expand = c(0.01,0.01)) +
    scale_y_continuous(expand = c(0,0)) +
    geom_flow(aes(fill = Lineage),alpha = 1,width=0.4) +
    LinFillScale+
    geom_stratum(alpha = 0.4,width=0.41 )+
    scale_color_manual(name = "geo",values = globalPalette.ch,na.value="grey60")+
    geom_text(stat = "stratum", size = 3.3,min.y=1,label.padding=unit(0.1, "lines")) +
    geom_text(stat="flow",aes(label=Lineage,color=Lineage),size=1.5,min.y=1,color="white",
              nudge_x=-0.206,hjust=1)+
    pubTheme+
    theme(legend.position = "none",
          axis.ticks.x = element_blank(),
          axis.text.x = element_text(hjust=c(0.5,0.5)),
          axis.title.y=element_text(vjust=-1),
          plot.margin=margin(4,4,4,1,unit="pt"))+
    labs(x=NULL,y=paste0("# sublineages "))
  alluv.lin.n
  ggsave(paste(f.out,"/Alluvial.Count.Parent.Node.Lin.png",sep=""),height=5,width=5,units="in")

}

#and if there was a var-specific intervention, stratify by intervetion period
if(mean(un.lins)>1 & int.yn==T){
  ### BEFORE ####
  #summarize the total number and percent of intros by 1) par. loc, 2) prov of intro, maybe also 3) lineage
  sum.Par.Prov.L1.l<-replicate(n.B,vector())
  
  ## tabulate instances of location pairs
  for (k in 1:n.B){
    sum.Par.Prov.L1.l[[k]]<-sum.boots[[k]] %>%
      filter(tmrca.dt<as.Date(int.start)) %>%
      dplyr::group_by (Parent.Location, Node.Location, Lineage) %>% dplyr::summarize (.groups="rowwise", n.Par= n()) %>% as.data.frame() %>% mutate(perc.Par=(n.Par/sum(n.Par))*100)
  
    ## add a column for subsample
    sum.Par.Prov.L1.l[[k]]$SampleSet<-paste("Sample",BOOTS[k])
  }
  
  sum.Par.Prov.L<-bind_rows(sum.Par.Prov.L1.l)

  #summarize the mean and range for each of 1), 2) and 3)
  sum.Par.Prov.L1.summary<-sum.Par.Prov.L %>% dplyr::group_by(Parent.Location, Node.Location, Lineage) %>%
    dplyr::summarize(.groups="rowwise",
                     mean.n=round(mean(n.Par)),
                     sd.n=round(sd(n.Par,na.rm=T),digits=2),
                     mean.perc=round(mean(perc.Par),digits=2),
                     sd.perc=round(sd(perc.Par,na.rm=T),digits=2)) %>%
    as.data.frame()
  
  ### Alluvial plot for Figure 2
  #make a "subject column"
  sum.Par.Prov.L1.summary$subject<-1:nrow(sum.Par.Prov.L1.summary)
  sum.Par.Prov.L1.summary$Node.Location<-str_replace_all(sum.Par.Prov.L1.summary$Node.Location,"British Columbia","British\nColumbia")

  #order the geos by frequency
  ord.count<-sum.Par.Prov.L1.summary%>% dplyr::group_by(Parent.Location) %>%
    dplyr::summarise(.groups="rowwise",n=sum(mean.n)) %>% as.data.frame()
  ord.count<-ord.count[rev(order(ord.count$n)),'Parent.Location']
  sum.Par.Prov.L1.summary$Parent.Location<-factor(sum.Par.Prov.L1.summary$Parent.Location,levels=ord.count)
  
  ord.prov<-sum.Par.Prov.L1.summary%>% dplyr::group_by(Node.Location) %>%
    dplyr::summarise(.groups="rowwise",n=sum(mean.n)) %>% as.data.frame()
  ord.prov<-ord.prov[rev(order(ord.prov$n)),'Node.Location']
  sum.Par.Prov.L1.summary$Node.Location<-factor(sum.Par.Prov.L1.summary$Node.Location,levels=ord.prov)
  
  #make it long
  sum.Par.Prov.L1.summary.long<-sum.Par.Prov.L1.summary %>% pivot_longer(1:2, names_to = "geo.type", values_to = "geo")
  #order the geo types
  sum.Par.Prov.L1.summary.long$geo.type<-factor(sum.Par.Prov.L1.summary.long$geo.type,levels=c("Parent.Location","Node.Location"),labels=c("Origin","Destination"))
  sum.Par.Prov.L1.summary.long$Lineage<-factor(sum.Par.Prov.L1.summary.long$Lineage,levels=aliases$lineage)
  
  #re-scale
  sum.Par.Prov.L1.summary.long$metric<-sum.Par.Prov.L1.summary.long$mean.perc
  matchy.origin<-which(sum.Par.Prov.L1.summary.long$geo.type=="Origin")
  sum.origin<-sum(sum.Par.Prov.L1.summary.long$mean.perc[matchy.origin])
  sum.Par.Prov.L1.summary.long$metric[matchy.origin]<-sum.Par.Prov.L1.summary.long$mean.perc[matchy.origin]/sum.origin*100
  sum(sum.Par.Prov.summary.long$metric[matchy.origin],na.rm=T) #should be 100
  matchy.prov<-which(sum.Par.Prov.L1.summary.long$geo.type=="Destination")
  sum.prov<-sum(sum.Par.Prov.L1.summary.long$mean.perc[matchy.prov])
  sum.Par.Prov.L1.summary.long$metric[matchy.prov]<-sum.Par.Prov.L1.summary.long$mean.perc[matchy.prov]/sum.prov*100
  
  #plot it
  alluv.w1.lin<-ggplot(sum.Par.Prov.L1.summary.long,
         aes(x = geo.type, stratum = geo, alluvium = subject,
             y = metric, label = geo)) +
    scale_x_discrete(expand = c(0.01,0.01)) +
    scale_y_continuous(expand = c(0,0)) +
    geom_flow(aes(fill = Lineage),alpha = 1,width=0.4) +
    LinFillScale+
    # new_scale("fill")+ #sneaky
    geom_stratum(alpha = 0.4,width=0.4) +
    scale_color_manual(name = "geo",values = globalPalette.ch,na.value="grey60")+
    geom_text(stat = "stratum", size = 3.1,min.y=2) +
    geom_text(stat="flow",aes(label=Lineage,color=Lineage),size=1.5,min.y=1,color="white",
              nudge_x=-0.206,hjust=1)+
    pubTheme+
    theme(legend.position = "none",
          axis.ticks.x = element_blank(),axis.text.x = element_text(hjust=c(0.55,0.7)),
          axis.title.y=element_text(vjust=-2),
          plot.margin=margin(4,4,4,1,unit="pt"))+ #accommodate the lineage group image
    labs(x=NULL,y=paste0("% sublineages before intervention"))
  alluv.w1.lin
  ggsave(paste(f.out,"/Alluvial.Sublin.Before.Parent.Node.Lin.png",sep=""),height=5,width=5,units="in")
  
  ### DURING ###
  #summarize the total number and percent of intros by 1) par. loc, 2) prov of intro, maybe also 3) lineage
  #prep list item
  sum.Par.Prov.L2.l<-replicate(n.B,vector())
  
  #go through each list item/subsample
  ## tabulate instances of location pairs
  for (k in 1:n.B){
    sum.Par.Prov.L2.l[[k]]<-sum.boots[[k]] %>%
      filter(tmrca.dt>=as.Date(int.start)) %>%
      filter(tmrca.dt<=as.Date(int.end)) %>%
      dplyr::group_by (Parent.Location, Node.Location, Lineage) %>% dplyr::summarize (.groups="rowwise", n.Par= n()) %>% as.data.frame() %>% mutate(perc.Par=(n.Par/sum(n.Par))*100)
  
    ## add a column for subsample
    sum.Par.Prov.L2.l[[k]]$SampleSet<-paste("Sample",BOOTS[k])
  }
  sum.Par.Prov.L<-bind_rows(sum.Par.Prov.L2.l)
  
  #summarize the mean and range for each of 1), 2) and 3)
  sum.Par.Prov.L2.summary<-sum.Par.Prov.L %>% dplyr::group_by(Parent.Location, Node.Location, Lineage) %>%
    dplyr::summarize(.groups="rowwise",
                     mean.n=round(mean(n.Par)),
                     sd.n=round(sd(n.Par,na.rm=T),digits=2),
                     mean.perc=round(mean(perc.Par),digits=2),
                     sd.perc=round(sd(perc.Par,na.rm=T),digits=2)) %>%
    as.data.frame()
  
  ### Alluvial plot for Figure 2
  #make a "subject column"
  sum.Par.Prov.L2.summary$subject<-1:nrow(sum.Par.Prov.L2.summary)
  # sum.Par.Prov.L2.summary<-sum.Par.Prov.L2.summary[-which(sum.Par.Prov.L2.summary$mean.n<1),]
  
  sum.Par.Prov.L2.summary$Node.Location<-str_replace_all(sum.Par.Prov.L2.summary$Node.Location,"British Columbia","British\nColumbia")
  sum.Par.Prov.L2.summary$Parent.Location<-str_replace_all(sum.Par.Prov.L2.summary$Parent.Location,focal.source,focal.source)
  
  #order the geos by frequency
  ord.count<-sum.Par.Prov.L2.summary%>% dplyr::group_by(Parent.Location) %>%
    dplyr::summarise(.groups="rowwise",n=sum(mean.n)) %>% as.data.frame()
  ord.count<-ord.count[rev(order(ord.count$n)),'Parent.Location']
  sum.Par.Prov.L2.summary$Parent.Location<-factor(sum.Par.Prov.L2.summary$Parent.Location,levels=ord.count)
  
  ord.prov<-sum.Par.Prov.L2.summary%>% dplyr::group_by(Node.Location) %>%
    dplyr::summarise(.groups="rowwise",n=sum(mean.n)) %>% as.data.frame()
  ord.prov<-ord.prov[rev(order(ord.prov$n)),'Node.Location']
  sum.Par.Prov.L2.summary$Node.Location<-factor(sum.Par.Prov.L2.summary$Node.Location,levels=ord.prov)
  
  #make it long
  sum.Par.Prov.L2.summary.long<-sum.Par.Prov.L2.summary %>% pivot_longer(1:2, names_to = "geo.type", values_to = "geo")
  #order the geo types
  sum.Par.Prov.L2.summary.long$geo.type<-factor(sum.Par.Prov.L2.summary.long$geo.type,levels=c("Parent.Location","Node.Location"),labels=c("Origin","Destination"))
  sum.Par.Prov.L2.summary.long$Lineage<-factor(sum.Par.Prov.L2.summary.long$Lineage,levels=aliases$lineage)
  
  #re-scale
  sum.Par.Prov.L2.summary.long$metric<-sum.Par.Prov.L2.summary.long$mean.perc
  matchy.origin<-which(sum.Par.Prov.L2.summary.long$geo.type=="Origin")
  sum.origin<-sum(sum.Par.Prov.L2.summary.long$mean.perc[matchy.origin])
  sum.Par.Prov.L2.summary.long$metric[matchy.origin]<-sum.Par.Prov.L2.summary.long$mean.perc[matchy.origin]/sum.origin*100
  sum(sum.Par.Prov.summary.long$metric[matchy.origin],na.rm=T) #should be 100
  matchy.prov<-which(sum.Par.Prov.L2.summary.long$geo.type=="Destination")
  sum.prov<-sum(sum.Par.Prov.L2.summary.long$mean.perc[matchy.prov])
  sum.Par.Prov.L2.summary.long$metric[matchy.prov]<-sum.Par.Prov.L2.summary.long$mean.perc[matchy.prov]/sum.prov*100
  
  #plot it
  alluv.w2.lin<-ggplot(sum.Par.Prov.L2.summary.long,
         aes(x = geo.type, stratum = geo, alluvium = subject,
             y = metric, label = geo)) +
    scale_x_discrete(expand = c(0.01,0.01)) +
    scale_y_continuous(expand = c(0,0)) +
    geom_flow(aes(fill = Lineage),alpha = 1,width=0.4) +
    LinFillScale+
    # new_scale("fill")+ #sneaky
    geom_stratum(alpha = 0.4,width=0.4) +
    scale_color_manual(name = "geo",values = globalPalette.ch,na.value="grey60")+
    geom_text(stat = "stratum", size = 3.1,min.y=2) +
    geom_text(stat="flow",aes(label=Lineage,color=Lineage),size=1.5,min.y=1,color="white",
              nudge_x=-0.206,hjust=1)+
    pubTheme+
    theme(legend.position = "none",
          axis.ticks.x = element_blank(),axis.text.x = element_text(hjust=c(0.55,0.7)),
          axis.title.y=element_text(vjust=-2),
          plot.margin=margin(4,4,4,1,unit="pt"))+ #accommodate the lineage group image
    labs(x=NULL,y=paste0("% sublineages during intervention"))
  alluv.w2.lin
  #
  ggsave(paste(f.out,"/Alluvial.Sublin.during.Parent.Node.Lin.png",sep=""),height=5,width=5,units="in")

  ### after ###
  #summarize the total number and percent of intros by 1) par. loc, 2) prov of intro, maybe also 3) lineage
  #prep list item
  sum.Par.Prov.L3.l<-replicate(n.B,vector())
  
  #go through each list item/subsample
  ## tabulate instances of location pairs
  for (k in 1:n.B){
    sum.Par.Prov.L3.l[[k]]<-sum.boots[[k]] %>%
      filter(tmrca.dt>as.Date(int.end)) %>%
      dplyr::group_by (Parent.Location, Node.Location, Lineage) %>% dplyr::summarize (.groups="rowwise", n.Par= n()) %>% as.data.frame() %>% mutate(perc.Par=(n.Par/sum(n.Par))*100)
  
    ## add a column for subsample
    sum.Par.Prov.L3.l[[k]]$SampleSet<-paste("Sample",BOOTS[k])
  }
  sum.Par.Prov.L<-bind_rows(sum.Par.Prov.L3.l)
  
  #summarize the mean and range for each of 1), 2) and 3)
  sum.Par.Prov.L3.summary<-sum.Par.Prov.L %>% dplyr::group_by(Parent.Location, Node.Location, Lineage) %>%
    dplyr::summarize(.groups="rowwise",
                     mean.n=round(mean(n.Par)),
                     sd.n=round(sd(n.Par,na.rm=T),digits=2),
                     mean.perc=round(mean(perc.Par),digits=2),
                     sd.perc=round(sd(perc.Par,na.rm=T),digits=2)) %>%
    as.data.frame()
  
  ### Alluvial plot for Figure 2
  #make a "subject column"
  sum.Par.Prov.L3.summary$subject<-1:nrow(sum.Par.Prov.L3.summary)
  # sum.Par.Prov.L3.summary<-sum.Par.Prov.L3.summary[-which(sum.Par.Prov.L3.summary$mean.n<1),]
  
  sum.Par.Prov.L3.summary$Node.Location<-str_replace_all(sum.Par.Prov.L3.summary$Node.Location,"British Columbia","British\nColumbia")
  sum.Par.Prov.L3.summary$Parent.Location<-str_replace_all(sum.Par.Prov.L3.summary$Parent.Location,focal.source,focal.source)
  
  #order the geos by frequency
  ord.count<-sum.Par.Prov.L3.summary%>% dplyr::group_by(Parent.Location) %>%
    dplyr::summarise(.groups="rowwise",n=sum(mean.n)) %>% as.data.frame()
  ord.count<-ord.count[rev(order(ord.count$n)),'Parent.Location']
  sum.Par.Prov.L3.summary$Parent.Location<-factor(sum.Par.Prov.L3.summary$Parent.Location,levels=ord.count)
  
  ord.prov<-sum.Par.Prov.L3.summary%>% dplyr::group_by(Node.Location) %>%
    dplyr::summarise(.groups="rowwise",n=sum(mean.n)) %>% as.data.frame()
  ord.prov<-ord.prov[rev(order(ord.prov$n)),'Node.Location']
  sum.Par.Prov.L3.summary$Node.Location<-factor(sum.Par.Prov.L3.summary$Node.Location,levels=ord.prov)
  
  #make it long
  sum.Par.Prov.L3.summary.long<-sum.Par.Prov.L3.summary %>% pivot_longer(1:2, names_to = "geo.type", values_to = "geo")
  #order the geo types
  sum.Par.Prov.L3.summary.long$geo.type<-factor(sum.Par.Prov.L3.summary.long$geo.type,levels=c("Parent.Location","Node.Location"),labels=c("Origin","Destination"))
  sum.Par.Prov.L3.summary.long$Lineage<-factor(sum.Par.Prov.L3.summary.long$Lineage,levels=aliases$lineage)
  
  #re-scale
  sum.Par.Prov.L3.summary.long$metric<-sum.Par.Prov.L3.summary.long$mean.perc
  matchy.origin<-which(sum.Par.Prov.L3.summary.long$geo.type=="Origin")
  sum.origin<-sum(sum.Par.Prov.L3.summary.long$mean.perc[matchy.origin])
  sum.Par.Prov.L3.summary.long$metric[matchy.origin]<-sum.Par.Prov.L3.summary.long$mean.perc[matchy.origin]/sum.origin*100
  sum(sum.Par.Prov.summary.long$metric[matchy.origin],na.rm=T) #should be 100
  matchy.prov<-which(sum.Par.Prov.L3.summary.long$geo.type=="Destination")
  sum.prov<-sum(sum.Par.Prov.L3.summary.long$mean.perc[matchy.prov])
  sum.Par.Prov.L3.summary.long$metric[matchy.prov]<-sum.Par.Prov.L3.summary.long$mean.perc[matchy.prov]/sum.prov*100
  
  #plot it
  alluv.w3.lin<-ggplot(sum.Par.Prov.L3.summary.long,
         aes(x = geo.type, stratum = geo, alluvium = subject,
             y = metric, label = geo)) +
    scale_x_discrete(expand = c(0.01,0.01)) +
    scale_y_continuous(expand = c(0,0)) +
    geom_flow(aes(fill = Lineage),alpha = 1,width=0.4) +
    LinFillScale+
    # new_scale("fill")+ #sneaky
    geom_stratum(alpha = 0.4,width=0.4) +
    scale_color_manual(name = "geo",values = globalPalette.ch,na.value="grey60")+
    geom_text(stat = "stratum", size = 3.1,min.y=2) +
    geom_text(stat="flow",aes(label=Lineage,color=Lineage),size=1.5,min.y=1,color="white",
              nudge_x=-0.206,hjust=1)+
    pubTheme+
    theme(legend.position = "none",
          axis.ticks.x = element_blank(),axis.text.x = element_text(hjust=c(0.55,0.7)),
          axis.title.y=element_text(vjust=-2),
          plot.margin=margin(4,4,4,1,unit="pt"))+ #accommodate the lineage group image
    labs(x=NULL,y=paste0("% sublineages after intervention"))
  alluv.w3.lin
  #
  ggsave(paste(f.out,"/Alluvial.Sublin.after.Parent.Node.Lin.png",sep=""),height=5,width=5,units="in")  
  
  #composite of both lineage-spec wave-spec flows
  linwaves<-plot_grid(alluv.w1.lin,alluv.w2.lin,alluv.w3.lin,labels=c("A","B","C"),nrow=1)
  linwaves
  ggsave(paste(f.out,"/Alluvial.Sublin.AllPeriods.Parent.Node.Lin.png",sep=""),height=5,width=9,units="in")  
}
```

## Summary of sublineage size, global and Can desc, histogram
```{r}
#first need a way of comparing sublineages... cross reference to see how common
sublin.df<-data.frame(Sublineage=NA,Sublineage2=NA,Lineage=NA,N.Desc.glob=NA,
                      SampleSet=NA)
for (k in 1:n.B){
  sum.boots[[k]]$SampleSet<-k
  #add sublineages to the dataframe
  sublin.df<-rbind(sublin.df,sum.boots[[k]][,c("Sublineage","SublineageUnq","Lineage","N.Desc.glob", "SampleSet")]) #removed lineage group
}
sublin.df<-sublin.df[-1,] #NA row from rbind

k=1 
#Bin sublineage size by frequency
sum.boots.binSize<-sum.boots[[k]] %>% 
  group_by(N.Desc.glob,Lineage) %>% 
  dplyr::summarize(.groups="rowwise",n=n())
#bin the larger sizes
bin.sublinsize<-function(df){
  df$Number.Desc.Factor<-as.character("NA")
  for (i in 1:nrow(df)){
    if (df$N.Desc.glob[i]<10){
      df$Number.Desc.Factor[i]<-as.character(df$N.Desc.glob[i]);next}
    if (df$N.Desc.glob[i]>=10 & df$N.Desc.glob[i]<20){
      df$Number.Desc.Factor[i]<-as.character("10-19");next}
    if (df$N.Desc.glob[i]>=20 &df$N.Desc.glob[i]<30){
      df$Number.Desc.Factor[i]<-as.character("20-29");next}
    if (df$N.Desc.glob[i]>=30 & df$N.Desc.glob[i]<40){
      df$Number.Desc.Factor[i]<-as.character("30-39");next}
    if (df$N.Desc.glob[i]>=40 &df$N.Desc.glob[i]<50){
      df$Number.Desc.Factor[i]<-as.character("40-49");next}
    if (df$N.Desc.glob[i]>=50 & df$N.Desc.glob[i]<100){
      df$Number.Desc.Factor[i]<-as.character("50-99");next}
    if (df$N.Desc.glob[i]>=100 &df$N.Desc.glob[i]<1000){
      df$Number.Desc.Factor[i]<-as.character("100-999");next}
    if (df$N.Desc.glob[i]>=1000 & df$N.Desc.glob[i]<5000){
      df$Number.Desc.Factor[i]<-as.character("1000-4999");next}
    if (df$N.Desc.glob[i]>=5000){
      df$Number.Desc.Factor[i]<-as.character("5000+");next}
  }
  df$Number.Desc.Factor<-factor(df$Number.Desc.Factor, levels=c(as.character(2:9),'10-19','20-29','30-39','40-49','50-99','100-999','1000-4999',"5000+"))
  df$Lineage<-factor(df$Lineage,levels=rev(aliases$lineage))
  return(df)
}

#use function:
sum.boots.binSize<-bin.sublinsize(sum.boots.binSize)

#make a summary df of n in each category for text and pos
sum.boots.binSize.summ<-sum.boots.binSize%>% dplyr::group_by(Number.Desc.Factor) %>%
  dplyr::summarise(.groups="rowwise",total.subs=sum(n)) %>% as.data.frame()

#PLOT IT 
# sum(sum.boots.binSize$n) #685
ymax.tot<-max(sum.boots.binSize$n)+3
P3<-ggplot(data=sum.boots.binSize)+
  geom_bar(aes(x=as.factor(Number.Desc.Factor),y=n, group=Lineage,fill=Lineage),
               position="stack",stat="identity",alpha=0.9)+
  pubTheme+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        axis.text.x=element_text(angle=45,vjust=1,hjust=1,size=rel(1.2)),
        # legend.position = c(0.7,0.8),
        legend.position = "none",
        legend.text = element_text(size=9),
        # axis.title.y=element_text(vjust=4),       
        axis.title.y=element_text(vjust=1,size=rel(1.2)), 
        plot.margin=unit(c(4,4,4,4),"pt"))+
  LinFillScale+
  labs(x="Sublineage size",y="# sublineages")+
  guides(fill=guide_legend(ncol= 1,title="Lineage",title.position="top",reverse = T, keywidth = 1.2,keyheight = 1.2))+
  geom_text(data=sum.boots.binSize.summ,aes(y=total.subs,x=Number.Desc.Factor,label=paste(total.subs,sep=""),hjust=0.5,vjust=-0.3),size=2.7)+  
  scale_y_continuous(limits=c(0,ymax.tot),expand=c(0.02,0.01))
  # annotate("rect",xmin=2.5,xmax=16.4,ymin=166,ymax=202, fill="white")

P3
ggsave(paste(f.out,"/Sublineagesizes.bylin.Frequencies.png",sep=""),width=4,height=4,units="in")

```

## Alternative figure for sublineage size using treemap tiles
```{r}
k=1
sb<-sum.boots[[k]][,c("Lineage","Sublineage","Number.Descendants","N.Desc.glob","N.Desc.can")]
# sb$Sublineage3<-NA
# sb$Sublineage3[sb$N.Desc.glob>20]<-sb$Sublineage[sb$N.Desc.glob>20]
p.size<-ggplot(sb, aes(area = N.Desc.glob, fill = Lineage, 
                       label=paste(Sublineage,"\n","n=",N.Desc.glob,sep=""))) +
  geom_treemap()+
  LinFillScale+
  geom_treemap_text(colour = "white", place = "centre",grow = TRUE,reflow=T,
                    min.size = 0.4, padding.x=unit(1,"mm"),padding.y=unit(1,"mm"))+
  theme(legend.position="none",
        plot.margin=margin(4,4,4,4,unit="pt"))
p.size
ggsave(paste(f.out,"/SublineageSizeTreeMap.Lineage.png",sep=""),height=2,width=3,unit="in")

p.size.can<-ggplot(sb, aes(area = N.Desc.can, fill = Lineage, 
                           label=paste(Sublineage,"\n","n=",N.Desc.can,sep=""))) +
  geom_treemap()+
  LinFillScale+
  geom_treemap_text(colour = "white", place = "centre",grow = TRUE,reflow=T,
                    min.size = 0.4, padding.x=unit(1,"mm"),padding.y=unit(1,"mm"))+
  theme(legend.position="none",
        plot.margin=margin(4,4,4,4,unit="pt"))
p.size.can
ggsave(paste(f.out,"/SublineageSizeCANADATreeMap.Lineage.png",sep=""),height=2,width=3,unit="in")
```

## Sublin sizes (Can desc) by period
```{r}
## if there are var-spec interventions...
if(int.yn==T){
  #stratify this by wave, only for Canadian descendants,
  # need to calculate number of descendants in each wave
  sb2<-sum.boots[[k]][,c("Lineage","Sublineage","Number.Descendants","N.Desc.glob","N.Desc.can")]
  #wave 1 = before intervention
  wave1.desc<-sublin.long.unq[[k]] %>% ### CHANGED TO UNIQUE
    filter(Date<as.Date(int.end)) %>%
    filter(State %in% provs) %>% #only canadians allowed
    dplyr::count(Sublineage)
  colnames(wave1.desc)[2]<-"wave1.Desc"
  
  #wave 2 = during intervention
  wave2.desc<-sublin.long.unq[[k]] %>%
    filter(Date>=as.Date(int.start)) %>%
    filter(Date<=as.Date(int.end)) %>%
      filter(State %in% provs) %>%
    dplyr::count(Sublineage)
  colnames(wave2.desc)[2]<-"wave2.Desc"
  
  #wave 3 = after intervention
  wave3.desc<-sublin.long.unq[[k]] %>%
    filter(Date>as.Date(int.end)) %>%
      filter(State %in% provs) %>%
    dplyr::count(Sublineage)
  colnames(wave3.desc)[2]<-"wave3.Desc"
  
  sb2<-sb2%>%
    left_join(wave1.desc,by="Sublineage") %>%
    left_join(wave2.desc,"Sublineage") %>%
    left_join(wave3.desc,"Sublineage")
  
  # head(sb2)
  p.size.w1<-ggplot(sb2, aes(area = wave1.Desc, fill = Lineage,
                             label=paste(Sublineage,"\n","n=",wave1.Desc,sep=""))) +
    geom_treemap()+
    LinFillScale+
    geom_treemap_text(colour = "white", place = "centre",
                      grow = TRUE,reflow=T,min.size = 0.4,
                      padding.x=unit(1,"mm"),padding.y=unit(1,"mm"))+
    theme(legend.position="none",
          plot.margin=margin(4,4,4,4,unit="pt"))
  p.size.w1
  ggsave(file=paste(f.out,"/Wave1_SublinSizesUnq.png",sep=""),width=3,height=2,units = "in")
  
  p.size.w2<-ggplot(sb2, aes(area = wave2.Desc, fill = Lineage,
                             label=paste(Sublineage,"\n","n=",wave2.Desc,sep=""))) +
    geom_treemap()+
    LinFillScale+
    geom_treemap_text(colour = "white", place = "centre",
                      grow = TRUE,reflow=T,min.size = 0.4,
                      padding.x=unit(1,"mm"),padding.y=unit(1,"mm"))+
    theme(legend.position="none",
          plot.margin=margin(4,4,4,4,unit="pt"))
  p.size.w2
  ggsave(file=paste(f.out,"/Wave2_SublinSizesUnq.png",sep=""),width=3,height=2,units = "in")
  
  p.size.w3<-ggplot(sb2, aes(area = wave3.Desc, fill = Lineage,
                             label=paste(Sublineage,"\n","n=",wave3.Desc,sep=""))) +
    geom_treemap()+
    LinFillScale+
    geom_treemap_text(colour = "white", place = "centre",
                      grow = TRUE,reflow=T,min.size = 0.4,
                      padding.x=unit(1,"mm"),padding.y=unit(1,"mm"))+
    theme(legend.position="none",
          plot.margin=margin(4,4,4,4,unit="pt"))
  p.size.w3
  ggsave(file=paste(f.out,"/Wave3_SublinSizesUnq.png",sep=""),width=3,height=2,units = "in")
  
  
  ## Could make this animated so rects change over time
  #see https://github.com/wilkox/treemapify/tree/3debdbf2350e6d44a2ac4f7eb5e4d7f8c74ab210
  
  #descendants row
  size.row<-plot_grid(p.size.w1,p.size.w2,p.size.w3,
                      ncol=3, align="h")
  size.row
  ggsave(file=paste(f.out,"/WavesSublinSize.png",sep=""),width=8,height=3,units = "in")
}
```


# Sublineage importations over time
## Calculate rolling mean of importations by 1) origin, 2) destination using tmrca
```{r}
Parent.Location.sum.boots<-replicate(n=n.B,vector())
Node.Location.sum.boots<-replicate(n=n.B,vector())
Parent.Location.sum.boots.full<-replicate(n=n.B,vector())
Node.Location.sum.boots.full<-replicate(n=n.B,vector())

for (k in 1:n.B){
  #make sure this a date
  sum.boots[[k]]$tmrca.dt<-as.Date(sum.boots[[k]]$tmrca.dt)
  
  #### Calculate a rolling 7-day mean for origins ####
  ## count the importations by origin location over time
  Parent.Location.sum.boots[[k]]<-sum.boots[[k]] %>%
    dplyr::select(Parent.Location, Lineage,tmrca.dt) %>%
    dplyr::group_by(tmrca.dt, Parent.Location) %>%
    dplyr::summarize(.groups="rowwise", total=n()) %>%
    dplyr::arrange(desc(Parent.Location)) %>% 
    dplyr::group_by(Parent.Location) 
  
  #need to add rows for missing dates
  alldays<-seq(ymd(first(sort(Parent.Location.sum.boots[[k]]$tmrca.dt))),
      ymd(last(sort(Parent.Location.sum.boots[[k]]$tmrca.dt))),
      by='1 day')
  
  #make a empty df in same structure as above then populate it
  nL<-length(unique(Parent.Location.sum.boots[[k]]$Parent.Location))
  nD<-length(alldays)
  Parent.Location.sum.boots.full[[k]]<-data.frame(tmrca.dt=rep(alldays,times=nL),
Parent.Location = sort(rep(unique(Parent.Location.sum.boots[[k]]$Parent.Location),times=nD)),
                                 total=0)

  #populate it
  for (i in 1:nrow(Parent.Location.sum.boots.full[[k]])){
    #look for a match
    match<-which(Parent.Location.sum.boots[[k]]$Parent.Location==Parent.Location.sum.boots.full[[k]]$Parent.Location[i] &
            Parent.Location.sum.boots[[k]]$tmrca.dt==Parent.Location.sum.boots.full[[k]]$tmrca.dt[i])
    if(length(match)==0) next #no match, no change
    #else, replace:
    Parent.Location.sum.boots.full[[k]]$total[i]<-Parent.Location.sum.boots[[k]]$total[match]
  }

  Parent.Location.sum.boots.full[[k]]<-Parent.Location.sum.boots.full[[k]] %>% 
    dplyr::mutate(intros_mean7d = zoo::rollmean(total, k = 7, fill = NA),
                  intros_mean14d = zoo::rollmean(total, k = 14, fill = NA),
                  intros_median7d = zoo::rollmedian(total, k = 7, fill = NA),
                  intros_sum7d = zoo::rollsum(total, k = 7, fill = NA,align="right")) %>% #right align to sum all prev
    #rolling mean and median weekly importation rate
    dplyr::mutate(intros_meansum7d = zoo::rollmean(intros_sum7d, k = 7, fill = NA), 
                  intros_mediansum7d = zoo::rollmedian(intros_sum7d, k = 7, fill = NA),) %>%
    dplyr::ungroup()

  ## count the importations by node.location over time
  Node.Location.sum.boots[[k]]<-sum.boots[[k]] %>%
    dplyr::select(Node.Location, Lineage,tmrca.dt) %>%
    group_by(tmrca.dt, Node.Location) %>%
    dplyr::summarize(.groups="rowwise", total=n()) %>%
    dplyr::arrange(desc(Node.Location)) %>% 
    dplyr::group_by(Node.Location) 
  
  #need to add rows for missing dates
  alldays<-seq(ymd(first(sort(Node.Location.sum.boots[[k]]$tmrca.dt))),
      ymd(last(sort(Node.Location.sum.boots[[k]]$tmrca.dt))),
      by='1 day')
  
  #make a empty df in same structure as above then populate it
  nL<-length(unique(Node.Location.sum.boots[[k]]$Node.Location))
  nD<-length(alldays)
  Node.Location.sum.boots.full[[k]]<-data.frame(tmrca.dt=rep(alldays,times=nL),
                                 Node.Location=sort(rep(unique(Node.Location.sum.boots[[k]]$Node.Location),times=nD)),
                                 total=0)
  # nrow(Node.Location.sum.boots[[k]].empty)==nD*nL      
  
  #populate it
  for (i in 1:nrow(Node.Location.sum.boots.full[[k]])){
    #look for a match
    match<-which(Node.Location.sum.boots[[k]]$Node.Location==Node.Location.sum.boots.full[[k]]$Node.Location[i] &
            Node.Location.sum.boots[[k]]$tmrca.dt==Node.Location.sum.boots.full[[k]]$tmrca.dt[i])
    if(length(match)==0) next #no match, no change
    #else, replace:
    Node.Location.sum.boots.full[[k]]$total[i]<-Node.Location.sum.boots[[k]]$total[match]
  }

  Node.Location.sum.boots.full[[k]]<-Node.Location.sum.boots.full[[k]] %>% 
    dplyr::mutate(intros_mean7d = zoo::rollmean(total, k = 7, fill = NA),
                  intros_mean14d = zoo::rollmean(total, k = 14, fill = NA),
                  intros_median7d = zoo::rollmedian(total, k = 7, fill = NA),
                  intros_sum7d = zoo::rollsum(total, k = 7, fill = NA,align="right")) %>% 
    #rolling mean and median weekly importation rate
    dplyr::mutate(intros_meansum7d = zoo::rollmean(intros_sum7d, k = 7, fill = NA), 
                  intros_mediansum7d = zoo::rollmedian(intros_sum7d, k = 7, fill = NA),) %>%
    dplyr::ungroup()

}

## Summarize the rolling means overall

#go through each list item/subsample
for (k in 1:n.B){
  ## add a column for subsample
  Parent.Location.sum.boots.full[[k]]$SampleSet<-paste("Sample",BOOTS[k])
}

## rbind the summaries
sum.Par.Roll<-bind_rows(Parent.Location.sum.boots.full)
#summarize the mean and confint
sum.Par.Roll.summary<-sum.Par.Roll %>% dplyr::group_by(tmrca.dt, Parent.Location) %>%
  dplyr::summarize(.groups="rowwise",
                   intros_meansum7d.mean=(mean(intros_meansum7d,na.rm=T)),
                   intros_meansum7d.sd=sd(intros_meansum7d,na.rm=T)) %>%
  as.data.frame()

#order the geos
ord.count<-sum.Par.Roll.summary%>% dplyr::group_by(Parent.Location) %>%
  dplyr::summarise(.groups="rowwise",n=sum(intros_meansum7d.mean,na.rm=T)) %>% as.data.frame()
# ord.count<-ord.count[-which(ord.count$n=="NaN"),]
ord.count<-ord.count[rev(order(ord.count$n)),'Parent.Location']
sum.Par.Roll.summary$Parent.Location<-factor(sum.Par.Roll.summary$Parent.Location,levels=ord.count)

#Global specific fill 
GlobRegFillScale<-scale_fill_manual(name = "Location",values = globalPalette.ch[match(ord.count,names(globalPalette.ch))], na.value="grey60")
GlobRegColScale<-scale_color_manual(name = "Location",values = globalPalette.ch[match(ord.count,names(globalPalette.ch))], na.value="grey60")

## BY PROVINCE
for (k in 1:n.B){
  Node.Location.sum.boots.full[[k]]$SampleSet<-paste("Sample",BOOTS[k])
}

sum.Prov.Roll<-bind_rows(Node.Location.sum.boots.full)

#summarize the mean and confint
sum.Prov.Roll.summary<-sum.Prov.Roll %>% dplyr::group_by(tmrca.dt, Node.Location) %>%
  dplyr::summarize(.groups="rowwise",
                   intros_meansum7d.mean=(mean(intros_meansum7d,na.rm=T)),
                   intros_meansum7d.sd=(sd(intros_meansum7d,na.rm=T))) %>%
  as.data.frame()

#make sure proper order
ord.prov<-sum.Prov.Roll.summary%>% dplyr::group_by(Node.Location) %>%
  dplyr::summarise(.groups="rowwise",n=sum(intros_meansum7d.mean,na.rm = T)) %>% as.data.frame()
ord.prov<-ord.prov[rev(order(ord.prov$n)),'Node.Location']
sum.Prov.Roll.summary$Node.Location<-factor(sum.Prov.Roll.summary$Node.Location,levels=ord.prov)

## Add confidence upper and lower
t.here<-qt(0.025,(n.B-1),lower.tail=F)
sum.Par.Roll.summary<-sum.Par.Roll.summary %>% mutate(upper.CI=(intros_meansum7d.mean)+(intros_meansum7d.sd/sqrt(10)*t.here),
       lower.CI=(intros_meansum7d.mean)-(intros_meansum7d.sd/sqrt(10)*t.here))

## Add an indidicator for source country vs not to add alpha channel to other lines
sum.Par.Roll.summary$focal<-0
sum.Par.Roll.summary$focal[which(sum.Par.Roll.summary$Parent.Location%in%focal.source)]<-1

#PRovince specific fill 
ProvFillScale<-scale_fill_manual(name = "Location",values = globalPalette.ch[match(ord.prov,names(globalPalette.ch))], na.value="grey60")

ProvColScale<-scale_color_manual(name = "Location",values = globalPalette.ch[match(ord.prov,names(globalPalette.ch))], na.value="grey60")

write.csv(sum.Par.Roll.summary, paste0(f.out,"sum.par.roll.summary.csv"))
```

## Plot sublineages over time using rolling rates, by tmrca, by origin or dest
```{r}
#set some limits
all.y<-sum.Par.Roll.summary %>% dplyr::group_by(tmrca.dt) %>% dplyr::summarize(allsum=sum(intros_meansum7d.mean,na.rm=T))
y.max.all<-ceiling(max(all.y$allsum,na.rm = T))
y.jumps1<-ceiling(y.max.all/5)
y.max.singles<-ceiling(max(sum.Par.Roll.summary$intros_meansum7d.mean,na.rm=T))
y.jumps<-ceiling(y.max.singles/5)
y.lim<-c(0,y.max.all)

p1<-sum.Par.Roll.summary %>%
  ggplot(aes(x=tmrca.dt,y=intros_meansum7d.mean,group=Parent.Location,fill=Parent.Location))+
  pubThemeDate+
  theme(text=element_text(size=10,face="bold"),
        legend.position = "top",
        legend.text=element_text(size=rel(0.7)),
        legend.title=element_text(size=rel(0.8)),
        legend.margin=margin(1,1,1,1,"pt"))+
  # annotate(geom="rect",xmin = as.Date(int.start), xmax = as.Date(int.end),
  #            ymin = y.lim[1], ymax =y.lim[2], color="grey85",size=0,  fill="grey80")+
  # annotate(geom="text",x = as.Date(int.start),y=y.lim[2], vjust=1, hjust=0,
  #          label=int.descrip,fontface="italic",color="grey25",size=3)+
    geom_density(stat="identity", position="stack",lwd=0,alpha=0.9)+
  GlobRegFillScale+
  labs(x="Date of most recent common ancestor",y=paste0("Sublineages per week"), fill="Origin Location")+
  scaleDateFlex+
  scale_y_continuous(expand=c(0,0),limits=y.lim,breaks=seq(0,max(y.lim),y.jumps1))+
  guides(fill = guide_legend(keywidth = 0.6,keyheight=0.6,title.position = "top",title="Global region",legend.spacing=0,nrow=2))
# p1
# ggsave(paste(f.out,"/Rolling-sublin-importRate.png",sep=""),height=4,width=6)

##PLOT AS LINE WITH CONFIDENCE INTERVALS
alphavals<-c(0.3,0.9)
names(alphavals)<-c("0","1")  
sum.Par.Roll.summary$focal<-as.factor(sum.Par.Roll.summary$focal)
y.lim2<-c(0,(y.max.singles+1))

p1.line.ci<-sum.Par.Roll.summary %>%
  ggplot(aes(x=tmrca.dt,y=intros_meansum7d.mean,group=Parent.Location))+
  pubThemeDate+
  theme(text=element_text(size=10,face="bold"),
        legend.position = c(0.05,0.65),
        legend.justification = "left",
        legend.text=element_text(size=rel(0.5)),
        legend.title=element_text(size=rel(0.6)),
        legend.margin=margin(1,1,1,1,"pt"))+
  # annotate(geom="rect",xmin = as.Date(int.start), 
  #          xmax = as.Date(int.end),
  #            ymin = y.lim2[1], ymax =y.lim2[2], 
  #          color="grey85",size=0,  fill="grey80")+
  # annotate(geom="text",x = as.Date(int.start)+int.duration/2,
  #          y=y.lim2[2]-0.15, vjust=1, hjust=0.5,
  #          label=int.descrip,fontface="italic",color="grey25",size=3)+
  geom_ribbon(aes(ymin=lower.CI,ymax=upper.CI, 
                  fill=Parent.Location, alpha=focal))+
  geom_line(stat="identity",lwd=1,aes(alpha=focal,color=Parent.Location))+
  GlobRegColScale+
  GlobRegFillScale+
  scale_alpha_manual(values=alphavals)+
  labs(x="Date of most recent common ancestor",y=paste0("Sublineages per week"), fill="Origin Location")+
  scaleDateFlex+
  scale_y_continuous(expand=c(0,0),breaks=seq(0,y.max.singles,y.jumps))+
 guides(fill = guide_legend(keywidth = 0.4,keyheight=0.4,
                              title.position = "top",title="Global origin",
                              legend.spacing=0,ncol=1),
         alpha="none", color="none")+
  coord_cartesian(ylim=y.lim2)
p1.line.ci
ggsave(paste(f.out,"/Rolling-sublin-importRate_line_confint.png",sep=""),height=3,width=3.5)

#Line no CI
p1.line<-sum.Par.Roll.summary %>%
  ggplot(aes(x=tmrca.dt,y=intros_meansum7d.mean,group=Parent.Location))+
  pubThemeDate+
  theme(text=element_text(size=10,face="bold"),
        legend.position = c(0.05,0.65),
        legend.justification = "left",        
        legend.text=element_text(size=rel(0.5)),
        legend.title=element_text(size=rel(0.6)),
        legend.margin=margin(1,1,1,1,"pt"))+
  # annotate(geom="rect",xmin = as.Date(int.start), xmax = as.Date(int.end),
  #            ymin = y.lim2[1], ymax =y.lim2[2], color="grey85",size=0,  fill="grey80")+
  # annotate(geom="text",x = as.Date(int.start)+int.duration/2,
  #          y=y.lim2[2]-0.15, vjust=1, hjust=0.5,
  #          label=int.descrip,fontface="italic",color="grey25",size=3)+
  geom_line(stat="identity",lwd=1,aes(alpha=focal,color=Parent.Location))+
  GlobRegColScale+
  # GlobRegFillScale+
  scale_alpha_manual(values=alphavals)+
  labs(x="Date of most recent common ancestor",y=paste0("Sublineages per week"), fill="Origin Location")+
  scaleDateFlex+
  scale_y_continuous(expand=c(0,0),breaks=seq(0,y.max.singles,y.jumps))+
  guides(color = guide_legend(keywidth = 0.4,keyheight=0.4,
                              title.position = "top",title="Global origin",
                              legend.spacing=0,ncol=1),
         alpha="none")+
  coord_cartesian(ylim=y.lim2)
p1.line
ggsave(paste(f.out,"/Rolling-sublin-importRate_line.png",sep=""),height=3,width=3.5)

#rolling importation rate, by province destination
y.lim<-c(0,y.max.all)
p2<-sum.Prov.Roll.summary %>%
  ggplot(aes(x=tmrca.dt,y=intros_meansum7d.mean,group=Node.Location,fill=Node.Location))+
  pubThemeDate+
  theme(text=element_text(size=10,face="bold"),
        legend.position = "top",
        legend.text=element_text(size=rel(0.7)),
        legend.title=element_text(size=rel(0.8)),
        legend.margin=margin(1,1,1,1,"pt"))+
  # annotate(geom="rect",xmin = as.Date(int.start), xmax = as.Date(int.end),
  #            ymin = y.lim[1], ymax =y.lim[2], color="grey85",size=0,  fill="grey80")+
  # annotate(geom="text",x = as.Date(int.start),y=y.lim[2], vjust=1, hjust=0,
  #          label=int.descrip,fontface="italic",color="grey25",size=3)+
  scaleDateFlex+
  labs(x="Date of most recent common ancestor",y=paste0("Sublineages per week"))+
  geom_density(stat="identity", position="stack",lwd=0,alpha=0.9)+
  ProvFillScale+
  scale_y_continuous(expand=c(0,0),limits=y.lim,breaks=seq(0,y.max.all,y.jumps1))+
  guides(fill = guide_legend(keywidth = 0.6,keyheight=0.6,title.position = "top",title="Province",legend.spacing=0,nrow=2))
# p2
# ggsave(paste(f.out,"/Rolling-sublin-importRate-byprovince.png",sep=""),height=4,width=6)

y.lim3<-c(0,y.max.singles)
p2.line<-sum.Prov.Roll.summary %>%
  ggplot(aes(x=tmrca.dt,y=intros_meansum7d.mean,group=Node.Location,color=Node.Location))+
  pubThemeDate+
  theme(text=element_text(size=10,face="bold"),
        legend.position = "top",
        legend.text=element_text(size=rel(0.7)),
        legend.title=element_text(size=rel(0.8)),
        legend.margin=margin(1,1,1,1,"pt"))+
  #   annotate(geom="rect",xmin = as.Date(int.start), xmax = as.Date(int.end),
  #            ymin = y.lim3[1], ymax =y.lim3[2], color="grey85",size=0,  fill="grey80")+
  # annotate(geom="text",x = as.Date(int.start),y=y.lim3[2], vjust=1, hjust=0,
  #          label=int.descrip,fontface="italic",color="grey25",size=3)+
  scaleDateFlex+
  labs(x="Date of most recent common ancestor",y=paste0("Sublineages per week"))+
  geom_line(stat="identity", lwd=1,alpha=0.9)+
  ProvColScale+
  scale_y_continuous(expand=c(0,0),limits=y.lim3,breaks=seq(0,y.max.singles,y.jumps))+
  guides(color = guide_legend(keywidth = 0.6,keyheight=0.6,title.position = "top",title="Province",legend.spacing=0,nrow=2))
p2.line
ggsave(paste(f.out,"/Rolling-sublin-importRate-byprovince_line.png",sep=""),height=4,width=6)

```


## re-generate this plot using just sum.par.roll.summary
```{r}
# sum.Par.Roll.summary<-read.csv("2023-02-10_beta_analysis/sum.par.roll.summary.csv")

# all.y<-sum.Par.Roll.summary %>% dplyr::group_by(tmrca.dt) %>% dplyr::summarize(allsum=sum(intros_meansum7d.mean,na.rm=T))
# y.max.all<-ceiling(max(all.y$allsum,na.rm = T))
# y.jumps1<-ceiling(y.max.all/5)
y.max.singles<-ceiling(max(sum.Par.Roll.summary$intros_meansum7d.mean,na.rm=T))
y.jumps<-ceiling(y.max.singles/5)
# y.lim<-c(0,y.max.all)

##PLOT AS LINE WITH CONFIDENCE INTERVALS
alphavals<-c(0.3,0.9)
names(alphavals)<-c("0","1")  
sum.Par.Roll.summary$focal<-as.factor(sum.Par.Roll.summary$focal)
y.lim2<-c(0,(y.max.singles+2))

##set up colors
#order the geos
ord.count<-sum.Par.Roll.summary%>% dplyr::group_by(Parent.Location) %>%
  dplyr::summarise(.groups="rowwise",n=sum(intros_meansum7d.mean,na.rm=T)) %>% as.data.frame()
# ord.count<-ord.count[-which(ord.count$n=="NaN"),]
ord.count<-ord.count[rev(order(ord.count$n)),'Parent.Location']
sum.Par.Roll.summary$Parent.Location<-factor(sum.Par.Roll.summary$Parent.Location,levels=ord.count)

#Global specific fill 
GlobRegFillScale<-scale_fill_manual(name = "Location",values = globalPalette.ch[match(ord.count,names(globalPalette.ch))], na.value="grey60")
GlobRegColScale<-scale_color_manual(name = "Location",values = globalPalette.ch[match(ord.count,names(globalPalette.ch))], na.value="grey60")

#remove the confidence intervals for any but the focal source
sum.Par.Roll.summary$upper.CI[which(sum.Par.Roll.summary$focal==0)]<-NA
sum.Par.Roll.summary$lower.CI[which(sum.Par.Roll.summary$focal==0)]<-NA

sum.Par.Roll.summary$tmrca.dt<-as.Date(sum.Par.Roll.summary$tmrca.dt)

y.lim2<-c(0,3.5)
p1.line.ci<-sum.Par.Roll.summary %>%
  ggplot(aes(x=tmrca.dt,y=intros_meansum7d.mean,group=Parent.Location))+
  pubThemeDate+
  theme(text=element_text(size=10,face="bold"),
        legend.position = c(0.6,0.75),
        legend.justification=c(0,0.5), 
        legend.text=element_text(size=rel(0.8)),
        legend.title=element_text(size=rel(0.9)),
        legend.margin=margin(1,1,1,1,"pt"))+
  # annotate(geom="rect",xmin = as.Date(int.start), 
  #          xmax = as.Date(int.end),
  #            ymin = y.lim2[1], ymax =y.lim2[2], 
  #          color="grey85",size=0,  fill="grey80",alpha=0.8)+
  # annotate(geom="text",x = as.Date(int.start)+int.duration/2,
  #          y=y.lim2[2]-0.1, vjust=1, hjust=0.5,
  #          label=int.descrip,fontface="italic",color="grey25",size=4)+
  geom_ribbon(aes(ymin=lower.CI,ymax=upper.CI, 
                  fill=Parent.Location, alpha=focal))+
  geom_line(stat="identity",lwd=1,aes(alpha=focal,color=Parent.Location))+
  GlobRegColScale+
  GlobRegFillScale+
  scale_alpha_manual(values=alphavals)+
  labs(x="Date of most recent common ancestor",y=paste0("Sublineages per week"), fill="Origin Location")+
  scaleDateFlexLess+
  scale_y_continuous(expand=c(0,0),breaks=seq(0,y.lim2[2],y.jumps))+
 guides(fill = guide_legend(keywidth = 0.6,keyheight=0.6,
                              title.position = "top",title="Global origin",
                              legend.spacing=0,ncol=1),
                               # override.aes = list(alpha = c(0.3,0.3,0.3,0.9,0.3,0.3,0.3,0.3,0.3))),
        color="none",
        alpha="none")+
  coord_cartesian(ylim=y.lim2)
p1.line.ci
ggsave(paste(f.out,"/Rolling-sublin-importRate_line_confint.png",sep=""),height=3,width=3.5)


##Plot as above, but no legend, limited scale to figure end date
# direct labels for big contributors
p1.line.ci.noleg<-sum.Par.Roll.summary %>%
  ggplot(aes(x=tmrca.dt,y=intros_meansum7d.mean,group=Parent.Location))+
  pubThemeDate+
  theme(text=element_text(size=10,face="bold"),
        legend.position = "none",#c(0.8,0.7),
        # legend.text=element_text(size=rel(0.7)),
        # legend.title=element_text(size=rel(0.8)),
        plot.margin=margin(20,4,1,4,"pt"),
        axis.title.y=element_text(vjust=2))+
  # annotate(geom="rect",xmin = as.Date(int.start), 
  #          xmax = as.Date(int.end),
  #            ymin = y.lim2[1], ymax =y.lim2[2], 
  #          color="grey85",size=0,  fill="grey80")+
  # annotate(geom="text",x = as.Date(int.start)+int.duration/2,
  #          y=y.lim2[2]-0.1, vjust=1, hjust=0.5,
  #          label=int.descrip,fontface="italic",color="grey25",size=3)+
  geom_ribbon(aes(ymin=lower.CI,ymax=upper.CI, 
                  fill=Parent.Location, alpha=focal))+
  geom_line(stat="identity",lwd=1,aes(alpha=focal,color=Parent.Location))+
  GlobRegColScale+
  GlobRegFillScale+
  scale_alpha_manual(values=alphavals)+
  labs(x="Date of most recent common ancestor",y=paste0("Sublineages per week"), fill="Origin Location")+
  scaleDateFlexLess+
  scale_y_continuous(expand=c(0,0),breaks=seq(0,y.max.singles,y.jumps))+
 guides(fill = guide_legend(keywidth = 0.6,keyheight=0.6,
                              title.position = "top",title="Global origin",
                              legend.spacing=0,ncol=1),
         alpha="none", color="none")+
  coord_cartesian(ylim=y.lim2)
  # annotate(geom="text",x=as.Date("2020-12-12"),y=1.3, label="South Africa",
  #          color=globalPalette.ch[which(names(globalPalette.ch)=="South Africa")],size=4)+
  # annotate(geom="text",x=as.Date("2021-05-16"),y=1.6, label="Africa",
  #          color=globalPalette.ch[which(names(globalPalette.ch)=="Africa")],alpha=0.8,size=2.5)+
  # annotate(geom="text",x=as.Date("2021-04-17"),y=2.4,label="Asia",
  #          color=globalPalette.ch[which(names(globalPalette.ch)=="Asia")],alpha=0.8,size=2.5)+
  # annotate(geom="text",x=as.Date("2021-02-07"),y=1.25,label="Europe",
  #          color=globalPalette.ch[which(names(globalPalette.ch)=="Europe")],alpha=0.8,size=2.5)

p1.line.ci.noleg
ggsave(paste(f.out,"/Rolling-sublin-importRate_line_confint_noleg.png",sep=""),height=3,width=3.5)


```



```{r}
#make a list of grobs
## add in the Canadian province representation plots
plot.row<-plot_grid(p1,p2,ncol=2,rel_widths = c(1,1),labels=c("A" ,"B"))
png(file=paste(f.out,"/Sublin_OverTime_OriginsDestinations.png",sep=""),
          width=9,height=4,units = "in", bg = "white",res=200)
print(plot.row)
dev.off()
```

## summarize Maximum rolling rates
```{r}
#overall sum of new sublineages/week in Canada max
sum.Roll.total<-sum.Prov.Roll.summary %>% dplyr::group_by(tmrca.dt) %>%
  dplyr::summarize(.groups="rowwise",
                   total_meansum7d.mean=(sum(intros_meansum7d.mean,na.rm=T)),
                   total_meansum7d.sd=(sum(intros_meansum7d.sd,na.rm=T))) %>%
  as.data.frame()
max.overall<-head(na.omit(sum.Roll.total[rev(order(sum.Roll.total$total_meansum7d.mean)),]),n=1)
dt.temp<-max.overall[1,1]
cat(paste0("Max weekly sublin importation rate overall on ", dt.temp,": ",
           mean.95ci.givenmsd(m=max.overall[2],sd=max.overall[3],n=n.B,2)),
    file=text.out,sep="\n",append=T)

#Max from focal.source
max.mean.focal<-max(sum.Par.Roll.summary$intros_meansum7d.mean[sum.Par.Roll.summary$Parent.Location%in%focal.source],na.rm=T) 
max.sd.focal<-sum.Par.Roll.summary$intros_meansum7d.sd[which(sum.Par.Roll.summary$intros_meansum7d.mean ==max(sum.Par.Roll.summary$intros_meansum7d.mean[sum.Par.Roll.summary$Parent.Location%in%focal.source],na.rm=T) )]
dt.focal<-sum.Par.Roll.summary$tmrca.dt[which(sum.Par.Roll.summary$intros_meansum7d.mean==max(sum.Par.Roll.summary$intros_meansum7d.mean[sum.Par.Roll.summary$Parent.Location%in%focal.source],na.rm=T)) ] 

cat(paste0("Max weekly sublin importation rate from ",focal.source, " on ",dt.focal,
           ": ", mean.95ci.givenmsd(m=max.mean.focal,sd=max.sd.focal, n.B, 2) ),
    file=text.out,sep="\n",append=T)

## Max from USA 
max.mean.usa<-max(sum.Par.Roll.summary$intros_meansum7d.mean[sum.Par.Roll.summary$Parent.Location=="USA"],na.rm=T) 
max.sd.usa<-sum.Par.Roll.summary$intros_meansum7d.sd[which(sum.Par.Roll.summary$intros_meansum7d.mean ==max.mean.usa )]
dt.usa<-sum.Par.Roll.summary$tmrca.dt[which(sum.Par.Roll.summary$intros_meansum7d.mean==max.mean.usa) ] 
cat(paste0("Max weekly sublin importation rate from ","USA", " on ",dt.usa,
           ": ", mean.95ci.givenmsd(m=max.mean.usa,sd=max.sd.usa, n.B, 2) ),
    file=text.out,sep="\n",append=T)

## IF there was a var-specifc intervention, calculate sublin import on date implemented vs two weeks after from focal source
if(int.yn==T){
   rate.pre<-sum.Par.Roll.summary %>% filter(Parent.Location%in%focal.source) %>% filter(tmrca.dt==int.start)
   
   rate.2wk<-sum.Par.Roll.summary %>% filter(Parent.Location%in%focal.source) %>% filter(tmrca.dt==(int.start+14))
   
    rate.4wk<-sum.Par.Roll.summary %>% filter(Parent.Location%in%focal.source) %>% filter(tmrca.dt==(int.start+28))
   
   cat(paste0("Weekly sublin importation rate pre-int from ",focal.source, 
              " on ",int.start,": ", 
              mean.95ci.givenmsd(m=rate.pre$intros_meansum7d.mean,
                                    sd=rate.pre$intros_meansum7d.sd, n.B, 2) ),
    file=text.out,sep="\n",append=T)
   
   cat(paste0("Weekly sublin importation rate 2-weeks post-int from ",focal.source, 
              " on ",int.start+14, ": ", 
              mean.95ci.givenmsd(m=rate.2wk$intros_meansum7d.mean,
                                    sd=rate.2wk$intros_meansum7d.sd, n.B, 2) ),
    file=text.out,sep="\n",append=T)
   
   
   ## FOLD DECREASE from pre to 2wk
   fc2wk.focal<-c()
   fc4wk.focal<-c()

   for (k in 1:n.B){
     temp<-Parent.Location.sum.boots.full[[k]] %>% 
      dplyr::filter(Parent.Location%in%focal.source) %>%
      as.data.frame()
     temp.pre<-temp %>% filter(tmrca.dt==int.start)
     temp.2wk<-temp %>% filter(tmrca.dt==(int.start+14))
     temp.4wk<-temp %>% filter(tmrca.dt==(int.start+28))

     fc2wk<-temp.pre$intros_meansum7d/temp.2wk$intros_meansum7d #fold change 2wk/pre (ex: 10/1)
     fc2wk.focal<-c(fc2wk.focal, fc2wk)
     
     fc4wk<-temp.pre$intros_meansum7d/temp.4wk$intros_meansum7d #fold change 2wk
     fc4wk.focal<-c(fc4wk.focal, fc4wk)
   }
   fc2wk.focal<-fc2wk.focal[is.finite(fc2wk.focal)]
   fc4wk.focal<-fc4wk.focal[is.finite(fc4wk.focal)]
   
   mean.fc.2wk<-mean.95ci.X(fc2wk.focal,2)
   mean.fc.4wk<-mean.95ci.X(fc4wk.focal,2)

   cat(paste0("Fold decrease sublin rate pre-int to 2-weeks after int from ",focal.source, 
              ": ", mean.fc.2wk),    file=text.out,sep="\n",append=T)
   
   cat(paste0("Fold decrease sublin rate pre-int to 4-weeks after int from ",focal.source, 
              ": ", mean.fc.4wk),    file=text.out,sep="\n",append=T)
   
}

```

## how many sublineages had >100 or >500 descendants?
```{r}
hund<-c()
hund.perc<-c()
hund.des<-c()
for (k in 1:n.B){ 
  big<-which(sum.boots[[k]]$N.Desc.glob>99)
  hund<-c(hund, length(big))
  #what percent of sublins were big (>99)
  hund.perc<-c(hund.perc, length(big)/nrow(sum.boots[[k]])*100)
  
  # What percent of sampled cases in Canada were downstream of these sublineages?
  restr<-sublin.long.unq[[k]] [ sublin.long.unq[[k]]$Sublineage %in% sum.boots[[k]]$Sublineage[big] ,]
  can.des<-length(which(restr$State %in% provs ))
  hund.des<-c(hund.des, can.des/nrow(meta.boots[[k]][meta.boots[[k]]$country=="Canada",])*100)
}
mean.95ci.X(hund) 
mean.95ci.X(hund.perc,1) 
mean.95ci.X(hund.des,1)  

# how many sublineagse had >500 descendants?
fvhund<-c()
fvhund.perc<-c()
fvhund.des<-c()
for (k in 1:n.B){ 
  big<-which(sum.boots[[k]]$N.Desc.glob>499)
  fvhund<-c(fvhund, length(big))
  fvhund.perc<-c(fvhund.perc, length(big)/nrow(sum.boots[[k]])*100)
  # What percent of sampled cases in Canada were downstream of these sublineages?
  restr<-sublin.long.unq[[k]] [ sublin.long.unq[[k]]$Sublineage %in% sum.boots[[k]]$Sublineage[big] ,]
  # restr<-restr[-which(duplicated(restr$Descendant.AccessionIDs)),]
  can.des<-length(which(restr$State %in% provs))
  fvhund.des<-c(fvhund.des, can.des/nrow(meta.boots[[k]][meta.boots[[k]]$country=="Canada",])*100)
}
mean.95ci.X(fvhund)
mean.95ci.X(fvhund.perc,1)
mean.95ci.X(fvhund.des,1) 

## ADD TO TEXT EXPORT 
cat(paste0("# sublineages with >=100 desc: ",mean.95ci.X(hund), 
           ", accounting for ",mean.95ci.X(hund.perc,1) ,
           "% of sublineages and ",mean.95ci.X(hund.des,1) ,"% of Canadian descendants"),
    file=text.out,sep="\n",append=T)

cat(paste0("# sublineages with >=500 desc: ",mean.95ci.X(fvhund), 
           ", accounting for ",mean.95ci.X(fvhund.perc,1) ,
           "% of sublineages and ",mean.95ci.X(fvhund.des,1) ,"% of Canadian descendants"),
    file=text.out,sep="\n",append=T)
```

## Sublineage longevity and recency analysis
```{r }
# head(sum.boots[[k]]$longevityTMRCA)

#distrib of longevity (life span)
k=1
P3<-ggplot(sum.boots[[k]])+
  geom_density(aes(x=longevityTMRCA, color="deepskyblue3"),alpha=0.5)+ 
  scale_color_manual(values=c("deepskyblue3"))+ 
  pubTheme+
  labs(x="Sublineage longevity (days)",y="Density")+
  annotate(geom="text",x=100,y=0.007,label=paste("Median longevity =\n", median(sum.boots[[k]]$longevityTMRCA)," days",sep=""),hjust=0,color="deepskyblue3")+
  theme(legend.position="none")
P3
ggsave(paste(f.out,"/SublineagelongevityDensity.png",sep=""),height=4,width=4, units="in")


#is it associated with tmrca (did they reduce over time?)
ggplot(sum.boots[[k]])+
  geom_point(aes(y=longevityTMRCA, x=tmrca.dt))

#looks like yes
mod.long<-lm(as.numeric(longevityTMRCA) ~ tmrca.dt ,data=sum.boots[[k]])
# summary(mod.long)
newdata2 <- data.frame(
  tmrca.dt = rep(seq(from = min(sum.boots[[k]]$tmrca.dt), to = max(sum.boots[[k]]$tmrca.dt), length.out = 100), 2))

newdata2 <- cbind(newdata2, predict(mod.long, newdata2, type = "response", se.fit=TRUE))
newdata2 <- within(newdata2, {
  longevityTMRCA <- (fit)
  LL <- (fit - 1.96 * se.fit)
  UL <- (fit + 1.96 * se.fit)
})


#plot again
P5<-ggplot(sum.boots[[k]])+
  geom_point(aes(y=longevityTMRCA, x=tmrca.dt),alpha=0.6)+
  scale_color_manual(values=c("deepskyblue3"))+
  geom_ribbon(data=newdata,aes(x=tmrca.dt, ymin=(LL),ymax=(UL)),fill="deepskyblue3",alpha = 0.25,) +
  geom_line(data=newdata,aes(x=tmrca.dt, y=longevityTMRCA), color="deepskyblue3",size = 0.5,alpha=0.5,) +
  pubThemeDate+
  theme(legend.position="none")+
  labs(x="Date of most recent common ancestor",y="Sublineage longevity (days)")+
  scaleDateFlex+
  scale_y_continuous(expand=c(0.01,0), limits=c(-50,390))+
    coord_cartesian(clip="on",ylim=c(0,390))

P5
ggsave(paste(f.out,"/longevityOverTime.png",sep=""),height=4,width=4, units="in")

## Composite figure of transmission longevity
plot_grid(P3,P5,ncol=2,labels=c("A" ,"B"))
ggsave(paste(f.out,"/Sublineagelongevity.png",sep=""),height=4,width=8, units="in")
```

## Number descendent vs tmrca, negative binomial
```{r}
#### # descendant vs tmrca.dt ######
k=1

#basic Y ~ X
mod.desc<-glm.nb((N.Desc.glob) ~ as.Date(tmrca.dt), data=sum.boots[[k]])
summary(mod.desc)

#adjust for node location
mod.desc2<-glm.nb((N.Desc.glob) ~ as.Date(tmrca.dt) + Node.Location, data=sum.boots[[k]])
summary(mod.desc2)

#compare to model 1
# anova(mod.desc,mod.desc2,test="lrt")
# BIC(mod.desc);BIC(mod.desc2) #modest improvement
# plot(mod.desc2) #residuals and QQ plot don't look great...

# go with model 3, not overfit
mod.desc<-mod.desc3

#summarize coeff, exponentiated because negbin
nb.summ<-as.data.frame(cbind(exp(mod.desc$coefficients),exp(confint(mod.desc))))
pvalz<-as.data.frame(summary(mod.desc)[12])[,4]
nb.summ$pvalue<-pvalz
colnames(nb.summ)<-c("Estimate","Lower 95% bound","Upper 95% bound","p-value")
nb.summ[,1:3]<-format(nb.summ[,1:3],scientific=T,digits=3)
nb.summ[,4]<-format(nb.summ[,4], scientific = TRUE,digits = 3)
rownames(nb.summ)<-str_replace_all(rownames(nb.summ),"Node.Location","")
# rownames(nb.summ)<-str_replace_all(rownames(nb.summ),"Newfoundland\nand Labrador","Newfoundland and Labrador")
rownames(nb.summ)[1:2]<-c("Intercept","TMRCA")
# write.csv(nb.summ,paste(f.out,"/tmrca_vs_logNumberDescendants_byLocation_NEGBIN.csv",sep = ""))
# nb.summ

newdata2 <- data.frame(
  tmrca.dt = rep(seq(from = min(sum.boots[[k]]$tmrca.dt), to = max(sum.boots[[k]]$tmrca.dt), length.out = 100), 2))

newdata2 <- cbind(newdata2, predict(mod.desc, newdata2, type = "link", se.fit=TRUE))
newdata2 <- within(newdata2, {
  N.Desc.glob <- exp(fit)
  LL <- exp(fit - 1.96 * se.fit)
  UL <- exp(fit + 1.96 * se.fit)
})

#PPLOT WITH NEGATIVE BINOMIAL FITS 
p3.v1<-ggplot(data=sum.boots[[k]],aes(x=as.Date(tmrca.dt),y=log10(N.Desc.glob)))+
  geom_point(alpha=0.8,color="deepskyblue3")+
  geom_ribbon(data=newdata2,aes(x=as.Date(tmrca.dt),ymin=log10(LL),ymax=log10(UL)),alpha = 0.15,
              fill="deepskyblue3") +
  geom_line(data=newdata2,aes(x=as.Date(tmrca.dt)), size = 0.5,alpha=0.5,fill="deepskyblue3") +
  coord_cartesian(ylim=c(0.2,5))+
  pubThemeDate+
  theme(legend.position=c(0.8,0.9),
        legend.text = element_text(size=rel(0.7)),
        legend.title=element_text(size=rel(0.8)))+
  scaleDateFlex+
  scale_y_continuous(expand=c(0,0))+
  labs(x="Date of most recent common ancestor",y="log10(total sampled descendants)")+
  scale_color_manual(values=c("deepskyblue3"),guide=NULL)+
  scale_fill_manual(values=c("deepskyblue3"),guide=NULL)
  # guides(color=guide_legend(title = "Sublineage activity"))
p3.v1
ggsave(paste(f.out,"/tmrca_vs_logNumberDescendants_NEGBIN.png",sep=""),height=4,width=4,units="in")

```

## Time since importation
```{r}
sublin.long2<-replicate(n.B,vector())
k=1

#join select columns from sum.boots onto sublin.long by sublineage2
#CHANGED TO the uniq
sublin.long2[[k]]<-sublin.long.unq[[k]]

# what is the average time since importation for sampled cases over time?
# for each sampled descendant of a sublineage, how long since the tmrca?
sublin.long2[[k]]$tmrca.dt<-as.Date(sublin.long2[[k]]$tmrca.dt)
sublin.long2[[k]]<- sublin.long2[[k]] %>% mutate(sublinAge=Date - tmrca.dt)

#only keep canadian descendants
# table(sublin.long2[[k]]$State)
# sublin.long2[[k]]$State<-str_replace_all(sublin.long2[[k]]$State,"Canada_","")
keepers<-which(sublin.long2[[k]]$State %in% provs)
sublin.long.Can<-sublin.long2[[k]] [keepers,] 

#calculate this as a rolling mean over time
summAge<-sublin.long.Can %>% dplyr::group_by(Date) %>%
  dplyr::summarize(.groups="rowwise",
                   meanAge=mean(sublinAge,na.rm=T),
                   sdAge=as.numeric(sd(sublinAge,na.rm=T)),
                   n=n())
# head(summAge)
summAge[is.na(summAge)]<-0 #get rid of NAs
summAge2<- summAge %>% as.data.frame() %>%
  dplyr::summarize(.groups="keep",
                   Date=Date,
                   meanAge2=meanAge,
                   #note that qt(.025, n, lower.tail=F) looks up the critical value for a given n
                   upperAge=as.numeric(meanAge)+( (sdAge/sqrt(n-1))*qt(.025, n, lower.tail=F) ), 
                   lowerAge=as.numeric(meanAge)-( (sdAge/sqrt(n-1))*qt(.025, n, lower.tail=F) ) ) %>% 
  dplyr::ungroup() %>% as.data.frame()

#if we can't calculate a sd, just make the upper/lower the mean
for (i in 1:nrow(summAge2)){
  if (is.na(summAge2$upperAge[i])){
    summAge2$lowerAge[i]<-summAge2$meanAge2[i]
    summAge2$upperAge[i]<-summAge2$meanAge2[i]
  }
  #if negative, make it zero
  if (summAge2$lowerAge[i]<0){summAge2$lowerAge[i]<-0}
}

summAge3<- summAge2 %>% as.data.frame() %>%
  dplyr::mutate(meanAge7d = zoo::rollmean(as.numeric(meanAge2), k = 7, fill=NA,align="center"),
                upperAge7d = zoo::rollmean(as.numeric(upperAge),k=7, fill=NA,align="center"),
                lowerAge7d = zoo::rollmean(as.numeric(lowerAge),k=7, fill=NA,align="center"),
                meanAge14d = zoo::rollmean(as.numeric(meanAge2), k = 14, fill=NA,align="center"),
                upperAge14d = zoo::rollmean(as.numeric(upperAge),k=14, fill=NA,align="center"),
                lowerAge14d = zoo::rollmean(as.numeric(lowerAge),k=14, fill=NA,align="center")) %>% 
  dplyr::ungroup() %>% as.data.frame()

#Add to the model
ord.prov2<-str_replace_all(ord.prov,"British\nColumbia","British Columbia")
ProvColScale2<-scale_color_manual(name = "Location",values = globalPalette.ch[match(ord.prov2,names(globalPalette.ch))], na.value="grey60")

p4<-sublin.long2[[k]] %>% filter(State %in% provs) %>%
  ggplot()+
  geom_point(aes(x=Date,y=sublinAge,color=Lineage),alpha=0.3,size=0.6)+
  geom_line(data=summAge3,aes(x=Date,y=meanAge14d),color="grey10",alpha=0.7,size=1)+
  geom_ribbon(data=summAge3,aes(x=Date,ymin=lowerAge14d,ymax=upperAge14d),fill="grey10",alpha=0.5)+
  # geom_line(data=pred.val,aes(x=Date,y=fit),color="grey10",alpha=0.8,size=1.5)+
  pubThemeDate+
  LinColScale+
  # ProvColScale2+
  theme(#legend.position=c(0.3,0.7), 
        legend.position="none",
        legend.title = element_text(size=rel(0.8)))+
  guides(color=guide_legend(title="Sampling location",
                            override.aes = list(alpha=1)))+
  labs(x="Canadian descendant sampling date",y="Days since importation")+
  # annotate(geom="text",x=as.Date("2020-09-08"),y=210,label="Rolling mean",hjust=1,size=3)+
  scaleDateFlex+
  scale_y_continuous(limits=c(0,300),expand=c(0.01,0))
  # annotate(geom="rect",xmin=as.Date("2020-01-15"),xmax=as.Date("2020-03-15"),
           # ymin=100,ymax=410,color="white",fill="white")
p4
ggsave(paste(f.out,"/TimeSinceImportationVsSampleDate.png",sep=""),height=4,width=5,units="in")
```

## descendant locations
```{r}
#summarize the total descendants by location

## tabulate instances of location pairs
sum.Desc.l<-replicate(n.B,vector())
for (k in 1:n.B){
  sum.Desc.l[[k]]<-sublin.long.unq[[k]] %>% dplyr::group_by (State) %>% 
    dplyr::summarize (.groups="rowwise", n.Par= n()) %>% as.data.frame() 
  sum.Desc.l[[k]]$SampleSet<-paste("Sample",BOOTS[k])
}

## rbind the summaries
sum.Desc<-bind_rows(sum.Desc.l)

#summarize the mean and range for each 
sum.Desc.summary<-sum.Desc %>% dplyr::group_by(State) %>%
  dplyr::summarize(.groups="rowwise",
                   mean.n=round(mean(n.Par)),
                   sd.n=round(sd(n.Par,na.rm=T),digits=2)) %>%
  as.data.frame()

## plot it
sum.Desc.summary<-sum.Desc.summary[rev(order(sum.Desc.summary$mean.n)),]
sum.Desc.summary$State<-factor(sum.Desc.summary$State,
                               levels=sum.Desc.summary$State)
#big ones
ylim.up<-max(sum.Desc.summary$mean.n)+30
sum.Desc.summary %>%
      ggplot(aes(x=State,y=mean.n,group=State,fill=State))+
        geom_bar(stat="identity")+
        geom_errorbar(stat="identity",aes(ymin=mean.n-sd.n, ymax=mean.n+sd.n),color="grey50",lwd=0.1)+
        pubThemeDate+
        theme(legend.position = "none")+
        labs(x="Sublineage descendant location", y="# sampled descendants")+
        GlobFillScale+
  scale_y_continuous(limits=c(0,ylim.up), expand=expansion(0,0))
ggsave(paste(f.out,"/DescendantsBarPlot.png",sep=""),height=4, width=6,units="in")
```

# Detection lag modelling
```{r}
#write a generic lm function
make.lm.eqn<-function(lm){
  slope<-coef(lm)[2]
  yint<-coef(lm)[1]
  pval<-anova(lm)$'Pr(>F)'[1]
  radj<-summary(lm)$adj.r.squared
  eqn<-paste("y = ",signif(slope,digits=3)," x + ",signif(yint,digits=3),"\n",
             "adj. R^2 = ",signif(radj,digits = 2),"\n",
             "p-value = ", signif(pval,digits = 2), sep="")
  return(eqn)
}
```

## Plot number of descendants by detection lag, colored by prov, linear model
```{r}
k=1

mod.9<-lm(log(N.Desc.glob) ~ detection.lag,data=sum.boots[[k]])
summary(mod.9) #N/S

#SETUP FOR PLOT
mod.9.text<-make.lm.eqn(mod.9)
#set positions
max.x<-max(sum.boots[[k]]$detection.lag)
max.y<-max(log(sum.boots[[k]]$N.Desc.glob))
pred.mod.9<-predict(mod.9,interval="confidence")
dat.mod.9 <-cbind(sum.boots[[k]], pred.mod.9)

#### Plot number of descendants by detection lag, colored by prov, 
###with eqn for line and line
ggplot(dat.mod.9,aes(x=detection.lag))+
  geom_point(aes(y=log(N.Desc.glob), color=Node.Location))+
  theme_bw()+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        axis.line = element_line(colour = "black"), panel.background=element_rect("grey95"),
        legend.key.size = unit(0.5,"line"),text=element_text(size=10,face="bold"),
        legend.text=element_text(size=8),axis.text.x=element_text(angle=45,hjust = 1))+
  # scale_x_date(date_breaks = "1 month", date_minor_breaks = "2 weeks", date_labels = "%b %Y")+
  labs(x="Detection lag (days)",y="log(Number Sampled Descendants)",color="Province\nof introduction")+
  ProvColScale2+
  # annotate("text",label=mod.9.text,x=max.x,y=max.y,hjust=1,color="black",size=3,vjust=1)+
  geom_line(aes(y=fit),color="darkblue",lwd=0.4)+
  geom_ribbon(aes(ymin = lwr, ymax = upr), fill="lightblue",alpha = .5) 

ggsave(paste(f.out,"DetectionLag_vs_logNumberDescendants_byProv_LM.png",sep=""),height=4,width=6,units="in")

#look at adjusting for tmrca.dt here
mod.9b<-lm(log(N.Desc.glob) ~ detection.lag+as.Date(tmrca.dt),data=sum.boots[[k]])
# summary(mod.9)
# summary(mod.9b)
# AIC(mod.9b);AIC(mod.9) #lower AIC for first model
# BIC(mod.9b);BIC(mod.9) #lower BIC for first model
# anova(mod.9,mod.9b,test="LRT") #p=0.0006576 ***
```

## Detection lag over time
```{r}
k=1

#make a model and add the lm fit to the plot
dl.mod<-lm(as.numeric(detection.lag) ~ as.Date(tmrca.dt), data=sum.boots[[k]])
dl.mod.2<-lm(as.numeric(detection.lag) ~ as.Date(tmrca.dt)+Node.Location, data=sum.boots[[k]])
# anova(dl.mod,dl.mod.2) #p=0.03364 *
# summary(dl.mod.2)
# summary(dl.mod) #0.616

dl.mod.3<-lm(as.numeric(detection.lag) ~ Node.Location, data=sum.boots[[k]])
# summary(dl.mod.3)
# BIC(dl.mod);BIC(dl.mod.2) #lower for simpler
# AIC(dl.mod);AIC(dl.mod.2) #support for including node
#support for including node location
sum.boots[[k]]$Node.Location<-factor(sum.boots[[k]]$Node.Location)
newdata2 <- data.frame(
  tmrca.dt = rep(seq(from = min(sum.boots[[k]]$tmrca.dt), to = max(sum.boots[[k]]$tmrca.dt), length.out = 100), 8),
  Node.Location = factor(rep(1:8, each = 100), levels = 1:8, labels =
  levels(sum.boots[[k]]$Node.Location)))

newdata2 <- cbind(newdata2, predict(dl.mod.2, newdata2, type = "response", se.fit=TRUE))
newdata2 <- within(newdata2, {
  detection.lag<- (fit)
  LL <- (fit - 1.96 * se.fit)
  UL <- (fit + 1.96 * se.fit)
})

#Color by province and add linear fit overall
# ggplot(sum.boots[[k]],aes(x=as.Date(tmrca.dt),y=detection.lag))+
#   geom_point(aes(color=Node.Location,alpha=Node.Likelihood))+
#   theme_bw()+
#   theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
#         axis.line = element_line(colour = "black"), panel.background=element_rect("grey95"),
#         legend.key.size = unit(0.5,"line"),text=element_text(size=10,face="bold"),
#         legend.text=element_text(size=8),axis.text.x=element_text(angle=45,hjust = 1))+
#   scaleDateBusy+
#   labs(x="Date of most recent common ancestor",y="Detection lag (days)",color="Province\nof introduction")+
#   theme(legend.position = "none")+
#   GlobColScale+
#   GlobFillScale+
#   # annotate("text",label=dl.mod.text,x=as.numeric(max.x),y=max.y,hjust=1,color="black",size=3,vjust=1)+
#   geom_line(data=newdata2,aes(y=detection.lag,color=Node.Location),lwd=0.4)+
#   geom_ribbon(data=newdata2,aes(ymin = UL, ymax = LL,fill=Node.Location),alpha = .5) 
#  
#repeat with one fit
# dl.mod
# summary(dl.mod) #  0.616
#as.Date(tmrca.dt)  -0.02144    0.00923  -2.323   0.0205 *
# -120*-0.02144 #120 days earlier, 2.5728 times longer the detection lag
newdata2 <- data.frame(
  tmrca.dt = rep(seq(from = min(sum.boots[[k]]$tmrca.dt), to = max(sum.boots[[k]]$tmrca.dt), length.out = 100), 8))

newdata2 <- cbind(newdata2, predict(dl.mod, newdata2, type = "response", se.fit=TRUE))
newdata2 <- within(newdata2, {
  detection.lag<- (fit)
  LL <- (fit - 1.96 * se.fit)
  UL <- (fit + 1.96 * se.fit)
})

#Color by province and add linear fit overall
px3<-ggplot(sum.boots[[k]],aes(x=as.Date(tmrca.dt),y=as.numeric(detection.lag)))+
  geom_point(aes(color=Lineage),alpha=0.6,size=1.5)+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        axis.line = element_line(colour = "black"), panel.background=element_rect("grey95"),
        legend.key.size = unit(0.5,"line"),text=element_text(size=10,face="bold"),
        legend.text=element_text(size=8),axis.text.x=element_text(angle=45,hjust = 1))+
scaleDateFlex+
  scale_y_continuous(limits=c(0,205),expand=c(0.01,0))+
  labs(x="Date of most recent common ancestor",y="Detection lag (days)",color="Province\nof introduction")+
  theme(legend.position = "none")+
  LinColScale+
  geom_line(data=newdata2,aes(y=detection.lag),lwd=0.4,color="grey30")+
  geom_ribbon(data=newdata2,aes(ymin = UL, ymax = LL),fill="grey30",alpha = .5) 
px3
ggsave(paste(f.out,"DetectionLag_SampleDateLSD-tMRCA.png",sep=""),height=4,width=4,units="in")

```

## assemble compostite plot of sublineage size over time, longevity, detection lag and days since importation
```{r}
plot.modz<-plot_grid(p3,P5,p4,px3, ncol=2, labels=c("A","B","C","D"),align="hv")
plot.modz

plot.modz
ggsave(paste(f.out,"/SublineagesOvertime_mod.png",sep=""),height=7,width=8,units="in")

```

## plot distrib of detection lag by prov
```{r}
dl.summ<-sum.boots[[k]] %>% group_by(Node.Location) %>% 
  dplyr::summarize(.groups="rowwise",
                   mean.dl=mean(detection.lag), 
                   median.dl=median(detection.lag), 
                   total=n())
dl.summ
# are detection lags sign'ly diff b/w provinces
kruskal.test(as.numeric(sum.boots[[k]]$detection.lag), sum.boots[[k]]$Node.Location) # p-value = 0.001977
pairwise.wilcox.test(as.numeric(sum.boots[[k]]$detection.lag), sum.boots[[k]]$Node.Location,
                 p.adjust.method = "bonferroni") #n/s
# 0.00068 quebec vs BC
dunn.test::dunn.test(as.numeric(sum.boots[[k]]$detection.lag), sum.boots[[k]]$Node.Location, method="bonferroni")
# p-value =  0.0004*  b/w quebec and BC

#which ones are 
ord1<-dl.summ[rev(order(dl.summ$median.dl)),]$Node.Location
sum.boots[[k]]$Node.Location<-factor(sum.boots[[k]]$Node.Location,levels=ord1)
px2<-ggplot(sum.boots[[k]])+
  geom_boxplot(aes(x=Node.Location,group=Node.Location,y=detection.lag))+
  geom_point(aes(x=Node.Location,group=Node.Location,y=detection.lag,color=Node.Location),alpha=0.8)+
  GlobColScale+
  pubThemeDate+
  labs(x=NULL,y="Detection lag (days)")+
  theme(legend.position="none")+
  geom_text(data=dl.summ,aes(label=paste("n=",total,sep=""),x=Node.Location,y=-5),size=3,vjust=1)
  # geom_segment(aes(x=2, xend=5, y=310, yend=310),size=0.1)+
  # geom_text(aes(label="p = 0.0002",x=3.5,  y=314 ),size=2.5,fontface="plain",vjust=0)
px2
ggsave(paste(f.out,"DetectionLag_by_province_boxplotpoints.png",sep=""),width=4,height=4,units="in")
```

# sublineages' dates over time
```{r}
# head(sublin.long.unq[[k]])
k=1

# plot these dates over time for each sublinage
sublin.long.unq[[k]]$tmrca.dt<-as.Date(sublin.long.unq[[k]]$tmrca.dt)
sublin.long.unq[[k]]$Sublineage <- reorder(sublin.long.unq[[k]]$Sublineage, sublin.long.unq[[k]]$tmrca.dt)
sublin.long.unq[[k]]$tmrca.upper.dt<-as.Date(sublin.long.unq[[k]]$tmrca.upper.dt)
sublin.long.unq[[k]]$tmrca.lower.dt<-as.Date(sublin.long.unq[[k]]$tmrca.lower.dt)

## PLOT
sublin.long.unq[[k]] %>% 
  filter(State %in% provs) %>%
  ggplot(aes(y=Sublineage,color=Lineage))+
  geom_linerangeh(aes(xmin=tmrca.lower.dt,xmax=tmrca.upper.dt),lwd=0.1,linetype="dotted")+
  geom_linerangeh(aes(xmin=tmrca.dt,xmax=FirstCanDateLSD),linetype="44",lwd=0.1)+ #detection lag
  geom_linerangeh(aes(xmin=FirstCanDateLSD,xmax=LastCanDateLSD),lwd=0.1)+
  # geom_point(aes(x=Date),alpha=0.7,size=0.5)+
  # geom_point(aes(x=FirstCanDateLSD),shape=22,size=0.7)+
  geom_point(aes(x=tmrca.dt),shape=18,size=0.5)+
  theme(#axis.text.y=element_text(size=1.3),
        axis.ticks.y=element_blank(),
        #axis.text.y=element_blank(), 
        axis.text.x=element_text(angle=45,hjust = 1,size=1),
          panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
          panel.background=element_rect("grey95"),
          legend.key.size = unit(0.5,"line"),
          text=element_text(size=10,face="bold"),
          legend.text=element_text(size=8),
        legend.position="top")+
    # scale_x_date(date_breaks = "1 month", date_minor_breaks = "2 weeks", date_labels = "%b %Y")+
  labs(x=NULL)+
  # ProvColScale2+
  LinColScale+
  scale_y_discrete(expand = c(0.01,0.01))+
  theme(legend.position = "none")+
  pubThemeDate
  
ggsave(paste(f.out,"/SamplesOverTimeForSublineages.png",sep=""),height=10,width=8,units="in")

## ANOTHER version, with only key sublineages shown
key.subs<-sum.boots[[k]]$Sublineage [sum.boots[[k]]$N.Desc.can>50]
sum.boots[[k]]$tmrca.upper.dt<-as.Date(sum.boots[[k]]$tmrca.upper.dt)
sum.boots[[k]]$tmrca.lower.dt<-as.Date(sum.boots[[k]]$tmrca.lower.dt)

sum.boots[[k]] %>% 
  filter(Sublineage %in% key.subs) %>%
  ggplot(aes(y=Sublineage,color=Lineage))+
  theme(legend.position = "none")+
  geom_linerangeh(aes(xmin=FirstCanDateLSD,xmax=LastCanDateLSD,lwd=0.5),fill=0.7)+
  geom_linerangeh(aes(xmin=tmrca.lower.dt,xmax=tmrca.upper.dt),lwd=0.5,linetype="dotted")+
  geom_linerangeh(aes(xmin=tmrca.dt,xmax=FirstCanDateLSD),linetype="44",lwd=0.3)+ #detection lag  
  theme(axis.text.y=element_text(size=5),axis.ticks.y=element_blank(),
        #axis.text.y=element_blank(), 
        axis.text.x=element_text(angle=45,hjust = 1),
          panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
          panel.background=element_rect("grey95"),
          legend.key.size = unit(0.5,"line"),
          text=element_text(size=10,face="bold"),
          legend.text=element_text(size=8),
        legend.position="top")+
    scale_x_date(date_breaks = "1 month", date_minor_breaks = "2 weeks", 
                 date_labels = "%b %Y")+
  labs(x=NULL)+
  # ProvColScale2+
  LinColScale+
  scale_y_discrete(expand = c(0.01,0.01))+
  theme(legend.position = "none")+
  pubThemeDate

ggsave(paste(f.out,"/SublineageCartoonExpansion.png",sep=""),height=4,width=8.5,units="in")

```

## Main sublineages as ggridge plot
```{r}
# length(which(sum.boots[[k]]$N.Desc.can>100))
#key sublineages
key.subs<-sum.boots[[k]]$Sublineage [sum.boots[[k]]$N.Desc.can>100]

#order of these sublins by first can sample date LSD
sum.boots[[k]]$FirstCanDateLSD[match(key.subs,sum.boots[[k]]$Sublineage)] #these are the right order
sublin.ord<-sum.boots[[k]]$Sublineage[match(key.subs,sum.boots[[k]]$Sublineage)]

temp.df<-sublin.long.unq[[k]] %>%
  filter(Sublineage %in% key.subs)

#order by first can sample date
temp.df$Sublineage<-factor(temp.df$Sublineage, levels=sublin.ord)

temp.df.count <- temp.df %>%
  dplyr::group_by(Sublineage,Date) %>%
  dplyr::summarize(.groups="rowwise",count=n())
temp.df.count<-temp.df.count %>% left_join( temp.df[,c("Sublineage","Lineage","tmrca.dt")],by="Sublineage")

#filter to only canadian samples
temp.df <- temp.df %>%
  filter(State %in% provs)
temp.df$label.x<-temp.df$tmrca.dt

temp.df<-temp.df %>% left_join(sum.boots[[k]][,c("Sublineage","N.Desc.can")], by = "Sublineage")
temp.df$Sublineage<-factor(temp.df$Sublineage, levels=sublin.ord)

# #manual changes to text location
# temp.df$label.x[which(temp.df$Sublineage=="B.1.617.2.can33")]<-as.Datd(temp.df$label.x[which(temp.df$Sublineage=="B.1.617.2.can33")]-14)

p.ridge<-ggplot(temp.df, aes(x=Date, y=Sublineage,fill=Lineage),alpha=0.7) + 
  geom_point(aes(x=tmrca.dt,color=Lineage),shape=23,size=0.5)+
  # geom_linerangeh(aes(xmin=as.Date(tmrca.lower.dt),xmax=as.Date(tmrca.upper.dt),color=Lineage),
                  # lwd=0.5,linetype="dotted")+
  geom_density_ridges(color="white",lwd=0.1,rel_min_height = 0.01, scale = 2)+
  geom_text(aes(label=Sublineage,x=label.x,color=Lineage),hjust=1,size=3,vjust=-1.7)+
  pubThemeDate+
  theme(legend.position = "none",
        axis.text.y=element_blank(),
        axis.text.x=element_text(size=8),
        plot.margin = unit(c(14,4,4,4), "pt"),
        axis.ticks.y=element_blank())+
  LinFillScale+ 
  LinColScale+
  labs(x=NULL, y= "Sublineages with 100+ Canadian descendants")+
  scale_x_date(date_labels = "%b %Y",expand=c(0,0),limits=as.Date(c("2020-12-01","2022-03-01")))+
  scale_y_discrete(expand=c(0.01,0)) + 
  # add annotations for n Can desc
  geom_text(aes(label=paste("n = ",N.Desc.can),
                x=label.x,color=Lineage),hjust=1,size=2,vjust=-0.8)

p.ridge
ggsave(paste(f.out,"/SublineageCartoonDensity_100plus_n_sml.png",sep=""),
       height=8,width=4,units="in")
  
```

# SINGLETONS
## summarize singletons for results text
```{r}
#summary of singletons
sing.tot<-c()
for (k in 1:n.B){
   sing.tot<-c(sing.tot,nrow(can.sing.boots[[k]] ))
}
cat(paste0("Total singletons (mean, 95%CI)  = ",mean.95ci.X(sing.tot,0) ),
    file=text.out,sep="\n",append=T)

#what was the TOTAL number of intros (singles + sublins)
tot.tot<-c()
for (k in 1:n.B){
   tot.tot<-c(tot.tot,(nrow(can.sing.boots[[k]] ) + nrow(sum.boots[[k]])))
}
cat(paste0("Total intros, singles + sublins (mean, 95%CI)= ",mean.95ci.X(tot.tot,0)  ),
    file=text.out,sep="\n",append=T)

#what proportion were singeltons
cat(paste0("Proportion singletons of all intros = ",
           mean.95ci.X((sing.tot/tot.tot*100),1)),
    file=text.out,sep="\n",append=t)

#what percent did the few large intros account for?
cat(paste0("Proportion intros with >99 desc = ",
          mean.95ci.X( hund/tot.tot*100, 1)),
    file=text.out,sep="\n",append=T)

cat(paste0("Proportion intros with >=500 desc = ",
          mean.95ci.X( fvhund/tot.tot*100, 1)),
    file=text.out,sep="\n",append=T)

```

## PROPORTION OF importations leading to sublineage analysis
## proportion of importations from each country of origin leading to singleton vs an introduction BY COUNTRY
```{r}
allimportz.boots<-replicate(n.B,vector())
for (k in 1:n.B){
  #what proportion of importations from each country resulted in a singleton vs an introdctuion leading to ongoing transmission, by month?
  singz<-as.data.frame.matrix(table(can.sing.boots[[k]]$par.state,can.sing.boots[[k]]$yearmonth))
  subz<-as.data.frame.matrix(table(sum.boots[[k]]$Parent.Location,sum.boots[[k]]$yearmonth))
  
  #go from wide to long
  singz$country<-rownames(singz)
  singz.long<-singz %>% pivot_longer(1:(ncol(singz)-1),names_to = "yearmonth")
  colnames(singz.long)[3]<-"singz"
    
  subz$country<-rownames(subz)
  subz.long<-subz %>% pivot_longer(1:(ncol(subz)-1),names_to = "yearmonth")
  colnames(subz.long)[3]<-"subz"
  
  allimportz<-left_join(singz.long,subz.long,by=c("country","yearmonth"))
  allimportz.boots[[k]]<-allimportz %>% mutate(total=subz+singz, prop.subz=subz/total)
}

#summarize across boots
summ.allimportz.boots<-bind_rows(allimportz.boots)
summary.allimportz.boots<-summ.allimportz.boots %>% 
  dplyr::group_by (country, yearmonth) %>%
  dplyr::summarise(.groups="rowwise",
                   mean.propsubz=mean(prop.subz)) %>%
  dplyr::ungroup() %>% as.data.frame()

  # #statistical test (different over time) 0.4631
  kruskal.test(summary.allimportz.boots$yearmonth, summary.allimportz.boots$mean.propsubz) #not signf  0.4713
  kruskal.test(summary.allimportz.boots$country, summary.allimportz.boots$mean.propsubz) #not signif  0.4719
  
## consider showing as boxplot with points behind
#USE IN PUBLlCATION GROB BELOW
PX2<-summary.allimportz.boots  %>%
  filter(!yearmonth %in% c("2021-07","2021-08","2021-09")) %>% #empty
  ggplot()+
    geom_boxplot(aes(x=yearmonth,y=mean.propsubz))+
    geom_point(aes(x=yearmonth,y=mean.propsubz,group=country,color=country),position=position_dodge2(width=0.4),alpha=0.9)+
    pubThemeDate+
    theme(legend.position="top")+
  labs(x=NULL,y="Prop. importations resulting in sublineage")+
  CountryColScale+
  guides(color=guide_legend(title="Origin\nlocation"))+
  coord_cartesian(clip="off")
PX2
ggsave(paste(f.out,"Boxplot with POINT Prop. of importations resulting in sublineage BY ORIGIN.png",sep=""),width=5,height=4,units="in")

```

## proportion of importations into each province leading to singleton vs an introduction BY PROVINCE
```{r}
allimportz.boots<-replicate(n.B,vector())
for (k in 1:n.B){
  #what proportion of importations from each country resulted in a singleton vs an introdctuion leading to ongoing transmission, by month?
  singz<-as.data.frame.matrix(table(can.sing.boots[[k]]$tip.state,can.sing.boots[[k]]$yearmonth))
  subz<-as.data.frame.matrix(table(sum.boots[[k]]$Node.Location,sum.boots[[k]]$yearmonth))
  
  #go from wide to long
  singz$country<-rownames(singz)
  singz.long<-singz %>% pivot_longer(1:(ncol(singz)-1),names_to = "yearmonth")
  colnames(singz.long)[3]<-"singz"
    
  subz$country<-rownames(subz)
  subz.long<-subz %>% pivot_longer(1:(ncol(subz)-1),names_to = "yearmonth")
  colnames(subz.long)[3]<-"subz"
  
  allimportz<-left_join(singz.long,subz.long,by=c("country","yearmonth"))
  allimportz.boots[[k]]<-allimportz %>% mutate(total=subz+singz, prop.subz=subz/total)
}

#summarize across boots
summ.allimportz.boots<-bind_rows(allimportz.boots)
summary.allimportz.boots<-summ.allimportz.boots %>% 
  dplyr::group_by (country, yearmonth) %>%
  dplyr::summarise(.groups="rowwise",
                   mean.propsubz=mean(prop.subz)) %>%
  dplyr::ungroup() %>% as.data.frame()

# #statistical test (different over time)
kruskal.test(summary.allimportz.boots$yearmonth, summary.allimportz.boots$mean.propsubz) #0.3665
kruskal.test(summary.allimportz.boots$country, summary.allimportz.boots$mean.propsubz) #not signif = 0.5286
#compare means acros month
# summary.allimportz.boots %>% dplyr::group_by(yearmonth) %>%
#   dplyr::summarise(.groups="rowwise",mean(mean.propsubz,na.rm=T))
# summary.allimportz.boots %>% dplyr::group_by(country) %>%
#   dplyr::summarise(.groups="rowwise",mean(mean.propsubz,na.rm=T))

#boxplot with points
PX1<-summary.allimportz.boots %>%
    filter(!yearmonth %in% c("2021-07","2021-08","2021-09")) %>% #empty
  ggplot()+
    geom_boxplot(aes(x=yearmonth,y=mean.propsubz))+
    geom_point(aes(x=yearmonth,y=mean.propsubz,group=country,color=country),position=position_dodge2(width=0.4),alpha=0.9)+
  pubThemeDate+
  theme(legend.position="top")+
  labs(x=NULL,y="Prop. importations resulting in sublineage")+
  guides(color=guide_legend(title="Province",nrow=3))+
  ProvColScale2+
  coord_cartesian(clip="off")
PX1
ggsave(paste(f.out,"Boxplot with POINT Prop. of importations resulting in sublineage BY PROV.png",sep=""),width=5,height=4,units="in")
```

## figure of proportion of importations resulting in sublineage
```{r}
plot_grid(PX1, PX2, labels=c("A","B"))
ggsave(file=paste(f.out,"boxplot_PropImportSublin_BY PROV and ORIGIN.png",sep=""),width=9,height=4,units = "in")
```


## Simple alluvial overall for singletons
```{r}
#summarize the total number and percent of intros by 1) par. loc, 2) prov of intro, maybe also 3) lineage 
#prep list item
sing.Par.Prov.l<-replicate(n.B,vector())

#go through each list item/subsample
## tabulate instances of location pairs
for (k in 1:n.B){
  sing.Par.Prov.l[[k]]<-can.sing.boots[[k]] %>% dplyr::group_by (par.state, tip.state) %>% dplyr::summarize (.groups="rowwise", n.Par= n()) %>% as.data.frame() %>% mutate(perc.Par=(n.Par/sum(n.Par))*100)

  ## add a column for subsample
  sing.Par.Prov.l[[k]]$SampleSet<-paste("Sample",BOOTS[k])

}

## rbind the summaries

sum.Par.Prov<-bind_rows(sing.Par.Prov.l)

#summarize the mean and range for each of 1), 2) and 3)
sing.Par.Prov.summary<-sum.Par.Prov %>% dplyr::group_by(par.state, tip.state) %>%
  dplyr::summarize(.groups="rowwise",
                   mean.n=round(mean(n.Par)),
                   sd.n=round(sd(n.Par,na.rm=T),digits=2),
                   mean.perc=round(mean(perc.Par),digits=2),
                   sd.perc=round(sd(perc.Par,na.rm=T),digits=2)) %>%
  as.data.frame()

tot.Par<-sing.Par.Prov.summary %>% dplyr::group_by(par.state) %>%
  dplyr::summarise(.groups = "rowwise", totalImports=sum(mean.n)) %>%
  as.data.frame()

## Alluvial plot for Figure 2
#make a "subject column"
sing.Par.Prov.summary$subject<-1:nrow(sing.Par.Prov.summary)
# sing.Par.Prov.summary<-sing.Par.Prov.summary[-which(sing.Par.Prov.summary$mean.n<1),]

#order the geos
ord.count<-sing.Par.Prov.summary%>% dplyr::group_by(par.state) %>%
  dplyr::summarise(.groups="rowwise",n=sum(mean.n)) %>% as.data.frame()
ord.count<-ord.count[rev(order(ord.count$n)),'par.state']
sing.Par.Prov.summary$par.state<-factor(sing.Par.Prov.summary$par.state,levels=ord.count)

ord.prov<-sing.Par.Prov.summary%>% dplyr::group_by(tip.state) %>%
  dplyr::summarise(.groups="rowwise",n=sum(mean.n)) %>% as.data.frame()
ord.prov<-ord.prov[rev(order(ord.prov$n)),'tip.state']
sing.Par.Prov.summary$tip.state<-factor(sing.Par.Prov.summary$tip.state,levels=ord.prov)


#make it long
sing.Par.Prov.summary.long<-sing.Par.Prov.summary %>% pivot_longer(1:2, names_to = "geo.type", values_to = "geo")
#order the geo types
sing.Par.Prov.summary.long$geo.type<-factor(sing.Par.Prov.summary.long$geo.type,levels=c("par.state","tip.state"),labels=c("Origin","Destination"))

## Alluvial plot
P1.singz<- ggplot(sing.Par.Prov.summary.long,
       aes(x = geo.type, stratum = geo, alluvium = subject,
           y = mean.n,
           fill = geo, label = geo)) +
  scale_x_discrete(expand = c(0.01,0.01)) +
  scale_y_continuous(expand = c(0,0)) +
  geom_flow(alpha = 0.6,width=0.45) +
  geom_stratum(alpha = 0.9,width=0.45) +
  geom_text(stat = "stratum", size = 3.4,min.y=1,fontface="bold") +
  pubTheme+
  theme(legend.position = "none", axis.line = element_blank(), text =element_text(size=14),
        axis.ticks.x = element_blank(),axis.text.x = element_text(hjust=c(0.5,0.5)))+
  labs(x=NULL,y=paste0("# singletons"))+
  GlobFillScale
P1.singz
ggsave(paste(f.out,"alluvial.singletons.Parent.Node.png",sep=""),height=6,width=5,units="in")
```

## Repeat with pre-intervention; during intervention; post-intervention
```{r}
if(int.yn==T){
  sing.Par.Prov.l<-replicate(n.B,vector())
  
  #go through each list item/subsample
  ## tabulate instances of location pairs
  for (k in 1:n.B){
    sing.Par.Prov.l[[k]]<-can.sing.boots[[k]] %>%
      filter(date<as.Date(int.start)) %>%
      dplyr::group_by (par.state, tip.state) %>% dplyr::summarize (.groups="rowwise", n.Par= n()) %>% as.data.frame() %>% mutate(perc.Par=(n.Par/sum(n.Par))*100)
  
    ## add a column for subsample
    sing.Par.Prov.l[[k]]$SampleSet<-paste("Sample",BOOTS[k])
  
  }
  
  ## rbind the summaries
  sing.Par.Prov<-bind_rows(sing.Par.Prov.l)
  
  #summarize the mean and range for each of 1), 2) and 3)
  sing.Par.Prov.summary<-sing.Par.Prov %>% dplyr::group_by(par.state, tip.state) %>%
    dplyr::summarize(.groups="rowwise",
                     mean.n=round(mean(n.Par)),
                     sd.n=round(sd(n.Par,na.rm=T),digits=2),
                     mean.perc=round(mean(perc.Par),digits=2),
                     sd.perc=round(sd(perc.Par,na.rm=T),digits=2)) %>%
    as.data.frame()
  
  tot.Par<-sing.Par.Prov.summary %>% dplyr::group_by(par.state) %>%
    dplyr::summarise(.groups = "rowwise", totalImports=sum(mean.perc)) %>%
    as.data.frame()
  
  ## Alluvial plot for Figure 2
  #make a "subject column"
  sing.Par.Prov.summary$subject<-1:nrow(sing.Par.Prov.summary)
  # sing.Par.Prov.summary<-sing.Par.Prov.summary[-which(sing.Par.Prov.summary$mean.n<1),]
  
  sing.Par.Prov.summary$tip.state<-str_replace_all(sing.Par.Prov.summary$tip.state,"British Columbia","British\nColumbia")

  #order the geos
  ord.count<-sing.Par.Prov.summary%>% dplyr::group_by(par.state) %>%
    dplyr::summarise(.groups="rowwise",n=sum(mean.perc)) %>% as.data.frame()
  ord.count<-ord.count[rev(order(ord.count$n)),'par.state']
  sing.Par.Prov.summary$par.state<-factor(sing.Par.Prov.summary$par.state,levels=ord.count)
  
  ord.prov<-sing.Par.Prov.summary%>% dplyr::group_by(tip.state) %>%
    dplyr::summarise(.groups="rowwise",n=sum(mean.perc)) %>% as.data.frame()
  ord.prov<-ord.prov[rev(order(ord.prov$n)),'tip.state']
  sing.Par.Prov.summary$tip.state<-factor(sing.Par.Prov.summary$tip.state,levels=ord.prov)
  
  #make it long
  sing.Par.Prov.summary.long<-sing.Par.Prov.summary %>% pivot_longer(1:2, names_to = "geo.type", values_to = "geo")
  #order the geo types
  sing.Par.Prov.summary.long$geo.type<-factor(sing.Par.Prov.summary.long$geo.type,levels=c("par.state","tip.state"),labels=c("Origin","Destination"))
  
  
  # sing.Par.Prov.summary.long$geo[which(!sing.Par.Prov.summary.long$geo %in% names(globalPalette.ch))]
  
  #BECAUSE now showing a percent, rescale to equal 100 (means might not sum to 100)
  sing.Par.Prov.summary.long$metric<-sing.Par.Prov.summary.long$mean.perc
  matchy.origin<-which(sing.Par.Prov.summary.long$geo.type=="Origin")
  sing.origin<-sum(sing.Par.Prov.summary.long$mean.perc[matchy.origin])
  sing.Par.Prov.summary.long$metric[matchy.origin]<-sing.Par.Prov.summary.long$mean.perc[matchy.origin]/sing.origin*100
  # sum(sing.Par.Prov.summary.long$metric[matchy.origin]) #should be 100
  matchy.prov<-which(sing.Par.Prov.summary.long$geo.type=="Destination")
  sing.prov<-sum(sing.Par.Prov.summary.long$mean.perc[matchy.prov])
  sing.Par.Prov.summary.long$metric[matchy.prov]<-sing.Par.Prov.summary.long$mean.perc[matchy.prov]/sing.prov*100
  # sum(sing.Par.Prov.summary.long$metric[matchy.prov])
  #Modified palette with weird names TODO
  globalPalette.ch.mod<-globalPalette.ch
  names(globalPalette.ch.mod)<-str_replace_all(names(globalPalette.ch.mod),c("British Columbia"="British\nColumbia",focal.source=focal.source))
  GlobFillScale.mod<-scale_fill_manual(name = "Location",values = globalPalette.ch.mod,na.value="grey60")
  GlobColScale.mod<-scale_color_manual(name = "Location",values = globalPalette.ch.mod,na.value="grey60")
  
  
  ## Alluvial plot
  P1.S.wave1<- ggplot(sing.Par.Prov.summary.long,
         aes(x = geo.type, stratum = geo, alluvium = subject,
             y = metric,
             fill = geo, label = geo)) +
    scale_x_discrete(expand = c(0.01,0.01)) +
    scale_y_continuous(expand = c(0,0)) +
    geom_flow(alpha = 0.6,width=0.55) +
    geom_stratum(alpha = 0.8,width=0.55) +
    geom_text(stat = "stratum", size = 3.4,min.y=2,fontface="bold") +
    pubTheme+
    theme(legend.position = "none", axis.line = element_blank(), text =element_text(size=14),
          axis.ticks.x = element_blank(),axis.text.x = element_text(hjust=c(0.5,0.7)),
          plot.margin=margin(4,4,4,4,unit="pt"))+
    labs(x=NULL,y="% singletons, before intervention")+
    GlobFillScale.mod
  P1.S.wave1
  # ggsave(paste(f.out,"WAVE1.Alluvial.percent.Parent.Node.png",sep=""),height=8,width=5,units="in")
  
  ### WAVE 2 DURING BAN####
  #prep list item
  sing.Par.Prov.2.l<-replicate(n.B,vector())
  
  #go through each list item/subsample
  ## tabulate instances of location pairs
  for (k in 1:n.B){
    sing.Par.Prov.2.l[[k]]<-can.sing.boots[[k]] %>%
      filter(date>=as.Date(int.start)) %>%
      filter(date<as.Date(int.end)) %>%
      dplyr::group_by (par.state, tip.state) %>% dplyr::summarize (.groups="rowwise", n.Par= n()) %>% as.data.frame() %>% mutate(perc.Par=(n.Par/sum(n.Par))*100)
  
    ## add a column for subsample
    sing.Par.Prov.2.l[[k]]$SampleSet<-paste("Sample",BOOTS[k])
  
  }
  
  ## rbind the summaries
  sing.Par.Prov<-bind_rows(sing.Par.Prov.2.l)
  
  #summarize the mean and range for each of 1), 2) and 3)
  sing.Par.Prov.2.summary<-sing.Par.Prov %>% dplyr::group_by(par.state, tip.state) %>%
    dplyr::summarize(.groups="rowwise",
                     mean.n=round(mean(n.Par)),
                     sd.n=round(sd(n.Par,na.rm=T),digits=2),
                     mean.perc=round(mean(perc.Par),digits=2),
                     sd.perc=round(sd(perc.Par,na.rm=T),digits=2)) %>%
    as.data.frame()
  
  tot.Par<-sing.Par.Prov.2.summary %>% dplyr::group_by(par.state) %>%
    dplyr::summarise(.groups = "rowwise", totalImports=sum(mean.perc)) %>%
    as.data.frame()
  
  ## Alluvial plot for Figure 2
  #make a "subject column"
  sing.Par.Prov.2.summary$subject<-1:nrow(sing.Par.Prov.2.summary)
  # sing.Par.Prov.2.summary<-sing.Par.Prov.2.summary[-which(sing.Par.Prov.2.summary$mean.n<1),]
  
  
  sing.Par.Prov.2.summary$tip.state<-str_replace_all(sing.Par.Prov.2.summary$tip.state,"British Columbia","British\nColumbia")
  sing.Par.Prov.2.summary$par.state<-str_replace_all(sing.Par.Prov.2.summary$par.state,focal.source,focal.source)
  
  #order the geos
  ord.count<-sing.Par.Prov.2.summary%>% dplyr::group_by(par.state) %>%
    dplyr::summarise(.groups="rowwise",n=sum(mean.perc)) %>% as.data.frame()
  ord.count<-ord.count[rev(order(ord.count$n)),'par.state']
  sing.Par.Prov.2.summary$par.state<-factor(sing.Par.Prov.2.summary$par.state,levels=ord.count)
  
  ord.prov<-sing.Par.Prov.2.summary%>% dplyr::group_by(tip.state) %>%
    dplyr::summarise(.groups="rowwise",n=sum(mean.perc)) %>% as.data.frame()
  ord.prov<-ord.prov[rev(order(ord.prov$n)),'tip.state']
  sing.Par.Prov.2.summary$tip.state<-factor(sing.Par.Prov.2.summary$tip.state,levels=ord.prov)
  
  
  #make it long
  sing.Par.Prov.2.summary.long<-sing.Par.Prov.2.summary %>% pivot_longer(1:2, names_to = "geo.type", values_to = "geo")
  #order the geo types
  sing.Par.Prov.2.summary.long$geo.type<-factor(sing.Par.Prov.2.summary.long$geo.type,levels=c("par.state","tip.state"),labels=c("Origin","Destination"))
  
  # sing.Par.Prov.2.summary.long$geo[which(!sing.Par.Prov.2.summary.long$geo %in% names(globalPalette.ch))]
  
  #BECAUSE now showing a percent, rescale to equal 100 (means might not sum to 100)
  sing.Par.Prov.2.summary.long$metric<-sing.Par.Prov.2.summary.long$mean.perc
  matchy.origin<-which(sing.Par.Prov.2.summary.long$geo.type=="Origin")
  sing.origin<-sum(sing.Par.Prov.2.summary.long$mean.perc[matchy.origin])
  sing.Par.Prov.2.summary.long$metric[matchy.origin]<-sing.Par.Prov.2.summary.long$mean.perc[matchy.origin]/sing.origin*100
  # sum(sing.Par.Prov.2.summary.long$metric[matchy.origin]) #should be 100
  matchy.prov<-which(sing.Par.Prov.2.summary.long$geo.type=="Destination")
  sing.prov<-sum(sing.Par.Prov.2.summary.long$mean.perc[matchy.prov])
  sing.Par.Prov.2.summary.long$metric[matchy.prov]<-sing.Par.Prov.2.summary.long$mean.perc[matchy.prov]/sing.prov*100
  # sum(sing.Par.Prov.2.summary.long$metric[matchy.prov])
  ## Alluvial plot
  
  P1.S.wave2<- ggplot(sing.Par.Prov.2.summary.long,
         aes(x = geo.type, stratum = geo, alluvium = subject,
             y = metric,
             fill = geo, label = geo)) +
    scale_x_discrete(expand = c(0.01,0.01)) +
    scale_y_continuous(expand = c(0,0)) +
    geom_flow(alpha = 0.6,width=0.55) +
    geom_stratum(alpha = 0.8,width=0.55) +
    geom_text(stat = "stratum", size = 3.4,min.y=2,fontface="bold") +
    pubTheme+
    theme(legend.position = "none", axis.line = element_blank(), text =element_text(size=14),
          axis.ticks.x = element_blank(),axis.text.x = element_text(hjust=c(0.5,0.7)),
                  plot.margin=margin(4,4,4,4,unit="pt"))+
    labs(x=NULL,y="% singletons, during intervention")+
    GlobFillScale.mod
  P1.S.wave2
  # ggsave(paste(f.out,"WAVE2.Alluvial.percent.Parent.Node.png",sep=""),height=8,width=5,units="in")
  
  
  ### WAVE 3 AFTER BAN####
  #prep list item
  sing.Par.Prov.3.l<-replicate(n.B,vector())
  
  #go through each list item/subsample
  ## tabulate instances of location pairs
  for (k in 1:n.B){
    sing.Par.Prov.3.l[[k]]<-can.sing.boots[[k]] %>%
      filter(date>=as.Date(int.end)) %>%
      dplyr::group_by (par.state, tip.state) %>% dplyr::summarize (.groups="rowwise", n.Par= n()) %>% as.data.frame() %>% mutate(perc.Par=(n.Par/sum(n.Par))*100)
  
    ## add a column for subsample
    sing.Par.Prov.3.l[[k]]$SampleSet<-paste("Sample",BOOTS[k])
  
  }
  
  ## rbind the summaries
  sing.Par.Prov<-bind_rows(sing.Par.Prov.3.l)
  
  #summarize the mean and range for each of 1), 2) and 3)
  sing.Par.Prov.3.summary<-sing.Par.Prov %>% dplyr::group_by(par.state, tip.state) %>%
    dplyr::summarize(.groups="rowwise",
                     mean.n=round(mean(n.Par)),
                     sd.n=round(sd(n.Par,na.rm=T),digits=2),
                     mean.perc=round(mean(perc.Par),digits=2),
                     sd.perc=round(sd(perc.Par,na.rm=T),digits=2)) %>%
    as.data.frame()
  
  tot.Par<-sing.Par.Prov.3.summary %>% dplyr::group_by(par.state) %>%
    dplyr::summarise(.groups = "rowwise", totalImports=sum(mean.perc)) %>%
    as.data.frame()
  
  ## Alluvial plot for Figure 2
  #make a "subject column"
  sing.Par.Prov.3.summary$subject<-1:nrow(sing.Par.Prov.3.summary)
  # sing.Par.Prov.3.summary<-sing.Par.Prov.3.summary[-which(sing.Par.Prov.3.summary$mean.n<1),]
  
  
  sing.Par.Prov.3.summary$tip.state<-str_replace_all(sing.Par.Prov.3.summary$tip.state,"British Columbia","British\nColumbia")
  sing.Par.Prov.3.summary$par.state<-str_replace_all(sing.Par.Prov.3.summary$par.state,focal.source,focal.source)
  
  #order the geos
  ord.count<-sing.Par.Prov.3.summary%>% dplyr::group_by(par.state) %>%
    dplyr::summarise(.groups="rowwise",n=sum(mean.perc)) %>% as.data.frame()
  ord.count<-ord.count[rev(order(ord.count$n)),'par.state']
  sing.Par.Prov.3.summary$par.state<-factor(sing.Par.Prov.3.summary$par.state,levels=ord.count)
  
  ord.prov<-sing.Par.Prov.3.summary%>% dplyr::group_by(tip.state) %>%
    dplyr::summarise(.groups="rowwise",n=sum(mean.perc)) %>% as.data.frame()
  ord.prov<-ord.prov[rev(order(ord.prov$n)),'tip.state']
  sing.Par.Prov.3.summary$tip.state<-factor(sing.Par.Prov.3.summary$tip.state,levels=ord.prov)
  
  
  #make it long
  sing.Par.Prov.3.summary.long<-sing.Par.Prov.3.summary %>% pivot_longer(1:2, names_to = "geo.type", values_to = "geo")
  #order the geo types
  sing.Par.Prov.3.summary.long$geo.type<-factor(sing.Par.Prov.3.summary.long$geo.type,levels=c("par.state","tip.state"),labels=c("Origin","Destination"))
  
  # sing.Par.Prov.3.summary.long$geo[which(!sing.Par.Prov.3.summary.long$geo %in% names(globalPalette.ch))]
  
  #BECAUSE now showing a percent, rescale to equal 100 (means might not sum to 100)
  sing.Par.Prov.3.summary.long$metric<-sing.Par.Prov.3.summary.long$mean.perc
  matchy.origin<-which(sing.Par.Prov.3.summary.long$geo.type=="Origin")
  sing.origin<-sum(sing.Par.Prov.3.summary.long$mean.perc[matchy.origin])
  sing.Par.Prov.3.summary.long$metric[matchy.origin]<-sing.Par.Prov.3.summary.long$mean.perc[matchy.origin]/sing.origin*100
  # sum(sing.Par.Prov.3.summary.long$metric[matchy.origin]) #should be 100
  matchy.prov<-which(sing.Par.Prov.3.summary.long$geo.type=="Destination")
  sing.prov<-sum(sing.Par.Prov.3.summary.long$mean.perc[matchy.prov])
  sing.Par.Prov.3.summary.long$metric[matchy.prov]<-sing.Par.Prov.3.summary.long$mean.perc[matchy.prov]/sing.prov*100
  # sum(sing.Par.Prov.3.summary.long$metric[matchy.prov])
  ## Alluvial plot
  
  P1.S.wave3<- ggplot(sing.Par.Prov.3.summary.long,
         aes(x = geo.type, stratum = geo, alluvium = subject,
             y = metric,
             fill = geo, label = geo)) +
    scale_x_discrete(expand = c(0.01,0.01)) +
    scale_y_continuous(expand = c(0,0)) +
    geom_flow(alpha = 0.6,width=0.55) +
    geom_stratum(alpha = 0.8,width=0.55) +
    geom_text(stat = "stratum", size = 3.4,min.y=2,fontface="bold") +
    pubTheme+
    theme(legend.position = "none", axis.line = element_blank(), text =element_text(size=14),
          axis.ticks.x = element_blank(),axis.text.x = element_text(hjust=c(0.5,0.7)),
                  plot.margin=margin(4,4,4,4,unit="pt"))+
    labs(x=NULL,y="% singletons, after intervention")+
    GlobFillScale.mod
  P1.S.wave3
  # ggsave(paste(f.out,"WAVE2.Alluvial.percent.Parent.Node.png",sep=""),height=8,width=5,units="in")
  
  #grob plot of both waves
  plot_grid(P1.S.wave1,P1.S.wave2,P1.S.wave3,nrow=1,labels=c("A","B","C"))
  ggsave(paste(f.out,"SepWaves.Alluvial.singles.percent.Parent.Node.png",sep=""),height=5,width=9,units="in")
}
```

## Alluvial stratified by lineage, by wave
```{r}
if(mean(un.lins)>1 & int.yn==T){
  #summarize the total number and percent of intros by 1) par. loc, 2) prov of intro, maybe also 3) lineage
  #prep list item
  sing.Par.Prov.L.l<-replicate(n.B,vector())

  #go through each list item/subsample
  ## tabulate instances of location pairs
  for (k in 1:n.B){
    can.sing.boots[[k]]$date<-as.Date(can.sing.boots[[k]]$tmrca.dt.half)
    sing.Par.Prov.L.l[[k]]<-can.sing.boots[[k]] %>%
      filter(tmrca.dt.half<as.Date(int.start)) %>%
      dplyr::group_by (par.state, tip.state, Lineage) %>% dplyr::summarize (.groups="rowwise", n.Par= n()) %>% as.data.frame() %>% mutate(perc.Par=(n.Par/sum(n.Par))*100)

    ## add a column for subsample
    sing.Par.Prov.L.l[[k]]$SampleSet<-paste("Sample",BOOTS[k])

  }

  sing.Par.Prov.L<-bind_rows(sing.Par.Prov.L.l)


  #summarize the mean and range for each of 1), 2) and 3)
  sing.Par.Prov.L.summary<-sing.Par.Prov.L %>% dplyr::group_by(par.state, tip.state, Lineage) %>%
    dplyr::summarize(.groups="rowwise",
                     mean.n=round(mean(n.Par)),
                     sd.n=round(sd(n.Par,na.rm=T),digits=2),
                     mean.perc=round(mean(perc.Par),digits=2),
                     sd.perc=round(sd(perc.Par,na.rm=T),digits=2)) %>%
    as.data.frame()

  ### Alluvial plot for Figure 2

  #make a "subject column"
  sing.Par.Prov.L.summary$subject<-1:nrow(sing.Par.Prov.L.summary)
  # sing.Par.Prov.L.summary<-sing.Par.Prov.L.summary[-which(sing.Par.Prov.L.summary$mean.n<1),]
  # sum(sing.Par.Prov.summary.long$metric[matchy.prov],na.rm=T) #should be 100
  sing.Par.Prov.L.summary$tip.state<-str_replace_all(sing.Par.Prov.L.summary$tip.state,"British Columbia","British\nColumbia")
  sing.Par.Prov.L.summary$par.state<-str_replace_all(sing.Par.Prov.L.summary$par.state,focal.source,focal.source)

  #order the geos by frequency
  ord.count<-sing.Par.Prov.L.summary%>% dplyr::group_by(par.state) %>%
    dplyr::summarise(.groups="rowwise",n=sum(mean.perc)) %>% as.data.frame()
  ord.count<-ord.count[rev(order(ord.count$n)),'par.state']
  sing.Par.Prov.L.summary$par.state<-factor(sing.Par.Prov.L.summary$par.state,levels=ord.count)

  ord.prov<-sing.Par.Prov.L.summary%>% dplyr::group_by(tip.state) %>%
    dplyr::summarise(.groups="rowwise",n=sum(mean.perc)) %>% as.data.frame()
  ord.prov<-ord.prov[rev(order(ord.prov$n)),'tip.state']
  sing.Par.Prov.L.summary$tip.state<-factor(sing.Par.Prov.L.summary$tip.state,levels=ord.prov)

  #make it long
  sing.Par.Prov.L.summary.long<-sing.Par.Prov.L.summary %>% pivot_longer(1:2, names_to = "geo.type", values_to = "geo") %>% as.data.frame()


  #order the geo types and lineages
  sing.Par.Prov.L.summary.long$geo.type<-factor(sing.Par.Prov.L.summary.long$geo.type,levels=c("par.state","tip.state"),labels=c("Origin","Destination"))
  sing.Par.Prov.L.summary.long$Lineage<-factor(sing.Par.Prov.L.summary.long$Lineage,levels=aliases$lineage)


  #re-scale to perfect 100
  sing.Par.Prov.L.summary.long$metric<-sing.Par.Prov.L.summary.long$mean.perc
  matchy.origin<-which(sing.Par.Prov.L.summary.long$geo.type=="Origin")
  sing.origin<-sum(sing.Par.Prov.L.summary.long$mean.perc[matchy.origin])
  sing.Par.Prov.L.summary.long$metric[matchy.origin]<-sing.Par.Prov.L.summary.long$mean.perc[matchy.origin]/sing.origin*100

  sum(sing.Par.Prov.L.summary.long$metric[matchy.origin],na.rm=T) #should be 100
  matchy.prov<-which(sing.Par.Prov.L.summary.long$geo.type=="Destination")
  sing.prov<-sum(sing.Par.Prov.L.summary.long$mean.perc[matchy.prov])
  sing.Par.Prov.L.summary.long$metric[matchy.prov]<-sing.Par.Prov.L.summary.long$mean.perc[matchy.prov]/sing.prov*100

  #plot it
  alluv.sing.w1.lin<-ggplot(sing.Par.Prov.L.summary.long,
         aes(x = geo.type, stratum = geo, alluvium = subject,
             y = metric, label = geo)) +
    scale_x_discrete(expand = c(0.01,0.01)) +
    scale_y_continuous(expand = c(0,0)) +
    geom_flow(aes(fill = Lineage),alpha = 1,width=0.4) +
    LinFillScale+
    geom_stratum(alpha = 0.4,width=0.4 )+
    scale_color_manual(name = "geo",values = globalPalette.ch,na.value="grey60")+
    geom_text(stat = "stratum", size = 3.5,min.y=1,label.padding=unit(0.1, "lines")) +
    geom_text(stat="flow",aes(label=Lineage,color=Lineage),size=1.6,min.y=0.5,color="white",
              nudge_x=-0.206,hjust=1)+
    pubTheme+
    theme(legend.position = "none",text =element_text(size=14),
          axis.ticks.x = element_blank(),axis.text.x = element_text(hjust=c(0.5,0.5)),
          plot.margin=margin(6,4,28,4,unit="pt"))+
    labs(x=NULL,y="% singletons, before intervention")
  alluv.sing.w1.lin

  ggsave(paste(f.out,"/Singleton.Alluvial.Wave1.Lineage.Parent.Node.Lin.png",sep=""),height=8,width=5,units="in")

  ### SECOND WAVE ####
  #summarize the total number and percent of intros by 1) par. loc, 2) prov of intro, maybe also 3) lineage
  #prep list item
  sing.Par.Prov.L2.l<-replicate(n.B,vector())

  #go through each list item/subsample
  ## tabulate instances of location pairs
  for (k in 1:n.B){
    can.sing.boots[[k]]$tmrca.dt.half<-as.Date(can.sing.boots[[k]]$tmrca.dt.half)
    sing.Par.Prov.L2.l[[k]]<-can.sing.boots[[k]] %>%
      filter(tmrca.dt.half>=as.Date(int.start)) %>%
      dplyr::group_by (par.state, tip.state, Lineage) %>% dplyr::summarize (.groups="rowwise", n.Par= n()) %>% as.data.frame() %>% mutate(perc.Par=(n.Par/sum(n.Par))*100)

    ## add a column for subsample
    sing.Par.Prov.L2.l[[k]]$SampleSet<-paste("Sample",BOOTS[k])

  }

  sing.Par.Prov.L<-bind_rows(sing.Par.Prov.L2.l)


  #summarize the mean and range for each of 1), 2) and 3)
  sing.Par.Prov.L2.summary<-sing.Par.Prov.L %>% dplyr::group_by(par.state, tip.state, Lineage) %>%
    dplyr::summarize(.groups="rowwise",
                     mean.n=round(mean(n.Par)),
                     sd.n=round(sd(n.Par,na.rm=T),digits=2),
                     mean.perc=round(mean(perc.Par),digits=2),
                     sd.perc=round(sd(perc.Par,na.rm=T),digits=2)) %>%
    as.data.frame()

  ### Alluvial plot for Figure 2

  #make a "subject column"
  sing.Par.Prov.L2.summary$subject<-1:nrow(sing.Par.Prov.L2.summary)
  # sing.Par.Prov.L2.summary<-sing.Par.Prov.L2.summary[-which(sing.Par.Prov.L2.summary$mean.n<1),]

  sing.Par.Prov.L2.summary$tip.state<-str_replace_all(sing.Par.Prov.L2.summary$tip.state,"British Columbia","British\nColumbia")

  #order the geos by frequency
  ord.count<-sing.Par.Prov.L2.summary%>% dplyr::group_by(par.state) %>%
    dplyr::summarise(.groups="rowwise",n=sum(mean.n)) %>% as.data.frame()
  ord.count<-ord.count[rev(order(ord.count$n)),'par.state']
  sing.Par.Prov.L2.summary$par.state<-factor(sing.Par.Prov.L2.summary$par.state,levels=ord.count)

  ord.prov<-sing.Par.Prov.L2.summary%>% dplyr::group_by(tip.state) %>%
    dplyr::summarise(.groups="rowwise",n=sum(mean.n)) %>% as.data.frame()
  ord.prov<-ord.prov[rev(order(ord.prov$n)),'tip.state']
  sing.Par.Prov.L2.summary$tip.state<-factor(sing.Par.Prov.L2.summary$tip.state,levels=ord.prov)

  #make it long
  sing.Par.Prov.L2.summary.long<-sing.Par.Prov.L2.summary %>% pivot_longer(1:2, names_to = "geo.type", values_to = "geo")
  #order the geo types
  sing.Par.Prov.L2.summary.long$geo.type<-factor(sing.Par.Prov.L2.summary.long$geo.type,levels=c("par.state","tip.state"),labels=c("Origin","Destination"))

  sing.Par.Prov.L2.summary.long$Lineage<-factor(sing.Par.Prov.L2.summary.long$Lineage,levels=aliases$lineage)

  #re-scale
  sing.Par.Prov.L2.summary.long$metric<-sing.Par.Prov.L2.summary.long$mean.perc
  matchy.origin<-which(sing.Par.Prov.L2.summary.long$geo.type=="Origin")
  sing.origin<-sum(sing.Par.Prov.L2.summary.long$mean.perc[matchy.origin])
  sing.Par.Prov.L2.summary.long$metric[matchy.origin]<-sing.Par.Prov.L2.summary.long$mean.perc[matchy.origin]/sing.origin*100
  sum(sing.Par.Prov.L2.summary.long$metric[matchy.origin],na.rm=T) #should be 100
  matchy.prov<-which(sing.Par.Prov.L2.summary.long$geo.type=="Destination")
  sing.prov<-sum(sing.Par.Prov.L2.summary.long$mean.perc[matchy.prov])
  sing.Par.Prov.L2.summary.long$metric[matchy.prov]<-sing.Par.Prov.L2.summary.long$mean.perc[matchy.prov]/sing.prov*100

  #plot it
  alluv.sing.w2.lin<-ggplot(sing.Par.Prov.L2.summary.long,
         aes(x = geo.type, stratum = geo, alluvium = subject,
             y = metric, label = geo)) +
    scale_x_discrete(expand = c(0.01,0.01)) +
    scale_y_continuous(expand = c(0,0)) +
    geom_flow(aes(fill = Lineage),alpha = 1,width=0.4) +
    LinFillScale+
    # new_scale("fill")+ #sneaky
    geom_stratum(alpha = 0.4,width=0.4) +
    scale_color_manual(name = "geo",values = globalPalette.ch,na.value="grey60")+
    geom_text(stat = "stratum", size = 3.5,min.y=1) +
    geom_text(stat="flow",aes(label=Lineage,color=Lineage),size=1.6,min.y=0.5,color="white",
              nudge_x=-0.206,hjust=1)+
    pubTheme+
    theme(legend.position = "none",text =element_text(size=14),
          axis.ticks.x = element_blank(),axis.text.x = element_text(hjust=c(0.5,0.5)),
          plot.margin=margin(6,4,28,4,unit="pt"))+ #accommodate the lineage group image
    labs(x=NULL,y="% singletons, after intervention")
  alluv.sing.w2.lin

  ggsave(paste(f.out,"/Singleton.Alluvial.Wave2.Lineage.Parent.Node.Lin.png",sep=""),height=8,width=5,units="in")
}
```

## singletons: rolling rates
```{r}
#mid script lists for rolling means
par.state.sing.boots<-replicate(n=n.B,vector())
par.state.sing.boots.full<-replicate(n=n.B,vector())
tip.state.sing.boots<-replicate(n=n.B,vector())
tip.state.sing.boots.full<-replicate(n=n.B,vector())


for (k in 1:n.B){
  #make sure this a date
  can.sing.boots[[k]]$tmrca.dt.half<-as.Date(can.sing.boots[[k]]$tmrca.dt.half)
  
  #### Calculate a rolling 7-day mean for origins ####
  
  ## count the importations by origin location over time
  par.state.sing.boots[[k]]<-can.sing.boots[[k]] %>%
    dplyr::select(par.state, Lineage,tmrca.dt.half) %>%
    dplyr::group_by(tmrca.dt.half, par.state) %>%
    dplyr::summarize(.groups="rowwise", total=n()) %>%
    dplyr::arrange(desc(par.state)) %>% 
    dplyr::group_by(par.state) 
  
  #need to add rows for missing dates
  alldays<-seq(ymd(first(sort(par.state.sing.boots[[k]]$tmrca.dt.half))),
      ymd(last(sort(par.state.sing.boots[[k]]$tmrca.dt.half))),
      by='1 day')
  
  #make a empty df in same structure as above then populate it
  nL<-length(unique(par.state.sing.boots[[k]]$par.state))
  nD<-length(alldays)
  par.state.sing.boots.full[[k]]<-data.frame(tmrca.dt.half=rep(alldays,times=nL),
par.state = sort(rep(unique(par.state.sing.boots[[k]]$par.state),times=nD)),
                                 total=0)
  # nrow(par.state.sing.boots[[k]].empty)==nD*nL      
  
  #populate it
  for (i in 1:nrow(par.state.sing.boots.full[[k]])){
    #look for a match
    match<-which(par.state.sing.boots[[k]]$par.state==par.state.sing.boots.full[[k]]$par.state[i] &
            par.state.sing.boots[[k]]$tmrca.dt.half==par.state.sing.boots.full[[k]]$tmrca.dt.half[i])
    if(length(match)==0) next #no match, no change
    #else, replace:
    par.state.sing.boots.full[[k]]$total[i]<-par.state.sing.boots[[k]]$total[match]
  }
  
  # sum(par.state.sing.boots.full[[k]]$total[par.state.sing.boots.full[[k]]$par.state=="USA"])==sum(par.state.sing.boots[[k]]$total[par.state.sing.boots[[k]]$par.state=="USA"])
  
  par.state.sing.boots.full[[k]]<-par.state.sing.boots.full[[k]] %>% 
    dplyr::mutate(intros_mean7d = zoo::rollmean(total, k = 7, fill = NA),
                  intros_mean14d = zoo::rollmean(total, k = 14, fill = NA),
                  intros_median7d = zoo::rollmedian(total, k = 7, fill = NA),
                  intros_sum7d = zoo::rollsum(total, k = 7, fill = NA,align="right")) %>% #right align to sum all prev
    #rolling mean and median weekly importation rate
    dplyr::mutate(intros_meansum7d = zoo::rollmean(intros_sum7d, k = 7, fill = NA), 
                  intros_mediansum7d = zoo::rollmedian(intros_sum7d, k = 7, fill = NA),) %>%
    dplyr::ungroup()
   
  ## count the importations by tip.state over time
  tip.state.sing.boots[[k]]<-can.sing.boots[[k]] %>%
    dplyr::select(tip.state, Lineage,tmrca.dt.half) %>%
    group_by(tmrca.dt.half, tip.state) %>%
    dplyr::summarize(.groups="rowwise", total=n()) %>%
    dplyr::arrange(desc(tip.state)) %>% 
    dplyr::group_by(tip.state) 
  
  #need to add rows for missing dates
  alldays<-seq(ymd(first(sort(tip.state.sing.boots[[k]]$tmrca.dt.half))),
      ymd(last(sort(tip.state.sing.boots[[k]]$tmrca.dt.half))),
      by='1 day')
  
  #make a empty df in same structure as above then populate it
  nL<-length(unique(tip.state.sing.boots[[k]]$tip.state))
  nD<-length(alldays)
  tip.state.sing.boots.full[[k]]<-data.frame(tmrca.dt.half=rep(alldays,times=nL),
                                 tip.state=sort(rep(unique(tip.state.sing.boots[[k]]$tip.state),times=nD)),
                                 total=0)
  # nrow(tip.state.sing.boots[[k]].empty)==nD*nL      
  
  #populate it
  for (i in 1:nrow(tip.state.sing.boots.full[[k]])){
    #look for a match
    match<-which(tip.state.sing.boots[[k]]$tip.state==tip.state.sing.boots.full[[k]]$tip.state[i] &
            tip.state.sing.boots[[k]]$tmrca.dt.half==tip.state.sing.boots.full[[k]]$tmrca.dt.half[i])
    if(length(match)==0) next #no match, no change
    #else, replace:
    tip.state.sing.boots.full[[k]]$total[i]<-tip.state.sing.boots[[k]]$total[match]
  }
  
  # sum(tip.state.sing.boots.full[[k]]$total[tip.state.sing.boots.full[[k]]$tip.state=="USA"])==sum(tip.state.sing.boots[[k]]$total[tip.state.sing.boots[[k]]$tip.state=="USA"])
  
  tip.state.sing.boots.full[[k]]<-tip.state.sing.boots.full[[k]] %>% 
    dplyr::mutate(intros_mean7d = zoo::rollmean(total, k = 7, fill = NA),
                  intros_mean14d = zoo::rollmean(total, k = 14, fill = NA),
                  intros_median7d = zoo::rollmedian(total, k = 7, fill = NA),
                  intros_sum7d = zoo::rollsum(total, k = 7, fill = NA,align="right")) %>% #right align to sum all prev
    #rolling mean and median weekly importation rate
    dplyr::mutate(intros_meansum7d = zoo::rollmean(intros_sum7d, k = 7, fill = NA), 
                  intros_mediansum7d = zoo::rollmedian(intros_sum7d, k = 7, fill = NA),) %>%
    dplyr::ungroup()

}

## Summarize the rolling means overall

## BY ORIGINS

#go through each list item/subsample
for (k in 1:n.B){
  ## add a column for subsample
  par.state.sing.boots.full[[k]]$SampleSet<-paste("Sample",BOOTS[k])
}

## rbind the summaries
sing.Par.Roll<-bind_rows(par.state.sing.boots.full)

#summarize the mean and confint
sing.Par.Roll.summary<-sing.Par.Roll %>% dplyr::group_by(tmrca.dt.half, par.state) %>%
  dplyr::summarize(.groups="rowwise",
                   intros_meansum7d.mean=(mean(intros_meansum7d,na.rm=T)),
                   intros_meansum7d.sd=sd(intros_meansum7d,na.rm=T)) %>%
  as.data.frame()

#order the geos
ord.count<-sing.Par.Roll.summary%>% dplyr::group_by(par.state) %>%
  dplyr::summarise(.groups="rowwise",n=sum(intros_meansum7d.mean)) %>% as.data.frame()
ord.count<-ord.count[rev(order(ord.count$n)),'par.state']
sing.Par.Roll.summary$par.state<-factor(sing.Par.Roll.summary$par.state,levels=ord.count)

# BY PROVINCE
#go through each list item/subsample
for (k in 1:n.B){
  ## add a column for subsample
  tip.state.sing.boots.full[[k]]$SampleSet<-paste("Sample",BOOTS[k])
}

## rbind the summaries
sing.Prov.Roll<-bind_rows(tip.state.sing.boots.full)
#summarize the mean and confint
sing.Prov.Roll.summary<-sing.Prov.Roll %>% dplyr::group_by(tmrca.dt.half, tip.state) %>%
  dplyr::summarize(.groups="rowwise",
                   intros_meansum7d.mean=(mean(intros_meansum7d,na.rm=T)),
                   intros_meansum7d.sd=(sd(intros_meansum7d,na.rm=T))) %>%
  as.data.frame()

#order the geos
ord.prov.s<-sing.Prov.Roll.summary%>% dplyr::group_by(tip.state) %>%
  dplyr::summarise(.groups="rowwise",n=sum(intros_meansum7d.mean,na.rm=T)) %>% as.data.frame()
ord.prov.s<-ord.prov.s[rev(order(ord.prov.s$n)),'tip.state']
sing.Prov.Roll.summary$tip.state<-factor(sing.Prov.Roll.summary$tip.state,levels=ord.prov.s)
```

## Plot singletons over time using rolling rates, by tmrca, by origin or dest
```{r}
sing.all<-sing.Par.Roll.summary %>% dplyr::group_by(tmrca.dt.half) %>%
  dplyr::summarise(totalmean=sum(intros_meansum7d.mean,na.rm=T))
y.upper<-ceiling(max(sing.all$totalmean,na.rm=T))
#rolling importation rate, by origin
y.lim<-c(0,y.upper)

p1.sing<-sing.Par.Roll.summary %>%
  ggplot(aes(x=tmrca.dt.half,y=intros_meansum7d.mean,group=par.state,fill=par.state))+
  # annotate(geom="rect",xmin = as.Date(int.start), 
  #          xmax = as.Date(int.end),
  #            ymin = y.lim[1], ymax =y.lim[2], 
  #          color="grey85",size=0,  fill="grey80")+
  # annotate(geom="text",
  #          x = (as.Date(int.start)),y=y.lim[2]-0.25, 
  #          vjust=0.5, hjust=0,
  #          label=int.descrip,fontface="italic",color="grey25",size=3)+
  geom_density(stat="identity", position="stack",lwd=0,alpha=0.9)+
  CountryFillScale+
  pubThemeDate+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        text=element_text(size=10,face="bold"),
        legend.position = "none")+
  scaleDateFlex+
  labs(x="Sample date",y=paste0("Singletons per week"))+
  scale_y_continuous(expand=c(0,0),limits=y.lim,breaks=seq(0,y.upper,5))+
  guides(fill = guide_legend(keywidth = 0.7,keyheight=0.7,title.position = "top",title="Origin",legend.spacing=0,ncol=4))
# p1.sing

##fake plots to take the legends
p1.f<-sing.Par.Roll.summary %>%
  ggplot(aes(x=tmrca.dt.half,y=intros_meansum7d.mean,group=par.state,fill=par.state))+
  geom_density(stat="identity", position="stack",lwd=0,alpha=0.9)+
  CountryFillScale+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        text=element_text(size=9,face="bold"),
        legend.position = c(0.1,1),
        legend.margin=margin(0,0,0,0),
        legend.background = element_blank(),
        legend.justification = c(0,1))+
  guides(fill = guide_legend(keywidth = 0.7,keyheight=0.7,title.position = "top",title="Origin",legend.spacing=0,nrow=4))

p1.guide<-get_legend(p1.f)


#rolling importation rate, by province destination
p2.sing<-sing.Prov.Roll.summary %>%
  ggplot(aes(x=tmrca.dt.half,y=intros_meansum7d.mean,group=tip.state,fill=tip.state))+
  # annotate(geom="rect",xmin =( as.Date(int.start)), 
  #          xmax = as.Date(int.end),
  #            ymin = y.lim[1], ymax =y.lim[2], 
  #          color="grey85",size=0,  fill="grey80")+
  #  annotate(geom="text",
  #          x = (as.Date(int.start)),y=y.lim[2]-0.25, 
  #          vjust=0.5, hjust=0,
  #          label=int.descrip,fontface="italic",color="grey25",size=3)+
  geom_density(stat="identity", position="stack",lwd=0,alpha=0.9)+
  ProvFillScale+
  pubThemeDate+
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        legend.position = "none",plot.margin = unit(c(4.5,4.5,4.5,4.5), "pt") #axis.title.y=element_blank()
        )+
  scaleDateFlex+
  labs(x="Sampling date",y=paste0("Singletons per week"))+
  scale_y_continuous(expand=c(0,0),limits=y.lim,breaks=seq(0,y.upper,5))
p2.sing
#fake plot to take legend
p2.f<-sing.Prov.Roll.summary %>%
  ggplot(aes(x=tmrca.dt.half,y=intros_meansum7d.mean,group=tip.state,fill=tip.state))+
  geom_density(stat="identity", position="stack",lwd=0,alpha=0.9)+  
  ProvFillScale+
  theme(axis.text.x=element_text(angle=45,hjust = 1),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background=element_rect("grey95"),
        text=element_text(size=9,face="bold"),
        legend.position = c(0.1,1),
        legend.margin=margin(0,0,0,0),
        legend.background = element_blank(),
        legend.justification = c(0,1))+
    guides(fill = guide_legend(keywidth = 0.7,keyheight=0.7,title.position = "top",title="Province",legend.spacing=0,nrow=4))
p2.guide<-get_legend(p2.f)

#make a list of grobs
## add in the Canadian province representation plots
plot.row<-plot_grid(p1.sing,p2.sing,rel_widths = c(1,0.93),ncol=2,labels=c("A" ,"B"))
plot.leg<-plot_grid(p1.guide,p2.guide,ncol=2,align="h")
plot.all<-plot_grid(plot.leg,plot.row,nrow=2,rel_heights = c(0.25,1),align = "v")

png(file=paste(f.out,"/Singles_OverTime_OriginsDestinations.png",sep=""),
          width=8.5,height=5,units = "in", bg = "white",res=200)
print(plot.all)
dev.off()

```

## Make singletons over time plots using lines
```{r}
##PLOT AS LINE WITH CONFIDENCE INTERVALS
t.here<-qt(0.025,(n.B-1),lower.tail=F)
sing.Par.Roll.summary<-sing.Par.Roll.summary %>% mutate(upper.CI=(intros_meansum7d.mean)+(intros_meansum7d.sd/sqrt(10)*t.here),
       lower.CI=(intros_meansum7d.mean)-(intros_meansum7d.sd/sqrt(10)*t.here))

## Add an indidicator for source country vs not to add alpha channel to other lines
sing.Par.Roll.summary$focal<-0
sing.Par.Roll.summary$focal[which(sing.Par.Roll.summary$par.state%in%focal.source)]<-1
alphavals<-c(0.3,0.9)
names(alphavals)<-c("0","1")  
sing.Par.Roll.summary$focal<-as.factor(sing.Par.Roll.summary$focal)
y.lim2<-c(0,(max(sing.Par.Roll.summary$upper.CI,na.rm=T)+1))
y.jumps2<-ceiling(y.lim2[2]/5)
p1.sing.line.ci<-sing.Par.Roll.summary %>%
  ggplot(aes(x=tmrca.dt.half,y=intros_meansum7d.mean,group=par.state))+
  pubThemeDate+
  theme(text=element_text(size=10,face="bold"),
        legend.position = c(0.8,0.7),
        legend.text=element_text(size=rel(0.7)),
        legend.title=element_text(size=rel(0.8)),
        legend.margin=margin(1,1,1,1,"pt"))+
  # annotate(geom="rect",xmin = int.start, xmax = int.end,
  #            ymin = y.lim2[1], ymax =y.lim2[2], color="grey85",size=0,  fill="grey80")+
  #   annotate(geom="text",
  #          x = (as.Date(int.start)),y=y.lim2[2]-0.25, 
  #          vjust=0.5, hjust=0,
  #          label=int.descrip,fontface="italic",color="grey25",size=3)+
  geom_ribbon(aes(ymin=lower.CI,ymax=upper.CI, 
                  fill=par.state, alpha=focal))+
  geom_line(stat="identity",lwd=1,aes(alpha=focal,color=par.state))+
  GlobRegColScale+
  GlobRegFillScale+
  scale_alpha_manual(values=alphavals)+
  labs(x="Sample date",y=paste0("Singletons per week"), fill="Origin Location")+
  scaleDateFlexLess+
  scale_y_continuous(expand=c(0,0),breaks=seq(0,y.lim2[2],y.jumps))+
 guides(fill = guide_legend(keywidth = 0.6,keyheight=0.6,
                              title.position = "top",title="Global origin",
                              legend.spacing=0,ncol=1),
         alpha="none", color="none")+
  coord_cartesian(ylim=y.lim2)
p1.sing.line.ci
ggsave(paste(f.out,"/Rolling-singleton-importRate_line_confint.png",sep=""),height=3,width=3.5)

#Line no CI
p1.sing.line<-sing.Par.Roll.summary %>%
  ggplot(aes(x=tmrca.dt.half,y=intros_meansum7d.mean,group=par.state))+
  pubThemeDate+
  theme(text=element_text(size=10,face="bold"),
        legend.position = c(0.8,0.7),
        legend.text=element_text(size=rel(0.7)),
        legend.title=element_text(size=rel(0.8)),
        legend.margin=margin(1,1,1,1,"pt"))+
  # annotate(geom="rect",xmin = int.start, xmax = int.end,
  #            ymin = y.lim2[1], ymax =y.lim2[2], 
  #          color="grey85",size=0,  fill="grey80")+
  #   annotate(geom="text",
  #          x = (as.Date(int.start)),y=y.lim2[2]-0.25, 
  #          vjust=0.5, hjust=0,
  #          label=int.descrip,fontface="italic",color="grey25",size=3)+
  geom_line(stat="identity",lwd=1,aes(alpha=focal,color=par.state))+
  GlobRegColScale+
  # GlobRegFillScale+
  scale_alpha_manual(values=alphavals)+
  labs(x="Sample date",y=paste0("Singletons per week"), fill="Origin Location")+
  scaleDateFlex+
  scale_y_continuous(expand=c(0,0),breaks=seq(0,y.lim2[2],y.jumps2))+
  guides(color = guide_legend(keywidth = 0.6,keyheight=0.6,
                              title.position = "top",title="Global origin",
                              legend.spacing=0,ncol=1),
         alpha="none")+
  coord_cartesian(ylim=y.lim2)
p1.sing.line
ggsave(paste(f.out,"/Rolling-singleton-importRate_line.png",sep=""),height=3,width=3.5)

write.csv(sing.Par.Roll.summary, paste0(f.out,"sing.par.roll.summary.csv"))

```



## summarize Maximum singleton rolling rates
```{r}
#overall sum of new singletons/week in Canada max
sing.Roll.total<-sing.Prov.Roll.summary %>% dplyr::group_by(tmrca.dt.half) %>%
  dplyr::summarize(.groups="rowwise",
                   total_meansum7d.mean=(sum(intros_meansum7d.mean,na.rm=T)),
                   total_meansum7d.sd=(sum(intros_meansum7d.sd,na.rm=T))) %>%
  as.data.frame()
max.overall<-head(na.omit(sing.Roll.total[rev(order(sing.Roll.total$total_meansum7d.mean)),]),n=1)
dt.temp<-max.overall[1,1]
cat(paste0("Max weekly singles importation rate overall on ", dt.temp,": ",
           mean.95ci.givenmsd(m=max.overall[2],sd=max.overall[3],n=n.B,2)),
    file=text.out,sep="\n",append=T)

#Max from focal.source
max.mean.focal<-max(sing.Par.Roll.summary$intros_meansum7d.mean[sing.Par.Roll.summary$par.state%in%focal.source],na.rm=T) 
max.sd.focal<-sing.Par.Roll.summary$intros_meansum7d.sd[which(sing.Par.Roll.summary$intros_meansum7d.mean ==max(sing.Par.Roll.summary$intros_meansum7d.mean[sing.Par.Roll.summary$par.state%in%focal.source],na.rm=T) )]
dt.focal<-sing.Par.Roll.summary$tmrca.dt.half[which(sing.Par.Roll.summary$intros_meansum7d.mean==max(sing.Par.Roll.summary$intros_meansum7d.mean[sing.Par.Roll.summary$par.state%in%focal.source],na.rm=T)) ] 

cat(paste0("Max weekly singles importation rate from ",focal.source, " on ",dt.focal,
           ": ", mean.95ci.givenmsd(m=max.mean.focal,sd=max.sd.focal, n.B, 2) ),
    file=text.out,sep="\n",append=T)

## Max from USA 
max.mean.usa<-max(sing.Par.Roll.summary$intros_meansum7d.mean[sing.Par.Roll.summary$par.state=="USA"],na.rm=T) 
max.sd.usa<-sing.Par.Roll.summary$intros_meansum7d.sd[which(sing.Par.Roll.summary$intros_meansum7d.mean ==max.mean.usa )]
dt.usa<-sing.Par.Roll.summary$tmrca.dt.half[which(sing.Par.Roll.summary$intros_meansum7d.mean==max.mean.usa) ] 
cat(paste0("Max weekly singles importation rate from ","USA", " on ",dt.usa,
           ": ", mean.95ci.givenmsd(m=max.mean.usa,sd=max.sd.usa, n.B, 2) ),
    file=text.out,sep="\n",append=T)

## IF there was a var-specifc intervention, calculate singles import on date implemented vs two weeks after from focal source
if(int.yn==T){
   rate.pre<-sing.Par.Roll.summary %>% filter(par.state%in%focal.source) %>% filter(tmrca.dt.half==int.start)
   
   rate.2wk<-sing.Par.Roll.summary %>% filter(par.state%in%focal.source) %>% filter(tmrca.dt.half==(int.start+14))
   
    rate.4wk<-sing.Par.Roll.summary %>% filter(par.state%in%focal.source) %>% filter(tmrca.dt.half==(int.start+28))
   
   cat(paste0("Weekly singles importation rate pre-int from ",focal.source, 
              " on ",int.start,": ", 
              mean.95ci.givenmsd(m=rate.pre$intros_meansum7d.mean,
                                    sd=rate.pre$intros_meansum7d.sd, n.B, 2) ),
    file=text.out,sep="\n",append=T)
   
   cat(paste0("Weekly singles importation rate 2-weeks post-int from ",focal.source, 
              " on ",int.start+14, ": ", 
              mean.95ci.givenmsd(m=rate.2wk$intros_meansum7d.mean,
                                    sd=rate.2wk$intros_meansum7d.sd, n.B, 2) ),
    file=text.out,sep="\n",append=T)
   
   
   ## FOLD DECREASE from pre to 2wk
   fc2wk.focal<-c()
   fc4wk.focal<-c()

   for (k in 1:n.B){
     temp<-par.state.sing.boots.full[[k]] %>% 
      dplyr::filter(par.state%in%focal.source) %>%
      as.data.frame()
     temp.pre<-temp %>% filter(tmrca.dt.half==int.start)
     temp.2wk<-temp %>% filter(tmrca.dt.half==(int.start+14))
     temp.4wk<-temp %>% filter(tmrca.dt.half==(int.start+28))

     fc2wk<-temp.pre$intros_meansum7d/temp.2wk$intros_meansum7d #fold change 2wk/pre (ex: 10/1)
     fc2wk.focal<-c(fc2wk.focal, fc2wk)
     
     fc4wk<-temp.pre$intros_meansum7d/temp.4wk$intros_meansum7d #fold change 2wk
     fc4wk.focal<-c(fc4wk.focal, fc4wk)
   }
   fc2wk.focal<-fc2wk.focal[is.finite(fc2wk.focal)]
   fc4wk.focal<-fc4wk.focal[is.finite(fc4wk.focal)]
   
   mean.fc.2wk<-mean.95ci.X(fc2wk.focal,2)
   mean.fc.4wk<-mean.95ci.X(fc4wk.focal,2)

   cat(paste0("Fold decrease singles rate pre-int to 2-weeks after int from ",focal.source, 
              ": ", mean.fc.2wk),    file=text.out,sep="\n",append=T)
   
   cat(paste0("Fold decrease singles rate pre-int to 4-weeks after int from ",focal.source, 
              ": ", mean.fc.4wk),    file=text.out,sep="\n",append=T)
   
}

```


## summary of total intros over time, all sources
```{r}
totalsublin<-sum.Par.Roll.summary %>% 
  dplyr::group_by(tmrca.dt) %>%
  dplyr::summarize(total.intros=sum(intros_meansum7d.mean, na.rm=T)) %>% as.data.frame()
totalsublin$type<-"sublineage"
head(totalsublin)

totalsingle<-sing.Par.Roll.summary %>% 
  dplyr::group_by(tmrca.dt.half) %>%
  dplyr::summarize(total.intros=sum(intros_meansum7d.mean, na.rm=T)) %>% as.data.frame()
totalsingle$type<-"singleton"
colnames(totalsingle)[1]<-"tmrca.dt"

totalintros<-bind_rows(totalsingle, totalsublin)

totalintros %>%
  ggplot()+
  geom_bar(aes(x=tmrca.dt,y=total.intros,color=type),stat="identity",width=1)+
  pubThemeDate+
  scaleDateFlex+
  labs(x=NULL, y="Total daily introductions")+
  theme(legend.position = "top")
ggsave(paste0(f.out,"AllIntros_OVerTime_byType.png"),width=5,height=5)

totalintros %>%
  ggplot()+
  geom_bar(aes(x=tmrca.dt,y=total.intros),stat="identity",width=1,color=var.col)+
  pubThemeDate+
  scaleDateFlex+
  labs(x=NULL, y="Total daily introductions")+
  theme(legend.position = "top")
ggsave(paste0(f.out,"AllIntros_OverTime_AllTypes.png"),width=4,height=4)

#export daily intros all sources
write.csv(totalintros,paste0(f.out, "alldailyintros.csv"))
```


# SUMMARY OF TOP SOURCES FOR SINGLETONS AND SUBLINEAGES
```{r}
#what percent of singletons came from the top sources
top.sources<-names(rev(sort(table(can.sing.boots[[1]]$par.state))))
for (i in 1:length(top.sources)){
  source<-c()
  for (k in 1:n.B){
    perc<- signif(length(which(can.sing.boots[[k]]$par.state==top.sources[i]))/
      nrow(can.sing.boots[[k]])*100, digits = 3)
    source<-c(source, perc)
  }
  # print(top.sources[i])
  # mean.95ci.X(source)
  cat(paste0("Percent singletons from",top.sources[i],"= ",
           mean.95ci.X(source) ),
    file=text.out,sep="\n",append=T)
}


#what percent of sublineages came from the top sources
top.sources<-names(rev(sort(table(sum.boots[[1]]$Parent.Location))))
for (i in 1:length(top.sources)){
  source<-c()
  for (k in 1:n.B){
    perc<- signif(length(which(sum.boots[[k]]$Parent.Location==top.sources[i]))/
      nrow(sum.boots[[k]])*100, digits = 3)
    source<-c(source, perc)
  }
  print(top.sources[i])
  mean.95ci.X(source)
  cat(paste0("Percent sublineages from ",top.sources[i],"= ",
           mean.95ci.X(source) ),
    file=text.out,sep="\n",append=T)
}
```

## Likelihood quadrants
```{r}
likes<-replicate(n.B,vector())
for (k in 1:n.B){
  likes[[k]]<-sum.boots[[k]][,c('Node.Likelihood','Parent.Likelihood')]
}
sum.likes<-bind_rows(likes)

#summary stats
summary(sum.likes$Node.Likelihood)
summary(sum.likes$Parent.Likelihood)

Nlik<-nrow(sum.likes)

#text for plot
p.5.n.5<-round(nrow(sum.likes[sum.likes$Parent.Likelihood<0.5 & sum.likes$Node.Likelihood<0.5,]) / Nlik * 100 ,digits=1)
p.5.n.9<-round(nrow(sum.likes[sum.likes$Parent.Likelihood<0.5 & sum.likes$Node.Likelihood<0.9 & sum.likes$Node.Likelihood>=0.5,]) / Nlik * 100,digits=1)
p.9.n.5<-round(nrow(sum.likes[sum.likes$Parent.Likelihood<0.9 & sum.likes$Parent.Likelihood>=0.5 & sum.likes$Node.Likelihood<0.5,]) / Nlik * 100,digits=1)
p.9.n.9<-round(nrow(sum.likes[sum.likes$Parent.Likelihood<0.9 & sum.likes$Parent.Likelihood>=0.5 & sum.likes$Node.Likelihood>=0.5 & sum.likes$Node.Likelihood<0.9,]) / Nlik * 100,digits=1)

p.5<-round(nrow(sum.likes[sum.likes$Parent.Likelihood<0.5 & sum.likes$Node.Likelihood>=0.9,]) / Nlik * 100,digits=1)
n.5<-round(nrow(sum.likes[sum.likes$Parent.Likelihood>=0.9 & sum.likes$Node.Likelihood<0.5,]) / Nlik * 100,digits=1)
p.9<-round(nrow(sum.likes[sum.likes$Parent.Likelihood<0.9 & sum.likes$Parent.Likelihood>=0.5 & sum.likes$Node.Likelihood>=0.9,]) / Nlik * 100,digits=1)
n.9<-round(nrow(sum.likes[sum.likes$Parent.Likelihood>=0.9 & sum.likes$Node.Likelihood>=0.5 & sum.likes$Node.Likelihood<0.9,]) / Nlik * 100,digits=1)

p.n<-round(nrow(sum.likes[sum.likes$Parent.Likelihood>=0.9 & sum.likes$Node.Likelihood>=0.9,]) / Nlik * 100,digits=1)


#Plot this with 0.5 and 0.9 cutoffs shown
ggplot(sum.likes)+
  geom_point(aes(x=Node.Likelihood, y=Parent.Likelihood),color="cyan4",alpha=0.5)+
  geom_vline(xintercept=c(0.5,0.9),linetype="dashed", color="red",size=0.5)+
  geom_hline(yintercept=c(0.5,0.9),linetype="dashed", color="blue",size=0.5)+
  pubTheme+
  annotate("text",x=0.5,y=0.5,label=paste(p.5.n.5,"%",sep=""),size=3.5,hjust=1,vjust=1, fontface="bold")+
  annotate("text",x=0.9,y=0.5,label=paste(p.5.n.9,"%",sep=""),size=3.5,hjust=1,vjust=1, fontface="bold")+
  annotate("text",x=0.5,y=0.9,label=paste(p.9.n.5,"%",sep=""),size=3.5,hjust=1,vjust=1, fontface="bold")+
  annotate("text",x=0.9,y=0.9,label=paste(p.9.n.9,"%",sep=""),size=3.5,hjust=1,vjust=1, fontface="bold")+
  annotate("text",x=1,y=0.5,label=paste(p.5,"%",sep=""),size=3.5,hjust=1,vjust=1, fontface="bold")+
  annotate("text",x=1,y=0.9,label=paste(p.9,"%",sep=""),size=3.5,hjust=1,vjust=1, fontface="bold")+
  annotate("text",x=0.5,y=1,label=paste(n.5,"%",sep=""),size=3.5,hjust=1,vjust=1, fontface="bold")+
  annotate("text",x=0.9,y=1,label=paste(n.9,"%",sep=""),size=3.5,hjust=1,vjust=1, fontface="bold")+
  annotate("text",x=1,y=1,label=paste(p.n,"%",sep=""),size=3.5,hjust=1,vjust=1, fontface="bold")+
  labs(x="Introduction node likelihood",y="Parent node likelihood")+
  theme(panel.background = element_rect(fill="grey95"))

ggsave(paste(f.out,"/sublin.Likelihoods.Nodes.Parents.png",sep=""),width=5,height=5)

#### note: should we apply a cutoff here? #####
## Also incorporate bootstrap tree support here
## try ultrafast bootstrap in IQtree for this or go RAxML or ?
```


# Characterize biggest sublineages
## re-generate desc.df.list using sublin.long
```{r}
desc.df.try<-split(sublin.long.unq[[1]],f = sublin.long.unq[[1]]$Sublineage)
```

## Sublineage plots of cases over time, Re
## stacked plots of sublin descenedants, Canada
```{r}
# function that generates stacked barplot by location
plot.stacked.bars<-function(df){
  df$State<-str_replace_all(df$State,"Canada_","")
  df<-df[which(df$State %in% provs),]
  if(nrow(df)>50){ #only for sublineages > 50 in size because so many
    name<-df$Sublineage[1]
    N<-paste(": ",nrow(df)," sampled Canadian desc.",sep="")
    ggplot(df,aes(x=Date,fill=State)) + 
      geom_bar(position="stack",width=2)+
      ProvFillScale+
     scale_x_date(date_breaks = "1 month", date_minor_breaks = "2 weeks", 
                 date_labels = "%b %Y")+
      labs(x=NULL, y="Daily case count", color="Province", 
           title=paste("Sublineage ",name,N,sep=""))+
      theme(legend.position="bottom",title=element_text(size=7))+
      pubThemeDate+
      guides(col=guide_legend(nrow=1,title.position = "left",title="Province"))
      # annotate("text",label=N, y=maxlen,x=first(sort(df$Date)),size=rel(3),hjust=0) 
    ggsave(paste(f.sublin.out,"/",name,"_StackedBars",".png",sep=""),
           width=4,height=4)
  }
}

lapply(desc.df.try, plot.stacked.bars)

```

## stacked plots of sublin descenedants, all geos
```{r}
# df<-desc.df.try[[which(names(desc.df.try)==biggest)]]
# function that generates stacked barplot by location
plot.stacked.bars.allgeo<-function(df){
  df$State<-str_replace_all(df$State,"Canada_","")
  if(nrow(df[which(df$State %in% provs),])>50){ #only for sublineages > 50 in size because so many
    name<-df$Sublineage[1]
    N<-paste(": ",nrow(df)," sampled descendants",sep="")
    
    #make a custom geo order based on frequency
    mygeos<-names(sort(table(df$State),decreasing = T))
    df$State<-factor(df$State,levels=mygeos)
    #make a custom scale fill to reflect this custom geo vector
    geoFillScale<-scale_fill_manual(name = "Location",
                                    values = globalPalette.ch[match(mygeos,names(globalPalette.ch))]
                                    ,na.value="grey60")  
      
    ggplot(df,aes(x=Date,fill=State)) + 
      geom_bar(position="stack",width=2)+
      geoFillScale+
     scale_x_date(date_breaks = "1 month", date_minor_breaks = "2 weeks", 
                 date_labels = "%b %Y")+
      labs(x=NULL, y="Daily case count", color="Province", 
           title=paste(name,N,sep=""))+
      theme(legend.position="bottom",title=element_text(size=7),
            legend.margin=margin(0,0,0,0,"pt"),
            plot.margin=margin(2,2,2,2,"pt"))+
      pubThemeDate+
      guides(fill=guide_legend(ncol=4,title.position = "top",title="Location"))
      # annotate("text",label=N, y=maxlen,x=first(sort(df$Date)),size=rel(3),hjust=0) 
    ggsave(paste(f.sublin.out,"/",name,"_StackedBarsAllGeo",".png",sep=""),
           width=4,height=4)
  }
}

lapply(desc.df.try, plot.stacked.bars.allgeo)

```

## chracterize the biggest sublineages' Re
```{r}
require(splines)

#sublin incidence, growth rates, epiestim Re estim
for (i in 1:length(desc.df.try)){
  df<-desc.df.try[[i]]
  df$State<-str_replace_all(df$State,"Canada_","")
  # df<-df[which(df$State %in% provs),]
  if(nrow(df)>50){ #only for sublineages > 50 in size because so many
    df2<-df %>% dplyr::group_by(Date) %>% dplyr::summarise(Incidence=n())
    dateran<-range(df2$Date)
    df3<-data.frame(Date=seq(as.Date(dateran[1]),as.Date(dateran[2]),'days'))
    df3<-left_join(df3,df2,by="Date")
    df3$Incidence[which(is.na(df3$Incidence))]<-0
    #MAke a smoothed incidence
    df3<-df3 %>% mutate(rollIncidence=zoo::rollmean(Incidence,k = 7, align="center",fill = NA))
    df3$rollIncidence[which(is.na(df3$rollIncidence))]<-0
    #double smoothed
    df3<-df3 %>% mutate(rollerIncidence=zoo::rollmean(rollIncidence,k = 7, align="center",fill = NA))
    df3$rollerIncidence[which(is.na(df3$rollerIncidence))]<-0
    
    #TRY a smoothing spline
    date.grid<-seq(from=as.Date(dateran[1]), to =as.Date(dateran[2]),'days')
    #fitting smoothing splines using smooth.spline(X,Y,df=...)
    free<-trunc(as.numeric(dateran[2]-dateran[1])/7) #one df for every 7 days
    fit1<-smooth.spline(df3$Date,df3$rollIncidence,df=free) 
    df3$splineIncidence<-fit1$y
    df3$splineIncidence[which(df3$splineIncidence<0)]<-0
    #plot incidence
    ggplot(df3,aes(x=Date,y=rollIncidence))+
             geom_bar(stat="identity")+
             geom_line(aes(y=splineIncidence),color="red")+
      pubThemeDate+
      labs(y="Rolling sublineage incidence",x=NULL)+
      scale_x_date(date_breaks = "1 month", date_minor_breaks = "2 weeks", date_labels = "%b %Y")
    ggsave(paste(f.sublin.out,"/",df$Sublineage[1],"_SplineIncidence",".png",sep=""),width=4,height=4)

    FIRST<-df3$Date[first(which(df3$splineIncidence>2))]
    if(is.na(FIRST)){next}
    START<-as.numeric(FIRST-dateran[1])
    # incidence::df$  
    t_start <- seq(3, nrow(df3)-14) # starting at 2 as conditional on the past observations
    t_end <- t_start + 14 # adding 13 to get 14-day windows as bounds included in window

    epi.out<-EpiEstim::estimate_R(df3$splineIncidence, 
                                method="parametric_si",
                                config = make_config(list(
                                  t_start=t_start,
                                  t_end=t_end,
                                  mean_si = 4.8, 
                                  std_si = 2.3)))
    ### SERIAL INTERVAL MEAN 4.8 days, 2.3 sd
    
    # plot(epi.out,"R")
    # ggsave(paste(f.sublin.out,"/",df$Sublineage[1],"_epiestim",".png",sep=""),width=4,height=4)
    len.re<-nrow(epi.out$R)
    x<-0
    datez<-seq(as.Date(dateran[1])+(3),as.Date(dateran[2])-x,'days')
    x<- -(len.re-length(datez))
    datez<-seq(as.Date(dateran[1])+(3),as.Date(dateran[2])-x,'days')
    len.re==length(datez)
    epi.df<-data.frame(date=datez,
                       Re.mean=epi.out$R$`Mean(R)`, 
                       Re.med=epi.out$R$`Median(R)`,
                       Re.low=epi.out$R$`Quantile.0.05(R)`,
                       Re.high=epi.out$R$`Quantile.0.95(R)`)
    #remove first Re estimates
     # epi.df<-epi.df[-c(1,2,3,4,5,6),]
    #plot it up
    ggplot(data=epi.df,aes(x=date,y=Re.mean))+
      geom_hline(yintercept =1,lwd=0.5,lty=2)+
      geom_line(color="black")+
      geom_ribbon(aes(ymin=Re.low,ymax=Re.high),fill="grey35",alpha=0.6)+
      pubThemeDate+
      scale_x_date(date_breaks = "1 month", date_minor_breaks = "2 weeks", 
                 date_labels = "%b %Y")+      
      labs(x=NULL,y="Effective reproduction number",title=df$Sublineage[1])
      # annotate("text",label=N, y=maxlen,x=first(sort(df$Date)),size=rel(3),hjust=0) 
    ggsave(paste(f.sublin.out,"/",df$Sublineage[1],"_Re_SI4.8",".png",sep=""),width=4,height=3)
  }
}
```

## Repeat with a lower serial interval
```{r}
#sublin incidence, growth rates, epiestim Re estim
for (i in 1:length(desc.df.try)){
  df<-desc.df.try[[i]]
  df$State<-str_replace_all(df$State,"Canada_","")
  # df<-df[which(df$State %in% provs),]
  if(nrow(df)>50){ #only for sublineages > 50 in size because so many
    df2<-df %>% dplyr::group_by(Date) %>% dplyr::summarise(Incidence=n())
    dateran<-range(df2$Date)
    df3<-data.frame(Date=seq(as.Date(dateran[1]),as.Date(dateran[2]),'days'))
    df3<-left_join(df3,df2,by="Date")
    df3$Incidence[which(is.na(df3$Incidence))]<-0
    #MAke a smoothed incidence
    df3<-df3 %>% mutate(rollIncidence=zoo::rollmean(Incidence,k = 7, align="center",fill = NA))
    df3$rollIncidence[which(is.na(df3$rollIncidence))]<-0
    #double smoothed
    df3<-df3 %>% mutate(rollerIncidence=zoo::rollmean(rollIncidence,k = 7, align="center",fill = NA))
    df3$rollerIncidence[which(is.na(df3$rollerIncidence))]<-0
    
    #TRY a smoothing spline
    date.grid<-seq(from=as.Date(dateran[1]), to =as.Date(dateran[2]),'days')
    #fitting smoothing splines using smooth.spline(X,Y,df=...)
    free<-trunc(as.numeric(dateran[2]-dateran[1])/7) #one df for every 7 days
    fit1<-smooth.spline(df3$Date,df3$rollIncidence,df=free) 
    df3$splineIncidence<-fit1$y
    df3$splineIncidence[which(df3$splineIncidence<0)]<-0
    #plot incidence
    ggplot(df3,aes(x=Date,y=rollIncidence))+
             geom_bar(stat="identity")+
             geom_line(aes(y=splineIncidence),color="red")+
      pubThemeDate+
      labs(y="Rolling sublineage incidence",x=NULL)+
      scale_x_date(date_breaks = "1 month", date_minor_breaks = "2 weeks", date_labels = "%b %Y")
    ggsave(paste(f.sublin.out,"/",df$Sublineage[1],"_SplineIncidence",".png",sep=""),width=4,height=4)

    FIRST<-df3$Date[first(which(df3$splineIncidence>2))]
    if(is.na(FIRST)){next}
    START<-as.numeric(FIRST-dateran[1])
    # incidence::df$  
    t_start <- seq(3, nrow(df3)-14) # starting at 2 as conditional on the past observations
    t_end <- t_start + 14 # adding 13 to get 14-day windows as bounds included in window

    epi.out<-EpiEstim::estimate_R(df3$splineIncidence, 
                                method="parametric_si",
                                config = make_config(list(
                                  t_start=t_start,
                                  t_end=t_end,
                                  mean_si = 3, 
                                  std_si = 2)))
    # plot(epi.out,"R")
    # ggsave(paste(f.sublin.out,"/",df$Sublineage[1],"_epiestim",".png",sep=""),width=4,height=4)
    len.re<-nrow(epi.out$R)
    x<-0
    datez<-seq(as.Date(dateran[1])+(3),as.Date(dateran[2])-x,'days')
    x<- -(len.re-length(datez))
    datez<-seq(as.Date(dateran[1])+(3),as.Date(dateran[2])-x,'days')
    len.re==length(datez)
    epi.df<-data.frame(date=datez,
                       Re.mean=epi.out$R$`Mean(R)`, 
                       Re.med=epi.out$R$`Median(R)`,
                       Re.low=epi.out$R$`Quantile.0.05(R)`,
                       Re.high=epi.out$R$`Quantile.0.95(R)`)
    #remove first Re estimates
     # epi.df<-epi.df[-c(1,2,3,4,5,6),]
    #plot it up
    ggplot(data=epi.df,aes(x=date,y=Re.mean))+
      geom_hline(yintercept =1,lwd=0.5,lty=2)+
      geom_line(color="black")+
      geom_ribbon(aes(ymin=Re.low,ymax=Re.high),fill="grey35",alpha=0.6)+
      pubThemeDate+
      scale_x_date(date_breaks = "1 month", date_minor_breaks = "2 weeks", 
                 date_labels = "%b %Y")+      
      labs(x=NULL,y="Effective reproduction number",title=df$Sublineage[1])
      # annotate("text",label=N, y=maxlen,x=first(sort(df$Date)),size=rel(3),hjust=0) 
    ggsave(paste(f.sublin.out,"/",df$Sublineage[1],"_Re_SI3",".png",sep=""),width=4,height=4)
  }
}
```


## Repeat with a low serial interval, but smaller window of estimation
```{r}
#sublin incidence, growth rates, epiestim Re estim
for (i in 1:length(desc.df.try)){
  df<-desc.df.try[[i]]
  df$State<-str_replace_all(df$State,"Canada_","")
  # df<-df[which(df$State %in% provs),]
  if(nrow(df)>50){ #only for sublineages > 50 in size because so many
    df2<-df %>% dplyr::group_by(Date) %>% dplyr::summarise(Incidence=n())
    dateran<-range(df2$Date)
    df3<-data.frame(Date=seq(as.Date(dateran[1]),as.Date(dateran[2]),'days'))
    df3<-left_join(df3,df2,by="Date")
    df3$Incidence[which(is.na(df3$Incidence))]<-0
    #MAke a smoothed incidence
    df3<-df3 %>% mutate(rollIncidence=zoo::rollmean(Incidence,k = 7, align="center",fill = NA))
    df3$rollIncidence[which(is.na(df3$rollIncidence))]<-0
    #double smoothed
    df3<-df3 %>% mutate(rollerIncidence=zoo::rollmean(rollIncidence,k = 7, align="center",fill = NA))
    df3$rollerIncidence[which(is.na(df3$rollerIncidence))]<-0
    
    #TRY a smoothing spline
    date.grid<-seq(from=as.Date(dateran[1]), to =as.Date(dateran[2]),'days')
    #fitting smoothing splines using smooth.spline(X,Y,df=...)
    free<-trunc(as.numeric(dateran[2]-dateran[1])/7) #one df for every 7 days
    fit1<-smooth.spline(df3$Date,df3$rollIncidence,df=free) 
    df3$splineIncidence<-fit1$y
    df3$splineIncidence[which(df3$splineIncidence<0)]<-0
    #plot incidence
    # ggplot(df3,aes(x=Date,y=rollIncidence))+
    #          geom_bar(stat="identity")+
    #          geom_line(aes(y=splineIncidence),color="red")+
    #   pubThemeDate+
    #   labs(y="Rolling sublineage incidence",x=NULL)+
    #   scale_x_date(date_breaks = "1 month", date_minor_breaks = "2 weeks", date_labels = "%b %Y")
    # ggsave(paste(f.sublin.out,"/",df$Sublineage[1],"_SplineIncidence",".png",sep=""),width=4,height=4)

    FIRST<-df3$Date[first(which(df3$splineIncidence>2))]
    if(is.na(FIRST)){next}
    START<-as.numeric(FIRST-dateran[1])
    # incidence::df$  
    t_start <- seq(3, nrow(df3)-7) # starting at 2 as conditional on the past observations
    t_end <- t_start + 7 # adding 13 to get 14-day windows as bounds included in window

    epi.out<-EpiEstim::estimate_R(df3$splineIncidence, 
                                method="parametric_si",
                                config = make_config(list(
                                  t_start=t_start,
                                  t_end=t_end,
                                  mean_si = 3, 
                                  std_si = 2)))
    # plot(epi.out,"R")
    # ggsave(paste(f.sublin.out,"/",df$Sublineage[1],"_epiestim",".png",sep=""),width=4,height=4)
    len.re<-nrow(epi.out$R)
    x<-0
    datez<-seq(as.Date(dateran[1])+(3),as.Date(dateran[2])-x,'days')
    x<- -(len.re-length(datez))
    datez<-seq(as.Date(dateran[1])+(3),as.Date(dateran[2])-x,'days')
    len.re==length(datez)
    epi.df<-data.frame(date=datez,
                       Re.mean=epi.out$R$`Mean(R)`, 
                       Re.med=epi.out$R$`Median(R)`,
                       Re.low=epi.out$R$`Quantile.0.05(R)`,
                       Re.high=epi.out$R$`Quantile.0.95(R)`)
    #remove Re estimates from dates with sparse data     
    # epi.df<-epi.df[-c(1:),]
    #plot it up
    ggplot(data=epi.df,aes(x=date,y=Re.mean))+
      geom_hline(yintercept =1,lwd=0.5,lty=2)+
      geom_line(color="black")+
      geom_ribbon(aes(ymin=Re.low,ymax=Re.high),fill="grey35",alpha=0.6)+
      pubThemeDate+
      scale_x_date(date_breaks = "1 month", date_minor_breaks = "2 weeks", 
                 date_labels = "%b %Y")+      
      labs(x=NULL,y="Effective reproduction number",title=df$Sublineage[1])
      # annotate("text",label=N, y=maxlen,x=first(sort(df$Date)),size=rel(3),hjust=0) 
    ggsave(paste(f.sublin.out,"/",df$Sublineage[1],"_Re_SI3-window7",".png",sep=""),width=4,height=4)
  }
}
```

